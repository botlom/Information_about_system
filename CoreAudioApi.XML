<?xml version="1.0"?>
<doc>
    <assembly>
        <name>CoreAudioApi</name>
    </assembly>
    <members>
        <member name="T:CoreAudioApi.ChannelMasks">
            <summary>
            Steuert die Zuordnung der Kanäle in einem Wav-Datenstrom.
            Dabei stellt jedes Bit einen Kanal dar (LSB => links vorn; LSB+1 => rechts vorn ...).
            </summary>
        </member>
        <member name="F:CoreAudioApi.ChannelMasks.SpeakerFrontLeft">
            <summary>
            vorn links
            </summary>
        </member>
        <member name="F:CoreAudioApi.ChannelMasks.SpeakerFrontRight">
            <summary>
            vorn rechts
            </summary>
        </member>
        <member name="F:CoreAudioApi.ChannelMasks.SpeakerFrontCenter">
            <summary>
            vorn center
            </summary>
        </member>
        <member name="F:CoreAudioApi.ChannelMasks.SpeakerLOWFrequency">
            <summary>
            Subwoofer
            </summary>
        </member>
        <member name="F:CoreAudioApi.ChannelMasks.SpeakerBackLeft">
            <summary>
            hinten links
            </summary>
        </member>
        <member name="F:CoreAudioApi.ChannelMasks.SpeakerBackRight">
            <summary>
            hinten rechts
            </summary>
        </member>
        <member name="F:CoreAudioApi.ChannelMasks.SpeakerFrontLeftOfCenter">
            <summary>
            SpeakerFrontLeftOfCenter
            </summary>
        </member>
        <member name="F:CoreAudioApi.ChannelMasks.SpeakerFrontRightOfCenter">
            <summary>
            SpeakerFrontRightOfCenter
            </summary>
        </member>
        <member name="F:CoreAudioApi.ChannelMasks.SpeakerBackCenter">
            <summary>
            SpeakerBackCenter
            </summary>
        </member>
        <member name="F:CoreAudioApi.ChannelMasks.SpeakerSideLeft">
            <summary>
            SpeakerSideLeft
            </summary>
        </member>
        <member name="F:CoreAudioApi.ChannelMasks.SpeakerSideRight">
            <summary>
            SpeakerSideRight
            </summary>
        </member>
        <member name="F:CoreAudioApi.ChannelMasks.SpeakerTopCenter">
            <summary>
            SpeakerTopCenter
            </summary>
        </member>
        <member name="F:CoreAudioApi.ChannelMasks.SpeakerTopFrontLeft">
            <summary>
            SpeakerTopFrontLeft
            </summary>
        </member>
        <member name="F:CoreAudioApi.ChannelMasks.SpeakerTopFrontCenter">
            <summary>
            SpeakerTopFrontCenter
            </summary>
        </member>
        <member name="F:CoreAudioApi.ChannelMasks.SpeakerTopFrontRight">
            <summary>
            SpeakerTopFrontRight
            </summary>
        </member>
        <member name="F:CoreAudioApi.ChannelMasks.SpeakerTopBackLeft">
            <summary>
            SpeakerTopBackLeft
            </summary>
        </member>
        <member name="F:CoreAudioApi.ChannelMasks.SpeakerTopBackCenter">
            <summary>
            SpeakerTopBackCenter
            </summary>
        </member>
        <member name="F:CoreAudioApi.ChannelMasks.SpeakerTopBackRight">
            <summary>
            SpeakerTopBackRight
            </summary>
        </member>
        <member name="F:CoreAudioApi.ChannelMasks.SpeakerBitstream1_Left">
            <summary>
            SpeakerBitstream1_Left
            </summary>
        </member>
        <member name="F:CoreAudioApi.ChannelMasks.SpeakerBitstream1_Right">
            <summary>
            SpeakerBitstream1_Right
            </summary>
        </member>
        <member name="F:CoreAudioApi.ChannelMasks.SpeakerBitstream2_Left">
            <summary>
            SpeakerBitstream2_Left
            </summary>
        </member>
        <member name="F:CoreAudioApi.ChannelMasks.SpeakerBitstream2_Right">
            <summary>
            SpeakerBitstream2_Right
            </summary>
        </member>
        <member name="F:CoreAudioApi.ChannelMasks.SpeakerControlsample1">
            <summary>
            SpeakerControlsample1
            </summary>
        </member>
        <member name="F:CoreAudioApi.ChannelMasks.SpeakerControlsample2">
            <summary>
            SpeakerControlsample2
            </summary>
        </member>
        <member name="F:CoreAudioApi.ChannelMasks.SpeakerStereoLeft">
            <summary>
            Linker Kanal, wenn neben einer Mehrkanalaufnahme auch heruntergemixte Stereokanäle vorhanden sind.
            </summary>
        </member>
        <member name="F:CoreAudioApi.ChannelMasks.SpeakerStereoRight">
            <summary>
            Rechter Kanal, wenn neben einer Mehrkanalaufnahme auch heruntergemixte Stereokanäle vorhanden sind.
            </summary>
        </member>
        <member name="F:CoreAudioApi.ChannelMasks.AllChannels">
            <summary>
            AllChannels
            </summary>
        </member>
        <member name="T:CoreAudioApi.WaveFormatTags">
            <summary>
            WaveFormatTags zur Kennzeichnung des Sound-Encodings.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.UNKNOWN">
            <summary>
            Microsoft Corporation
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.PCM">
            <summary>
            Microsoft Corporation
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.ADPCM">
            <summary>
            Microsoft Corporation
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.IEEE_FLOAT">
            <summary>
            Microsoft Corporation
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.VSELP">
            <summary>
            Compaq Computer Corp.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.IBM_CVSD">
            <summary>
            IBM Corporation
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.ALAW">
            <summary>
            Microsoft Corporation
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.MULAW">
            <summary>
            Microsoft Corporation
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.DTS">
            <summary>
            Microsoft Corporation
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.DRM">
            <summary>
            Microsoft Corporation
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.WMAVOICE9">
            <summary>
            Microsoft Corporation
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.WMAVOICE10">
            <summary>
            Microsoft Corporation
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.OKI_ADPCM">
            <summary>
            OKI
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.DVI_ADPCM">
            <summary>
            Intel Corporation
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.MEDIASPACE_ADPCM">
            <summary>
            Videologic
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.SIERRA_ADPCM">
            <summary>
            Sierra Semiconductor Corp
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.G723_ADPCM">
            <summary>
            Antex Electronics Corporation
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.DIGISTD">
            <summary>
            DSP Solutions, Inc.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.DIGIFIX">
            <summary>
            DSP Solutions, Inc.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.DIALOGIC_OKI_ADPCM">
            <summary>
            Dialogic Corporation
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.MEDIAVISION_ADPCM">
            <summary>
            Media Vision, Inc.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.CU_CODEC">
            <summary>
            Hewlett-Packard Company
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.YAMAHA_ADPCM">
            <summary>
            Yamaha Corporation of America
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.SONARC">
            <summary>
            Speech Compression
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.DSPGROUP_TRUESPEECH">
            <summary>
            DSP Group, Inc
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.ECHOSC1">
            <summary>
            Echo Speech Corporation
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.AUDIOFILE_AF36">
            <summary>
            Virtual Music, Inc.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.APTX">
            <summary>
            Audio Processing Technology
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.AUDIOFILE_AF10">
            <summary>
            Virtual Music, Inc.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.PROSODY_1612">
            <summary>
            Aculab plc
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.LRC">
            <summary>
            Merging Technologies S.A.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.DOLBY_AC2">
            <summary>
            Dolby Laboratories
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.GSM610">
            <summary>
            Microsoft Corporation
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.MSNAUDIO">
            <summary>
            Microsoft Corporation
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.ANTEX_ADPCME">
            <summary>
            Antex Electronics Corporation
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.CONTROL_RES_VQLPC">
            <summary>
            Control Resources Limited
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.DIGIREAL">
            <summary>
            DSP Solutions, Inc.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.DIGIADPCM">
            <summary>
            DSP Solutions, Inc.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.CONTROL_RES_CR10">
            <summary>
            Control Resources Limited
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.NMS_VBXADPCM">
            <summary>
            Natural MicroSystems
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.CS_IMAADPCM">
            <summary>
            Crystal Semiconductor IMA ADPCM
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.ECHOSC3">
            <summary>
            Echo Speech Corporation
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.ROCKWELL_ADPCM">
            <summary>
            Rockwell International
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.ROCKWELL_DIGITALK">
            <summary>
            Rockwell International
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.XEBEC">
            <summary>
            Xebec Multimedia Solutions Limited
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.G721_ADPCM">
            <summary>
            Antex Electronics Corporation
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.G728_CELP">
            <summary>
            Antex Electronics Corporation
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.MSG723">
            <summary>
            Microsoft Corporation
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.MPEG">
            <summary>
            Microsoft Corporation
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.RT24">
            <summary>
            InSoft, Inc.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.PAC">
            <summary>
            InSoft, Inc.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.MPEGLAYER3">
            <summary>
            ISO/MPEG Layer3 Format Tag
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.LUCENT_G723">
            <summary>
            Lucent Technologies
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.CIRRUS">
            <summary>
            Cirrus Logic
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.ESPCM">
            <summary>
            ESS Technology
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.VOXWARE">
            <summary>
            Voxware Inc
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.CANOPUS_ATRAC">
            <summary>
            Canopus, co., Ltd.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.G726_ADPCM">
            <summary>
            APICOM
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.G722_ADPCM">
            <summary>
            APICOM
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.DSAT_DISPLAY">
            <summary>
            Microsoft Corporation
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.VOXWARE_BYTE_ALIGNED">
            <summary>
            Voxware Inc
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.VOXWARE_AC8">
            <summary>
            Voxware Inc
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.VOXWARE_AC10">
            <summary>
            Voxware Inc
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.VOXWARE_AC16">
            <summary>
            Voxware Inc
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.VOXWARE_AC20">
            <summary>
            Voxware Inc
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.VOXWARE_RT24">
            <summary>
            Voxware Inc
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.VOXWARE_RT29">
            <summary>
            Voxware Inc
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.VOXWARE_RT29HW">
            <summary>
            Voxware Inc
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.VOXWARE_VR12">
            <summary>
            Voxware Inc
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.VOXWARE_VR18">
            <summary>
            Voxware Inc
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.VOXWARE_TQ40">
            <summary>
            Voxware Inc
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.SOFTSOUND">
            <summary>
            Softsound, Ltd.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.VOXWARE_TQ60">
            <summary>
            Voxware Inc
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.MSRT24">
            <summary>
            Microsoft Corporation
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.G729A">
            <summary>
            AT&amp;T Labs, Inc.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.MVI_MVI2">
            <summary>
            Motion Pixels
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.DF_G726">
            <summary>
            DataFusion Systems (Pty) (Ltd)
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.DF_GSM610">
            <summary>
            DataFusion Systems (Pty) (Ltd)
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.ISIAUDIO">
            <summary>
            Iterated Systems, Inc.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.ONLIVE">
            <summary>
            OnLive! Technologies, Inc.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.SBC24">
            <summary>
            Siemens Business Communications Sys
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.DOLBY_AC3_SPDIF">
            <summary>
            Sonic Foundry
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.MEDIASONIC_G723">
            <summary>
            MediaSonic
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.PROSODY_8KBPS">
            <summary>
            Aculab plc
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.ZYXEL_ADPCM">
            <summary>
            ZyXEL Communications, Inc.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.PHILIPS_LPCBB">
            <summary>
            Philips Speech Processing
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.PACKED">
            <summary>
            Studer Professional Audio AG
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.MALDEN_PHONYTALK">
            <summary>
            Malden Electronics Ltd.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.RAW_AAC1">
            <summary>
            For Raw AAC, with format block AudioSpecificConfig() (as defined by MPEG-4), that follows WAVEFORMATEX
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.RHETOREX_ADPCM">
            <summary>
            Rhetorex Inc.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.IRAT">
            <summary>
            BeCubed Software Inc.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.VIVO_G723">
            <summary>
            Vivo Software
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.VIVO_SIREN">
            <summary>
            Vivo Software
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.DIGITAL_G723">
            <summary>
            Digital Equipment Corporation
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.SANYO_LD_ADPCM">
            <summary>
            Sanyo Electric Co., Ltd.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.SIPROLAB_ACEPLNET">
            <summary>
            Sipro Lab Telecom Inc.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.SIPROLAB_ACELP4800">
            <summary>
            Sipro Lab Telecom Inc.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.SIPROLAB_ACELP8V3">
            <summary>
            Sipro Lab Telecom Inc.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.SIPROLAB_G729">
            <summary>
            Sipro Lab Telecom Inc.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.SIPROLAB_G729A">
            <summary>
            Sipro Lab Telecom Inc.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.SIPROLAB_KELVIN">
            <summary>
            Sipro Lab Telecom Inc.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.G726ADPCM">
            <summary>
            Dictaphone Corporation
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.QUALCOMM_PUREVOICE">
            <summary>
            Qualcomm, Inc.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.QUALCOMM_HALFRATE">
            <summary>
            Qualcomm, Inc.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.TUBGSM">
            <summary>
            Ring Zero Systems, Inc.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.MSAUDIO1">
            <summary>
            Microsoft Corporation
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.WMAUDIO2">
            <summary>
            Microsoft Corporation
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.WMAUDIO3">
            <summary>
            Microsoft Corporation
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.WMAUDIO_LOSSLESS">
            <summary>
            Microsoft Corporation
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.WMASPDIF">
            <summary>
            Microsoft Corporation
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.UNISYS_NAP_ADPCM">
            <summary>
            Unisys Corp.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.UNISYS_NAP_ULAW">
            <summary>
            Unisys Corp.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.UNISYS_NAP_ALAW">
            <summary>
            Unisys Corp.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.UNISYS_NAP_16K">
            <summary>
            Unisys Corp.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.CREATIVE_ADPCM">
            <summary>
            Creative Labs, Inc
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.CREATIVE_FASTSPEECH8">
            <summary>
            Creative Labs, Inc
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.CREATIVE_FASTSPEECH10">
            <summary>
            Creative Labs, Inc
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.UHER_ADPCM">
            <summary>
            UHER informatic GmbH
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.QUARTERDECK">
            <summary>
            Quarterdeck Corporation
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.ILINK_VC">
            <summary>
            I-link Worldwide
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.RAW_SPORT">
            <summary>
            Aureal Semiconductor
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.ESST_AC3">
            <summary>
            ESS Technology, Inc.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.GENERIC_PASSTHRU">
            <summary>
                 
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.IPI_HSX">
            <summary>
            Interactive Products, Inc.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.IPI_RPELP">
            <summary>
            Interactive Products, Inc.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.CS2">
            <summary>
            Consistent Software
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.SONY_SCX">
            <summary>
            Sony Corp.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.FM_TOWNS_SND">
            <summary>
            Fujitsu Corp.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.BTV_DIGITAL">
            <summary>
            Brooktree Corporation
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.QDESIGN_MUSIC">
            <summary>
            QDesign Corporation
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.VME_VMPCM">
            <summary>
            AT&amp;T Labs, Inc.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.TPC">
            <summary>
            AT&amp;T Labs, Inc.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.OLIGSM">
            <summary>
            Ing C. Olivetti &amp; C., S.p.A.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.OLIADPCM">
            <summary>
            Ing C. Olivetti &amp; C., S.p.A.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.OLICELP">
            <summary>
            Ing C. Olivetti &amp; C., S.p.A.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.OLISBC">
            <summary>
            Ing C. Olivetti &amp; C., S.p.A.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.OLIOPR">
            <summary>
            Ing C. Olivetti &amp; C., S.p.A.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.LH_CODEC">
            <summary>
            Lernout &amp; Hauspie
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.NORRIS">
            <summary>
            Norris Communications, Inc.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.SOUNDSPACE_MUSICOMPRESS">
            <summary>
            AT&amp;T Labs, Inc.
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.MPEG_ADTS_AAC">
            <summary>
            Microsoft Corporation
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.MPEG_RAW_AAC">
            <summary>
            Microsoft Corporation
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.MPEG_LOAS">
            <summary>
            Microsoft Corporation (MPEG-4 Audio Transport Streams (LOAS/LATM)
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.NOKIA_MPEG_ADTS_AAC">
            <summary>
            Microsoft Corporation
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.NOKIA_MPEG_RAW_AAC">
            <summary>
            Microsoft Corporation
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.VODAFONE_MPEG_ADTS_AAC">
            <summary>
            Microsoft Corporation
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.VODAFONE_MPEG_RAW_AAC">
            <summary>
            Microsoft Corporation
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.MPEG_HEAAC">
            <summary>
            Microsoft Corporation (MPEG-2 AAC or MPEG-4 HE-AAC v1/v2 streams with any payload (ADTS, ADIF, LOAS/LATM, RAW).
            Format block includes MP4 AudioSpecificConfig() -- see HEAACWAVEFORMAT below
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.DVM">
            <summary>
            FAST Multimedia AG
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.DTS2">
            <summary>
                 
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.EXTENSIBLE">
            <summary>
            Microsoft
            </summary>
        </member>
        <member name="F:CoreAudioApi.WaveFormatTags.DEVELOPMENT">
            <summary>
                 
            </summary>
        </member>
        <member name="T:CoreAudioApi.MMDeviceCollection">
            <summary>
            Eine Collection aus Audiogeräten mit Methoden um darauf zuzugreifen.
            </summary>
        </member>
        <member name="M:CoreAudioApi.MMDeviceCollection.#ctor(CoreAudioApi.IMMDeviceCollection)">
            <summary>
            Eine Collection aus Audiogeräten mit Methoden um darauf zuzugreifen.
            </summary>
            <param name="immDeviceCollection">
            IMMDeviceCollection aus dem IMMDeviceEnumerator.
            </param>
        </member>
        <member name="M:CoreAudioApi.MMDeviceCollection.GetEnumerator">
            <summary>
            Erzeugt einen Soundgeräteenumerator.
            </summary>
            <returns>
            Soundgeräteenumerator
            </returns>
        </member>
        <member name="M:CoreAudioApi.MMDeviceCollection.Dispose">
            <summary>
            Gibt die Ressourcen der MMDeviceCollection frei.
            </summary>
        </member>
        <member name="M:CoreAudioApi.MMDeviceCollection.Dispose(System.Boolean)">
            <summary>
            Gibt die Ressourcen der MMDeviceCollection frei.
            </summary>
            <param name="disposing">
            true, es werden auch verwaltete Objekte frei gegeben.
            false, wenn die Methode aus einem Destructor aufgerufen werden soll.
            </param>
        </member>
        <member name="M:CoreAudioApi.MMDeviceCollection.Finalize">
            <summary>
            Destructor
            </summary>
        </member>
        <member name="P:CoreAudioApi.MMDeviceCollection.Disposed">
            <summary>
            Ruft ab, ob das Element frei gegeben wurde.
            </summary>
        </member>
        <member name="P:CoreAudioApi.MMDeviceCollection.Count">
            <summary>
            Gibt die Anzahl der verfügbaren Soundgeräte an.
            </summary>
        </member>
        <member name="P:CoreAudioApi.MMDeviceCollection.Item(System.Int32)">
            <summary>
            Gibt ein nach seinem Index ausgewähltes Gerät zurück.
            </summary>
            <param name="Index">
            Index des gewünschten Soundgerätes.
            </param>
            <returns>
            Gewünschtes Soundgerät.
            </returns>
        </member>
        <member name="T:CoreAudioApi.MMDevice">
            <summary>
            Stellt die Grundeigenschaften eines Audiogerätes zur Verfügung. Ein MMDevice kann aus einem MMDeviceEnumerator gewonnen werden. Es muß nach seiner Verwendung mit Dispose
            vernichtet werden.
            </summary>
        </member>
        <member name="M:CoreAudioApi.MMDevice.#ctor(CoreAudioApi.IMMDevice)">
            <summary>
            Stellt die Grundeigenschaften eines Audiogerätes zur Verfügung. Ein MMDevice kann aus einem MMDeviceEnumerator gewonnen werden. Es muß nach seiner Verwendung mit Dispose
            vernichtet werden.
            </summary>
            <param name="immDevice">
            IMMDevice aus einem MMDeviceEnumerator.
            </param>
        </member>
        <member name="M:CoreAudioApi.MMDevice.ToString">
            <summary>
            Gibt den Namen des Soundgerätes zurück.
            </summary>
            <returns>
            Name des Soundgerätes.
            </returns>
        </member>
        <member name="M:CoreAudioApi.MMDevice.Dispose">
            <summary>
            Gibt die Ressourcen des MMDevice frei.
            </summary>
        </member>
        <member name="M:CoreAudioApi.MMDevice.Dispose(System.Boolean)">
            <summary>
            Gibt die Ressourcen des MMDevice frei.
            </summary>
            <param name="disposing">
            true, es werden auch verwaltete Objekte frei gegeben.
            false, wenn die Methode aus einem Destructor aufgerufen werden soll.
            </param>
        </member>
        <member name="M:CoreAudioApi.MMDevice.Finalize">
            <summary>
            Destructor
            </summary>
        </member>
        <member name="P:CoreAudioApi.MMDevice.Disposed">
            <summary>
            Ruft ab, ob das Element frei gegeben wurde.
            </summary>
        </member>
        <member name="P:CoreAudioApi.MMDevice.EndpointFormFactor">
            <summary>
            Gibt an, um welche Geräteart es sich handelt.
            </summary>
        </member>
        <member name="P:CoreAudioApi.MMDevice.AudioClient">
            <summary>
            Gibt einen AudioClient zurück.
            </summary>
        </member>
        <member name="P:CoreAudioApi.MMDevice.AudioEndpointVolumeEx">
            <summary>
            Gibt ein AudioEndpointVolumeEx Objekt zurück.
            </summary>
        </member>
        <member name="P:CoreAudioApi.MMDevice.AudioMeterInformation">
            <summary>
            Gibt ein AudioMeterInformation Objekt zurück.
            </summary>
        </member>
        <member name="P:CoreAudioApi.MMDevice.ID">
            <summary>
            Gibt die ID des Soundgerätes zurück. Die Struktur dieses Strings ist in verschiedenen Implementierungen der MMDeviceAPI nicht gleich. 
            </summary>
        </member>
        <member name="P:CoreAudioApi.MMDevice.Properties">
            <summary>
            Gibt eine Sammmlung von Eigenschaften des Soundgerätes zurück.
            </summary>
        </member>
        <member name="P:CoreAudioApi.MMDevice.NameDevice">
            <summary>
            Gibt den Namen des Soundgerätes zurück.
            </summary>
        </member>
        <member name="P:CoreAudioApi.MMDevice.AudioEndpointSupportsEventDrivenMode">
            <summary>
            Gibt true zurück, wenn der Audioendpoint den Eventmode beherrscht.
            </summary>
        </member>
        <member name="P:CoreAudioApi.MMDevice.DataFlow">
            <summary>
            Gibt die Richtung des Audiodatenflusses des Audiogerätes an.
            </summary>
        </member>
        <member name="P:CoreAudioApi.MMDevice.State">
            <summary>
            Gibt den Zustand des Audiogerätes zurück.
            </summary>
        </member>
        <member name="P:CoreAudioApi.MMDevice.DeviceIconPath">
            <summary>
            Gibt den Pfad zum Icon des Audiogerätes zurück.
            </summary>
        </member>
        <member name="T:CoreAudioApi.AudioClock">
            <summary>
            AudioClock stellt Methoden zur Positionsbestimmung im Audiostream bereit. Er wird aus der AudioClock-Eigenschaft eines AudioClient
            gewonnen. Die AudioClock muß nach ihrer Verwendung mit Dispose vernichtet werden.
            </summary>
        </member>
        <member name="M:CoreAudioApi.AudioClock.#ctor(CoreAudioApi.IAudioClock)">
            <summary>
            AudioClock stellt Methoden zur Positionsbestimmung im Audiostream bereit. Er wird aus der AudioClock-Eigenschaft eines AudioClient
            gewonnen. Die AudioClock muß nach ihrer Verwendung mit Dispose vernichtet werden.
            </summary>
            <param name="iAudioClock">
            Ein IAudioClock aus einem AudioClient.
            </param>
        </member>
        <member name="M:CoreAudioApi.AudioClock.Dispose">
            <summary>
            Gibt die Ressourcen der AudioClock frei.
            </summary>
        </member>
        <member name="M:CoreAudioApi.AudioClock.Dispose(System.Boolean)">
            <summary>
            Gibt die Ressourcen der AudioClock frei.
            </summary>
            <param name="disposing">
            true, es werden auch verwaltete Objekte frei gegeben.
            false, wenn die Methode aus einem Destructor aufgerufen werden soll.
            </param>
        </member>
        <member name="M:CoreAudioApi.AudioClock.Finalize">
            <summary>
            Destructor
            </summary>
        </member>
        <member name="P:CoreAudioApi.AudioClock.Disposed">
            <summary>
            Ruft ab, ob das Element frei gegeben wurde.
            </summary>
        </member>
        <member name="P:CoreAudioApi.AudioClock.Position">
            <summary>
            Gibt die Position des Audioframes in Sekunden zurück, der gerade hörbar bzw. am Audioeingang aufgenommen wird.
            </summary>
        </member>
        <member name="T:CoreAudioApi.IAudioClock">
            <summary>
            The IAudioClock interface enables a client to monitor a stream's data rate and the current position in the stream. The client obtains a reference to the IAudioClock
            interface of a stream object by calling the IAudioClient.GetService method with parameter riid set to REFIID IID_IAudioClock. When releasing an IAudioClock interface instance,
            the client must call the interface's Release method from the same thread as the call to IAudioClient.GetService that created the object. 
            </summary>
        </member>
        <member name="M:CoreAudioApi.IAudioClock.GetFrequency(System.Int64@)">
            <summary>
            The GetFrequency method gets the device frequency. The device frequency is the frequency generated by the hardware clock in the audio device.
            This method reports the device frequency in units that are compatible with those of the device position that the IAudioClock.GetPosition method reports. For example, if,
            for a particular stream, the GetPosition method expresses the position p as a byte offset, the GetFrequency method expresses the frequency f in bytes per second.
            For any stream, the offset in seconds from the start of the stream can always be reliably calculated as p / f regardless of the units in which p and f are expressed.
            </summary>
            <param name="frequency">
            Pointer to a UINT64 variable into which the method writes the device frequency.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IAudioClock.GetPosition(System.Int64@,System.Int64@)">
            <summary>
            The GetPosition method gets the current device position. Rendering or capture clients that need to expose a clock based on the stream's current playback or record position
            can use this method to derive that clock.
            </summary>
            <param name="position">
            Pointer to a UINT64 variable into which the method writes the device position. The device position is the offset from the start of the stream to the current position in the
            stream. However, the units in which this offset is expressed are undefined—the device position value has meaning only in relation to the frequency reported by the
            IAudioClock.GetFrequency method.
            </param>
            <param name="qPCPosition">
            Pointer to a UINT64 variable into which the method writes the value of the performance counter at the time that the audio endpoint device read the device position
            (qPCPosition) in response to the GetPosition call. The method converts the counter value to 100-nanosecond time units before writing it to qPCPosition.
            This parameter can be NULL if the client does not require the performance counter value.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IAudioClock.GetCharacteristics(System.UInt32@)">
            <summary>
            The GetCharacteristics method is reserved for future use.
            </summary>
            <param name="characteristics">
            Pointer to a DWORD variable into which the method writes a value that indicates the characteristics of the audio clock.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="T:CoreAudioApi.TagCLSCTX">
            <summary>
            Values that are used in activation calls to indicate the execution contexts in which an object is to be run.
            These values are also used in calls to CoRegisterClassObject to indicate the set of execution contexts in which a class object
            is to be made available for requests to construct instances. 
            </summary>
        </member>
        <member name="F:CoreAudioApi.TagCLSCTX.CLSCTX_INPROC_SERVER">
            <summary>
            The code that creates and manages objects of this class is a DLL that runs in the same process as the caller of the function specifying the class context.
            </summary>
        </member>
        <member name="F:CoreAudioApi.TagCLSCTX.CLSCTX_INPROC_HANDLER">
            <summary>
            The code that manages objects of this class is an in-process handler.
            This is a DLL that runs in the client process and implements client-side structures of this class when instances of the class are accessed remotely.
            </summary>
        </member>
        <member name="F:CoreAudioApi.TagCLSCTX.CLSCTX_LOCAL_SERVER">
            <summary>
            The EXE code that creates and manages objects of this class runs on same machine but is loaded in a separate process space.
            </summary>
        </member>
        <member name="F:CoreAudioApi.TagCLSCTX.CLSCTX_INPROC_SERVER16">
            <summary>
            Obsolete
            </summary>
        </member>
        <member name="F:CoreAudioApi.TagCLSCTX.CLSCTX_REMOTE_SERVER">
            <summary>
            A remote context. The LocalServer32 or LocalService code that creates and manages objects of this class is run on a different computer.
            </summary>
        </member>
        <member name="F:CoreAudioApi.TagCLSCTX.CLSCTX_INPROC_HANDLER16">
            <summary>
            Obsolete
            </summary>
        </member>
        <member name="F:CoreAudioApi.TagCLSCTX.CLSCTX_RESERVED1">
            <summary>
            Reserved
            </summary>
        </member>
        <member name="F:CoreAudioApi.TagCLSCTX.CLSCTX_RESERVED2">
            <summary>
            Reserved
            </summary>
        </member>
        <member name="F:CoreAudioApi.TagCLSCTX.CLSCTX_RESERVED3">
            <summary>
            Reserved
            </summary>
        </member>
        <member name="F:CoreAudioApi.TagCLSCTX.CLSCTX_RESERVED4">
            <summary>
            Reserved
            </summary>
        </member>
        <member name="F:CoreAudioApi.TagCLSCTX.CLSCTX_NO_CODE_DOWNLOAD">
            <summary>
            Disaables the downloading of code from the directory service or the Internet. This flag cannot be set at the same time as CLSCTX_ENABLE_CODE_DOWNLOAD.
            </summary>
        </member>
        <member name="F:CoreAudioApi.TagCLSCTX.CLSCTX_RESERVED5">
            <summary>
            Reserved
            </summary>
        </member>
        <member name="F:CoreAudioApi.TagCLSCTX.CLSCTX_NO_CUSTOM_MARSHAL">
            <summary>
            Specify if you want the activation to fail if it uses custom marshalling.
            </summary>
        </member>
        <member name="F:CoreAudioApi.TagCLSCTX.CLSCTX_ENABLE_CODE_DOWNLOAD">
            <summary>
            Enables the downloading of code from the directory service or the Internet. This flag cannot be set at the same time as CLSCTX_NO_CODE_DOWNLOAD.
            </summary>
        </member>
        <member name="F:CoreAudioApi.TagCLSCTX.CLSCTX_NO_FAILURE_LOG">
            <summary>
            The CLSCTX_NO_FAILURE_LOG can be used to override the logging of failures in CoCreateInstanceEx.
            </summary>
        </member>
        <member name="F:CoreAudioApi.TagCLSCTX.CLSCTX_DISABLE_AAA">
            <summary>
            Disables activate-as-activator (AAA) activations for this activation only.
            This flag overrides the setting of the EOAC_DISABLE_AAA flag from the EOLE_AUTHENTICATION_CAPABILITIES enumeration.
            This flag cannot be set at the same time as CLSCTX_ENABLE_AAA. Any activation where a server process would be launched under the caller's
            identity is known as an activate-as-activator (AAA) activation.
            Disabling AAA activations allows an application that runs under a privileged account (such as LocalSystem) to help prevent its identity from being used to
            launch untrusted components. Library applications that use activation calls should always set this flag during those calls. This helps prevent the library
            application from being used in an escalation-of-privilege security attack. This is the only way to disable AAA activations in a library application because
            the EOAC_DISABLE_AAA flag from the EOLE_AUTHENTICATION_CAPABILITIES enumeration is applied only to the server process and not to the library application.
            </summary>
        </member>
        <member name="F:CoreAudioApi.TagCLSCTX.CLSCTX_ENABLE_AAA">
            <summary>
            Enables activate-as-activator (AAA) activations for this activation only.
            This flag overrides the setting of the EOAC_DISABLE_AAA flag from the EOLE_AUTHENTICATION_CAPABILITIES enumeration.
            This flag cannot be set at the same time as CLSCTX_DISABLE_AAA. Any activation where a server process would be launched under the caller's identity
            is known as an activate-as-activator (AAA) activation. Enabling this flag allows an application to transfer its identity to an activated component. 
            </summary>
        </member>
        <member name="F:CoreAudioApi.TagCLSCTX.CLSCTX_FROM_DEFAULT_CONTEXT">
            <summary>
            Begin this activation from the default context of the current apartment.
            </summary>
        </member>
        <member name="F:CoreAudioApi.TagCLSCTX.CLSCTX_ACTIVATE_32_BIT_SERVER">
            <summary>
            Activate or connect to a 32-bit version of the server; fail if one is not registered.
            </summary>
        </member>
        <member name="F:CoreAudioApi.TagCLSCTX.CLSCTX_ACTIVATE_64_BIT_SERVER">
            <summary>
            Activate or connect to a 64 bit version of the server; fail if one is not registered.
            </summary>
        </member>
        <member name="F:CoreAudioApi.TagCLSCTX.CLSCTX_ENABLE_CLOAKING">
            <summary>
            When this flag is specified, COM uses the impersonation token of the thread, if one is present, for the activation request made by the thread.
            When this flag is not specified or if the thread does not have an impersonation token, COM uses the process token of the thread's process
            for the activation request made by the thread.
            </summary>
        </member>
        <member name="F:CoreAudioApi.TagCLSCTX.CLSCTX_PS_DLL">
            <summary>
            TBD
            </summary>
        </member>
        <member name="F:CoreAudioApi.TagCLSCTX.CLSCTX_ALL">
            <summary>
            All
            </summary>
        </member>
        <member name="T:CoreAudioApi.Blob">
            <summary>
            Angaben zu einem Stück Speicher (BLOB), auf dessen Anfang der Pointer zeigt und dessen Länge in Bytes angegeben wird.
            </summary>
        </member>
        <member name="P:CoreAudioApi.Blob.Length">
            <summary>
            Größe des Datenblockes in Bytes, auf den der Pointer zeigt.
            </summary>
        </member>
        <member name="P:CoreAudioApi.Blob.Pointer">
            <summary>
            Pointer zu einem Datenarray (Bytes im Speicher).
            </summary>
        </member>
        <member name="T:CoreAudioApi.MediaSubFormate">
            <summary>
            Stellt Media Subtypen zur Verfügung (uuids.h und KsMedia.h).
            </summary>
        </member>
        <member name="M:CoreAudioApi.MediaSubFormate.GetName(System.Guid)">
            <summary>
            Gibt den Namen einer MediaSubFormat-Guid als String zurück.
            </summary>
            <param name="guid">
            MediaSubFormat-Guid
            </param>
            <returns>
            Name des MediaSubFormat.
            </returns>
        </member>
        <member name="P:CoreAudioApi.MediaSubFormate.PCM">
            <summary>PCM audio</summary>
        </member>
        <member name="P:CoreAudioApi.MediaSubFormate.IEEEFloat">
            <summary>IEEE floating-point audio</summary>
        </member>
        <member name="P:CoreAudioApi.MediaSubFormate.DTS">
            <summary>DTS</summary>
        </member>
        <member name="P:CoreAudioApi.MediaSubFormate.DolbyDigital">
            <summary>AC-3</summary>
        </member>
        <member name="P:CoreAudioApi.MediaSubFormate.WMA_PRO">
            <summary>Windows Media Audio (WMA) Pro</summary>
        </member>
        <member name="P:CoreAudioApi.MediaSubFormate.MPEG1">
            <summary>MPEG-1 (Layer 1 und 2)</summary>
        </member>
        <member name="P:CoreAudioApi.MediaSubFormate.MPEG3">
            <summary>MPEG-3 (Layer 3)</summary>
        </member>
        <member name="P:CoreAudioApi.MediaSubFormate.MPEG2">
            <summary>MPEG-2(multichannel)</summary>
        </member>
        <member name="P:CoreAudioApi.MediaSubFormate.AAC">
            <summary>Advanced Audio Coding (MPEG-2/4 AAC in ADTS)</summary>
        </member>
        <member name="P:CoreAudioApi.MediaSubFormate.ATRAC">
            <summary>Adaptive Transform Acoustic Coding (ATRAC)</summary>
        </member>
        <member name="P:CoreAudioApi.MediaSubFormate.OneBitAudio">
            <summary>One-Bit Audio</summary>
        </member>
        <member name="P:CoreAudioApi.MediaSubFormate.DolbyDigitalPlus">
            <summary>Dolby Digital Plus</summary>
        </member>
        <member name="P:CoreAudioApi.MediaSubFormate.DTS_HD">
            <summary>DTS-HD (24-bit, 96Khz)</summary>
        </member>
        <member name="P:CoreAudioApi.MediaSubFormate.DolbyMLP">
            <summary>MAT(MLP)– Meridian Lossless Packing (Dolby Digital True HD – 24-bit 196KHz/up to 18M bps, 8 channels)</summary>
        </member>
        <member name="P:CoreAudioApi.MediaSubFormate.DirectStreamTransport">
            <summary>Direct Stream Transport (DST)—lossless compressed DSD (Direct Stream Digital).</summary>
        </member>
        <member name="T:CoreAudioApi.WaveFormatExtensible">
            <summary>
            WaveFormatExtensible Struktur zur Verwaltung von Eigenschaften des erweiterten Wave-Format.
            </summary>
        </member>
        <member name="T:CoreAudioApi.WaveFormatEx">
            <summary>
            WaveFormatEx Struktur zur Verwaltung der Eigenschaften des Wave-Format.
            </summary>
        </member>
        <member name="M:CoreAudioApi.WaveFormatEx.#ctor">
            <summary>
            WaveFormatEx Struktur zur Verwaltung der Eigenschaften des PCM-Wave-Format.
            Der Konstruktor erzeugt eine PCM Struktur mit ExtraSize = 0 und den Werten SamplesPerSecond = 44100, BitsPerSample = 16 und Channels = 2.
            </summary>
        </member>
        <member name="M:CoreAudioApi.WaveFormatEx.#ctor(System.Int32,System.Int32,System.Int32)">
            <summary>
            WaveFormatEx Struktur zur Verwaltung der Eigenschaften des PCM-Wave-Format.
            Der Konstruktor erzeugt eine PCM Struktur mit ExtraSize = 0 und den gewünschten Werten für SamplesPerSecond, BitsPerSample und Channels.
            </summary>
            <param name="SamplesPerSecond">
            Anzahl der abzuspielenden Audioframes pro Sekunde.
            </param>
            <param name="BitsPerSample">
            Auflösung eines Samples in einem Kanal in Bit.
            </param>
            <param name="Channels">
            Anzahl der Kanäle.
            </param>
        </member>
        <member name="M:CoreAudioApi.WaveFormatEx.Clone">
            <summary>
            Erstellt ein neues Objekt, das eine flache Kopie der aktuellen Instanz des WaveFormatEx darstellt.
            </summary>
            <returns>
            Kopie der aktuellen Instanz des WaveFormatEx-Objektes.
            </returns>
        </member>
        <member name="M:CoreAudioApi.WaveFormatEx.ToString">
            <summary>
            Gibt die Haupteigenschaften des WaveFormatEx als Zeichenkette zurück.
            </summary>
            <returns>
            Haupteigenschaften des WaveFormatEx.
            </returns>
        </member>
        <member name="M:CoreAudioApi.WaveFormatEx.TestFormat">
            <summary>
            Gibt einen String zurück, der bei falschen Formatangaben Hinweise zu den Fehlern gibt.
            </summary>
            <returns>
            Fehlerangaben
            </returns>
        </member>
        <member name="P:CoreAudioApi.WaveFormatEx.WaveFormatTag">
            <summary>
            Gibt das Wave-Format an oder legt dieses fest. Wenn diese Struktur in eine WaveFormatExtensible Struktur eingebettet wird, muß waveFormatTag EXTENSIBLE sein.
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFormatEx.Channels">
            <summary>
            Gibt die Anzahl der Audiokanäle an oder legt diese fest.
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFormatEx.SamplesPerSecond">
            <summary>
            Gibt die Abtastrate in Audioframes pro Sekunde an oder legt diese fest.
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFormatEx.BytesPerSecond">
            <summary>
            Gibt die ungefähre Übertragungsrate in Bytes pro Sekunde an. Bei PCM ist BytesPerSecond = SamplesPerSecond * BlockAlign.
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFormatEx.BlockAlign">
            <summary>
            Gibt an, wie viele Datenbytes zu einem Audioframe gehören. Bei PCM oder EXTENSIBLE ist BlockAlign = Channels * BitsPerSample / 8.
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFormatEx.BitsPerSample">
            <summary>
            Gibt an oder legt fest, wie viele Bits ein Sample eines Kanales darstellen.
            Bei gesetztem EXTENSIBLE Tag muß BitsPerSample ein Vielfaches von 8 sein und stellt die Containergröße dar, nicht unbedingt die Samplegröße.
            Es kann ein 20 Bit Sample in einem BitsPerSample = 24 Bit großem Container liegen. 
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFormatEx.ExtraSize">
            <summary>
            Gibt die Größe von Daten in Bytes an oder legt diese fest, die an die WaveFormatEx-Struktur angehängt werden. Es wird bei nicht PCM-Formaten genutzt, um zusätzliche
            Formatangaben zu speichern. Sind keine zusätzlichen Daten vorhanden, muß ExtraSize = 0 sein. Bei PCM und nur bei PCM wird ExtraSize ignoriert.
            Wenn WaveFormatEx in eine WaveFormatExtensible-Struktur eingebettet ist, muß ExtraSize mindestens 22 betragen.
            </summary>
        </member>
        <member name="M:CoreAudioApi.WaveFormatExtensible.#ctor">
            <summary>
            WaveFormatExtensible Struktur zur Verwaltung von Eigenschaften des erweiterten PCM-Wave-Format.
            Der Konstruktor erzeugt eine EXTENSIBLE-Struktur mit ExtraSize = 22 und den Werten SamplesPerSecond = 44100, BitsPerSample = 16 und Channels = 2.
            </summary>
        </member>
        <member name="M:CoreAudioApi.WaveFormatExtensible.#ctor(System.Int32,System.Int32,System.Int32)">
            <summary>
            WaveFormatExtensible Struktur zur Verwaltung von Eigenschaften des erweiterten PCM-Wave-Format.
            Der Konstruktor erzeugt eine EXTENSIBLE-Struktur mit ExtraSize = 22 und den gewünschten Werten für SamplesPerSecond, BitsPerSample und Channels.
            </summary>
        </member>
        <member name="M:CoreAudioApi.WaveFormatExtensible.#ctor(System.Int32,System.Int32,System.Int32,System.Guid)">
            <summary>
            WaveFormatExtensible Struktur zur Verwaltung von Eigenschaften des erweiterten PCM-Wave-Format.
            Der Konstruktor erzeugt eine EXTENSIBLE-Struktur mit ExtraSize = 22 und den gewünschten Werten für SamplesPerSecond, BitsPerSample, Channels und MediaSubFormat.
            </summary>
            <param name="SamplesPerSecond">
            Anzahl der abzuspielenden Audioframes pro Sekunde.
            </param>
            <param name="BitsPerSample">
            Auflösung eines Samples in einem Kanal in Bit.
            </param>
            <param name="Channels">
            Anzahl der Kanäle.
            </param>
            <param name="MediaSubFormat">
            MediaSubFormat.
            </param>
        </member>
        <member name="M:CoreAudioApi.WaveFormatExtensible.MarshalFromPtr(System.IntPtr)">
            <summary>
            Erzeugt eine WaveFormatExtensible-Struktur aus Speicherdaten, die am Pointer beginnen.
            </summary>
            <param name="pointer">
            Pointer zu einer WaveFormatExtensible-Struktur.
            </param>
            <returns>
            WaveFormatExtensible-Struktur.
            </returns>
        </member>
        <member name="M:CoreAudioApi.WaveFormatExtensible.Clone">
            <summary>
            Erstellt ein neues Objekt, das eine flache Kopie der aktuellen Instanz des WaveFormatExtensible darstellt.
            </summary>
            <returns>
            Kopie der aktuellen Instanz des WaveFormatExtensible-Objektes.
            </returns>
        </member>
        <member name="M:CoreAudioApi.WaveFormatExtensible.ToString">
            <summary>
            Gibt die Haupteigenschaften des WaveFormatExtensible als Zeichenkette zurück.
            </summary>
            <returns>
            Haupteigenschaften des WaveFormatExtensible.
            </returns>
        </member>
        <member name="M:CoreAudioApi.WaveFormatExtensible.TestFormat">
            <summary>
            Gibt einen String zurück, der bei falschen Formatangaben Hinweise zu den Fehlern gibt.
            </summary>
            <returns>
            Fehlerangaben
            </returns>
        </member>
        <member name="P:CoreAudioApi.WaveFormatExtensible.BitsPerSamplesPerBlock">
            <summary>
            BitsPerSamplesPerBlock gibt entweder die Auflösung des Signales in Bits pro Sample oder die Anzahl der Samples pro komprimiertem Block an.
            Ist die Anzahl der Samples in einem komprimiertem Block nicht konstant, kann BitsPerSamplesPerBlock = 0 sein.
            Zeigt es die Auflösung an, ist WaveFormatEx.BitsPerSample die Containergröße und muß ein Vielfaches von 8 sein.
            BitsPerSamplesPerBlock dagegen kann jede Größe annehmen, die in den Container passt.
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFormatExtensible.ChannelMask">
            <summary>
            Die ChannelMask gibt an, welche Kanäle sich im Datenstrom befinden. Dabei stellt jedes Bit einen Kanal dar (LSB => links vorn; LSB+1 => rechts vorn ...).
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFormatExtensible.MediaSubFormat">
            <summary>
            Format, in dem die Audiodaten codiert sind. Diese Angabe ist ähnlich der in WaveFormatEx.FormatTag.
            </summary>
        </member>
        <member name="T:CoreAudioApi.AudioClockAdjustment">
            <summary>
            AudioClockAdjustment stellt eine Methode zur Einstellung der Abtastrate in einem kleinen Bereich in Share-Mode-Streams bereit. Er wird aus der
            AudioClockAdjustment-Eigenschaft eines AudioClient gewonnen. AudioClockAdjustment muß nach der Verwendung mit Dispose vernichtet werden.
            </summary>
        </member>
        <member name="M:CoreAudioApi.AudioClockAdjustment.#ctor(CoreAudioApi.IAudioClockAdjustment)">
            <summary>
            AudioClockAdjustment stellt eine Methode zur Einstellung der Abtastrate in einem kleinen Bereich in Share-Mode-Streams bereit. Er wird aus der
            AudioClockAdjustment-Eigenschaft eines AudioClient gewonnen. AudioClockAdjustment muß nach der Verwendung mit Dispose vernichtet werden.
            </summary>
            <param name="iAudioClockAdjustment">
            Ein IAudioClockAdjustment aus einem AudioClient.
            </param>
        </member>
        <member name="M:CoreAudioApi.AudioClockAdjustment.SetSampleRate(System.Single)">
            <summary>
            SetSampleRate ändert die Samplerate eines Streames in einem engen Bereich um den mit AudioClient.Initialize() vereinbarten Wert.
            Der Stream muß mit AudioClientShareMode.Shared initialisiert worden sein.
            </summary>
            <param name="SamplesPerSecond">
            Die neue Samplerate in Audioframes pro Sekunde.
            </param>
        </member>
        <member name="M:CoreAudioApi.AudioClockAdjustment.Dispose">
            <summary>
            Gibt die Ressourcen von AudioClockAdjustment frei.
            </summary>
        </member>
        <member name="M:CoreAudioApi.AudioClockAdjustment.Dispose(System.Boolean)">
            <summary>
            Gibt die Ressourcen von AudioClockAdjustment frei.
            </summary>
            <param name="disposing">
            true, es werden auch verwaltete Objekte frei gegeben.
            false, wenn die Methode aus einem Destructor aufgerufen werden soll.
            </param>
        </member>
        <member name="M:CoreAudioApi.AudioClockAdjustment.Finalize">
            <summary>
            Destructor
            </summary>
        </member>
        <member name="P:CoreAudioApi.AudioClockAdjustment.Disposed">
            <summary>
            Ruft ab, ob das Element frei gegeben wurde.
            </summary>
        </member>
        <member name="T:CoreAudioApi.AudioClient">
            <summary>
            AudioClient stellt Methoden zum Abspielen und Aufnehmen von Sound zur Verfügung. Er stellt im Share-Mode einen Audio-Stream zwischen der Anwendung und der Audio-Engine
            bereit. Im Exclusive-Mode erzeugt er einen einen Puffer im Audio-Enpoint. Ein AudioClient-Objekt erhält man aus der AudioClient-Eigenschaft der MMDevice-Klasse. Der
            AudioClient muß nach seiner Verwendung mit Dispose vernichtet werden.
            </summary>
        </member>
        <member name="M:CoreAudioApi.AudioClient.#ctor(CoreAudioApi.IAudioClient)">
            <summary>
            AudioClient stellt Methoden zum Abspielen und Aufnehmen von Sound zur Verfügung. Er stellt im Share-Mode einen Audio-Stream zwischen der Anwendung und der Audio-Engine
            bereit. Im Exclusive-Mode erzeugt er einen einen Puffer im Audio-Enpoint. Ein AudioClient-Objekt erhält man aus der AudioClient-Eigenschaft der MMDevice-Klasse. Der
            AudioClient muß nach seiner Verwendung mit Dispose vernichtet werden.
            </summary>
            <param name="iAudioClient">
            IAudioClient aus einem MMDevice.
            </param>
        </member>
        <member name="M:CoreAudioApi.AudioClient.Initialize(CoreAudioApi.AudioClientShareMode,CoreAudioApi.AudioClientStreamFlags,System.Int64,System.Int64,CoreAudioApi.WaveFormatExtensible,System.Guid)">
            <summary>
            Initialisiert den AudioClient.
            </summary>
            <param name="shareMode">
            Legt den ShareMode fest.
            </param>
            <param name="streamFlags">
            Legt die StreamFlags fest. Es können mehrere ODER '|' verknüpft werden.
            </param>
            <param name="bufferDuration">
            Bestimmt die Zeitdauer der gepufferten Audiodaten in 100 ns Einheiten. Im eventgetriebenen Exclusive-Mode kann mit der Methode AudioClient.AlignedDuration() ein
            ausgerichteter Wert für bufferDuration erzeugt werden.
            </param>
            <param name="periodicity">
            Bestimmt die Periodendauer des Pufferprozesses in 100 ns Einheiten. Periodicity muß im Shared-Mode immer 0 sein. Im Exclusive-Mode darf periodicity maximal 2 s betragen
            und muß in diesem Modus gleich bufferDuration sein, wenn AudioClientStreamFlags.EventCallback festgelegt wurde. Im eventgetriebenen Exclusive-Mode kann mit der Methode
            AudioClient.AlignedDuration() ein ausgerichteter Wert für bufferDuration erzeugt werden.
            </param>
            <param name="waveFormatExtensible">
            Eine WaveFormatExtensible Struktur legt die Audioeigenschaften fest.
            </param>
            <param name="audioSessionGuid">
            Die Audio Session GUID bestimmt, zu welcher Audiosession der Client gehört. Bei Guid.Empty wird eine neue Session erstellt.
            </param>
        </member>
        <member name="M:CoreAudioApi.AudioClient.IsFormatSupported(CoreAudioApi.AudioClientShareMode,CoreAudioApi.WaveFormatExtensible)">
            <summary>
            Überprüft, ob das übergebene WaveFormatEx vom Gerät verarbeitet werden kann.
            </summary>
            <param name="shareMode">
            ShareMode, der überprüft werden soll.
            </param>
            <param name="waveFormatExtensible">
            Zu prüfendes Format.
            </param>
            <returns>
            true: Format wird unterstützt, sonst false.
            </returns>
        </member>
        <member name="M:CoreAudioApi.AudioClient.IsFormatSupported(CoreAudioApi.AudioClientShareMode,CoreAudioApi.WaveFormatExtensible,CoreAudioApi.WaveFormatExtensible@)">
            <summary>
            Überprüft, ob das übergebene WaveFormatEx vom Gerät verarbeitet werden kann.
            </summary>
            <param name="shareMode">
            ShareMode, der überprüft werden soll.
            </param>
            <param name="waveFormatExtensible">
            Zu prüfendes Format.
            </param>
            <param name="waveFormatExtensibleOut">
            Gibt eine WaveFormatExtensible Struktur mit dem am besten passenden Format oder null zurück.
            </param>
            <returns>
            true: Format wird unterstützt, sonst false.
            </returns>
        </member>
        <member name="M:CoreAudioApi.AudioClient.SetEventHandle(System.Threading.EventWaitHandle)">
            <summary>
            Setzt das EventWaitHandle, das ausgelöst wird, wenn ein Audiodatenpaket im Puffer zur Verarbeitung durch den Client bereit ist.
            Dazu muß bei der Initialisierung des AudioClient AudioClientStreamFlags.EventCallback gesetzt sein. Das Audiogerät muß den EventDrivenMode unterstützen.
            </summary>
            <param name="eventWaitHandle">
            EventWaitHandle, welches den Thread zur Bearbeitung der Pufferdaten steuert.
            </param>
        </member>
        <member name="M:CoreAudioApi.AudioClient.Start">
            <summary>
            Startet den Audiostream. Start darf nicht vor der Initialisierung aufgerufen werden!
            </summary>
        </member>
        <member name="M:CoreAudioApi.AudioClient.Stop">
            <summary>
            Stopt  den Audiostream. Stop darf nicht vor der Initialisierung aufgerufen werden!
            </summary>
        </member>
        <member name="M:CoreAudioApi.AudioClient.Reset">
            <summary>
            Setzt den gestopten Audiostream zurück. Der Stream muß gestopt sein.
            Reset darf nicht vor der Initialisierung aufgerufen werden!
            </summary>
        </member>
        <member name="M:CoreAudioApi.AudioClient.NumberFramesToDuration(System.Int32,System.Int32)">
            <summary>
            Errechnet die Spielzeit in Einheiten von 100 ns einer Anzahl von Audioframes bei einer bestimmmten Abtastrate. (Rundung nach Microsoft)
            </summary>
            <param name="NumberAudioFrames">
            Anzahl von Audioframes, deren Dauer errechnet werden soll.
            </param>
            <param name="SamplesPerSecond">
            Abtastrate
            </param>
            <returns>
            Zeitdauer Audioframes in Einheiten von 100 ns.
            </returns>
        </member>
        <member name="M:CoreAudioApi.AudioClient.DurationToNumberFrames(System.Int64,System.Int32)">
            <summary>
            Errechnet, wie viele Audioframes für eine gegebene Spielzeit in Einheiten von 100 ns und einer bestimmmten Abtastrate benötigt werden.
            </summary>
            <param name="Duration">
            Spielzeit einer Gruppe von Audioframes in Einheiten von 100 ns.
            </param>
            <param name="SamplesPerSecond">
            Abtastrate
            </param>
            <returns>
            Anzahl der Audioframes.
            </returns>
        </member>
        <member name="M:CoreAudioApi.AudioClient.AlignedDuration(System.Int64,CoreAudioApi.WaveFormatExtensible)">
            <summary>
            Berechnet aus einer Spielzeit in Einheiten von 100 ns eine neue Spielzeit in Einheiten von 100 ns, wobei diese in einem Raster vorliegt, in dem die
            AudioClient.Initialize Methode erfolgreich ausgeführt werden kann, wenn der AudioClient im Exclusive-Mode und eventgetrieben arbeiten soll.
            </summary>
            <param name="Duration">
            Spielzeit einer Gruppe von Audioframes in Einheiten von 100 ns.
            </param>
            <param name="waveFormatExtensible">
            WaveFormatExtensible, mit dem AudioClient.Initialize() ausgeführt werden soll.
            </param>
            <returns>
            Neue ausgerichtete Spielzeit.
            </returns>
        </member>
        <member name="M:CoreAudioApi.AudioClient.Dispose">
            <summary>
            Gibt die Ressourcen des AudioClient frei.
            </summary>
        </member>
        <member name="M:CoreAudioApi.AudioClient.Dispose(System.Boolean)">
            <summary>
            Gibt die Ressourcen des AudioClient frei.
            </summary>
            <param name="disposing">
            true, es werden auch verwaltete Objekte frei gegeben.
            false, wenn die Methode aus einem Destructor aufgerufen werden soll.
            </param>
        </member>
        <member name="M:CoreAudioApi.AudioClient.Finalize">
            <summary>
            Destructor
            </summary>
        </member>
        <member name="P:CoreAudioApi.AudioClient.Disposed">
            <summary>
            Ruft ab, ob das Element frei gegeben wurde.
            </summary>
        </member>
        <member name="P:CoreAudioApi.AudioClient.MixFormat">
            <summary>
            Gibt das Wave-Format an, welches im Shared-Mode Betrieb von der Audioengine verarbeitet wird.
            </summary>
        </member>
        <member name="P:CoreAudioApi.AudioClient.BufferSize">
            <summary>
            Gibt die Anzahl der Audioframes an, die im Puffer maximal gespeichert werden können. BufferSize darf nicht vor der Initialisierung abgerufen werden!
            </summary>
        </member>
        <member name="P:CoreAudioApi.AudioClient.StreamLatency">
            <summary>
            Gibt die Latenz des Puffers in 100 ns Einheiten an. Es bestimmt die minimale Anzahl von Audioframes, die in einem Puffervorgang, ohne Tonaussetzer zu provozieren,
            verarbeitet werden können. StreamLatency darf nicht vor der Initialisierung abgerufen werden!
            </summary>
        </member>
        <member name="P:CoreAudioApi.AudioClient.CurrentPadding">
            <summary>
            Gibt an, wie viele noch nicht gelesenen Audioframes im Puffer liegen. Beim Capturing gibt es an, wie viele neue Audioframes sicher ausgelesen werden können.
            GetCurrentPadding darf nicht vor der Initialisierung abgerufen werden!
            </summary>
        </member>
        <member name="P:CoreAudioApi.AudioClient.DefaultDevicePeriod">
            <summary>
            Gibt die Zeitdauer in 100 ns Einheiten an, welche die Audioengine für die periodische Abarbeitung eines Shared-Mode Streames benötigt.
            </summary>
        </member>
        <member name="P:CoreAudioApi.AudioClient.MinimumDevicePeriod">
            <summary>
            Gibt die Zeitdauer in 100 ns Einheiten an, welche mindestens für die periodische Abarbeitung eines Exclusive-Mode Streames benötigt wird.
            </summary>
        </member>
        <member name="P:CoreAudioApi.AudioClient.RenderClient">
            <summary>
            Gibt einen AudioRenderClient zurück. RenderClient darf nicht vor der Initialisierung abgerufen werden!
            </summary>
        </member>
        <member name="P:CoreAudioApi.AudioClient.CaptureClient">
            <summary>
            Gibt einen AudioCaptureClient zurück. CaptureClient darf nicht vor der Initialisierung abgerufen werden!
            </summary>
        </member>
        <member name="P:CoreAudioApi.AudioClient.Clock">
            <summary>
            Gibt eine AudioClock zurück. Clock darf nicht vor der Initialisierung abgerufen werden!
            </summary>
        </member>
        <member name="P:CoreAudioApi.AudioClient.ClockAdjustment">
            <summary>
            Gibt ein AudioClockAdjustment Objekt zurück. ClockAdjustment darf nicht vor der Initialisierung abgerufen werden!
            </summary>
        </member>
        <member name="T:CoreAudioApi.Role">
            <summary>
            Der Role Enumerator definiert Konstanten, welche die Rolle eines Audiogerätes festlegen.
            </summary>
        </member>
        <member name="F:CoreAudioApi.Role.Console">
            <summary>
            Spiele, Systemsounds und Sprachkommandos.
            </summary>
        </member>
        <member name="F:CoreAudioApi.Role.Multimedia">
            <summary>
            Musik, Filmton, Unterhaltung und Life Musikaufnahme.
            </summary>
        </member>
        <member name="F:CoreAudioApi.Role.Communications">
            <summary>
            Sprachkommunikation (Unterhaltung mit anderen Personen).
            </summary>
        </member>
        <member name="F:CoreAudioApi.Role.RoleEnumCount">
            <summary>
            Die Anzahl der Elemente in diesem Enumerator ohne das RoleEnumCount-Mitglied.
            </summary>
        </member>
        <member name="T:CoreAudioApi.MMNotificationClient">
            <summary>
            Stellt Ereignisse bereit, die von den im System enthaltenen Audiogeräten ausgelöst werden. Der MMNotificationClient muß mit MMDeviceEnumerator.AddEndpointNotifications
            registriert werden.
            </summary>
        </member>
        <member name="T:CoreAudioApi.IMMNotificationClient">
            <summary>
            The IMMNotificationClient interface provides notifications when an audio endpoint device is added or removed, when the state or properties of an endpoint device change,
            or when there is a change in the default role assigned to an endpoint device. Unlike the other interfaces in this section,
            which are implemented by the MMDevice API system component, an MMDevice API client implements the IMMNotificationClient interface.
            To receive notifications, the client passes a pointer to its IMMNotificationClient interface instance as a parameter to the
            IMMDeviceEnumerator.RegisterEndpointNotificationCallback method.
            </summary>
        </member>
        <member name="M:CoreAudioApi.IMMNotificationClient.OnDeviceStateChanged(System.String,CoreAudioApi.DeviceState)">
            <summary>
            The OnDeviceStateChanged method indicates that the state of an audio endpoint device has changed.
            </summary>
            <param name="deviceId">
            Pointer to the endpoint ID string that identifies the audio endpoint device.
            This parameter points to a null-terminated, wide-character string containing the endpoint ID.
            The string remains valid for the duration of the call.
            </param>
            <param name="newDeviceState">
            Specifies the new state of the endpoint device. The value of this parameter is one of the following DeviceState constants.
            </param>
        </member>
        <member name="M:CoreAudioApi.IMMNotificationClient.OnDeviceAdded(System.String)">
            <summary>
            Called by the IMMDeviceEnumerator object when a new Endpoint device is added to the system.
            Clients should check the state of the Endpoint before using it. It is generally more useful to monitor state changes than Endpoint additions and removals
            </summary>
            <param name="deviceId">
            Pointer to the endpoint ID string that identifies the audio endpoint device.
            This parameter points to a null-terminated, wide-character string containing the endpoint ID. The string remains valid for the duration of the call. 
            </param>
        </member>
        <member name="M:CoreAudioApi.IMMNotificationClient.OnDeviceRemoved(System.String)">
            <summary>
            Called by the IMMDeviceEnumerator object when an Endpoint device is removed from the system.
            It is generally more useful to monitor state changes than Endpoint additions and removals.
            </summary>
            <param name="deviceId">
            Pointer to the endpoint ID string that identifies the audio endpoint device.
            This parameter points to a null-terminated, wide-character string containing the endpoint ID.
            The string remains valid for the duration of the call. 
            </param>
        </member>
        <member name="M:CoreAudioApi.IMMNotificationClient.OnDefaultDeviceChanged(CoreAudioApi.DataFlow,CoreAudioApi.Role,System.String)">
            <summary>
            The OnDefaultDeviceChanged method notifies the client that the default audio endpoint device for a particular device role has changed.
            </summary>
            <param name="dataFlow">
            The data-flow direction of the endpoint device. This parameter is set to one of the following DataFlow enumeration.
            The data-flow direction for a rendering device is Render. The data-flow direction for a capture device is Capture.
            </param>
            <param name="role">
            The device role of the audio endpoint device. This parameter is set to one of the following Role enumeration.
            </param>
            <param name="defaultDeviceId">
            Pointer to the endpoint ID string that identifies the audio endpoint device. This parameter points to a null-terminated,
            wide-character string containing the endpoint ID. The string remains valid for the duration of the call.
            If the user has removed or disabled the default device for a particular role, and no other device is available to assume that role,
            then defaultDeviceId is NULL. 
            </param>
        </member>
        <member name="M:CoreAudioApi.IMMNotificationClient.OnPropertyValueChanged(System.String,CoreAudioApi.PropertyKey)">
            <summary>
            The OnPropertyValueChanged method indicates that the value of a property belonging to an audio endpoint device has changed.
            </summary>
            <param name="deviceId">
            Pointer to the endpoint ID string that identifies the audio endpoint device.
            This parameter points to a null-terminated, wide-character string that contains the endpoint ID.
            The string remains valid for the duration of the call.
            </param>
            <param name="propertyKey">
            The Property that was modified. A PropertyKey structure that specifies the property. The structure contains the property GUID and an index identifying a property within
            the set. The structure is passed by value. It remains valid for the duration of the call.
            </param>
        </member>
        <member name="M:CoreAudioApi.MMNotificationClient.OnDeviceStateChanged(System.String,CoreAudioApi.DeviceState)">
            <summary>
            Wird ausgelöst, wenn sich der Zustand eines Audiogerätes geändert hat.
            </summary>
            <param name="deviceId">
            ID des geänderten Soundgerätes.
            </param>
            <param name="newDeviceState">
            Neuer Zustand des Soundgerätes.
            </param>
        </member>
        <member name="M:CoreAudioApi.MMNotificationClient.OnDeviceAdded(System.String)">
            <summary>
            Wird ausgelöst, wenn ein Audiogerät zum System hinzugefügt wurde.
            </summary>
            <param name="deviceId">
            ID des Soundgerätes, welches zum System hinzugefügt wurde.
            </param>
        </member>
        <member name="M:CoreAudioApi.MMNotificationClient.OnDeviceRemoved(System.String)">
            <summary>
            Wird ausgelöst, wenn ein Audiogerät aus dem System entfernt wurde.
            </summary>
            <param name="deviceId">
            ID des Soundgerätes, welches vom System entfernt wurde.
            </param>
        </member>
        <member name="M:CoreAudioApi.MMNotificationClient.OnDefaultDeviceChanged(CoreAudioApi.DataFlow,CoreAudioApi.Role,System.String)">
            <summary>
            Wird ausgelöst, wenn ein anderes Audiogerät zum Standardgerät erklärt wurde. Dabei wird für jedes beteiligte Gerät ein Ereignis ausgelöst.
            </summary>
            <param name="dataFlow">
            Flußrichtung der Audiodaten des neuen Standardsoundgerätes.
            </param>
            <param name="role">
            Rolle des neuen Standardsoundgerätes.
            </param>
            <param name="defaultDeviceId">
            ID des neuen Standardsoundgerätes.
            </param>
        </member>
        <member name="M:CoreAudioApi.MMNotificationClient.OnPropertyValueChanged(System.String,CoreAudioApi.PropertyKey)">
            <summary>
            Wird ausgelöst, wenn sich eine Eigenschaft eines Audiogerätes geändert hat.
            </summary>
            <param name="deviceId">
            ID des Soundgerätes, dessen Eigenschaften sich geändert haben.
            </param>
            <param name="propertyKey">
            PropertyKey des Soundgerätes, dessen Eigenschaften sich geändert haben.
            </param>
            <returns>
            </returns>
        </member>
        <member name="E:CoreAudioApi.MMNotificationClient.DeviceStateChanged">
            <summary>
            Wird ausgelöst, wenn sich der Aktivitätszustand eines Audiogerätes geändert hat.
            </summary>
        </member>
        <member name="E:CoreAudioApi.MMNotificationClient.DeviceAdded">
            <summary>
            Wird ausgelöst, wenn ein Audiogerät zum System hinzugefügt wurde.
            </summary>
        </member>
        <member name="E:CoreAudioApi.MMNotificationClient.DeviceRemoved">
            <summary>
            Wird ausgelöst, wenn ein Audiogerät aus dem System entfernt wurde.
            </summary>
        </member>
        <member name="E:CoreAudioApi.MMNotificationClient.DefaultDeviceChanged">
            <summary>
            Wird ausgelöst, wenn ein anderes Audiogerät zum Standardgerät erklärt wurde.
            </summary>
        </member>
        <member name="E:CoreAudioApi.MMNotificationClient.PropertyValueChanged">
            <summary>
            Wird ausgelöst, wenn sich eine Eigenschaft eines Audiogerätes geändert hat.
            </summary>
        </member>
        <member name="T:CoreAudioApi.MMNotificationClient.DeviceStateChangedEvent">
            <summary>
            Wird ausgelöst, wenn sich der Aktivitätszustand eines Audiogerätes geändert hat.
            </summary>
            <param name="sender">
            Auslöser des Ereignisses.
            </param>
            <param name="e">
            Angaben zum Ereignis.
            </param>
        </member>
        <member name="T:CoreAudioApi.MMNotificationClient.DeviceAddedEvent">
            <summary>
            Wird ausgelöst, wenn ein Audiogerät zum System hinzugefügt wurde.
            </summary>
            <param name="sender">
            Auslöser des Ereignisses.
            </param>
            <param name="e">
            Angaben zum Ereignis.
            </param>
        </member>
        <member name="T:CoreAudioApi.MMNotificationClient.DeviceRemovedEvent">
            <summary>
            Wird ausgelöst, wenn ein Audiogerät aus dem System entfernt wurde.
            </summary>
            <param name="sender">
            Auslöser des Ereignisses.
            </param>
            <param name="e">
            Angaben zum Ereignis.
            </param>
        </member>
        <member name="T:CoreAudioApi.MMNotificationClient.DefaultDeviceChangedEvent">
            <summary>
            Wird ausgelöst, wenn ein anderes Audiogerät zum Standardgerät erklärt wurde. Dabei wird für jedes beteiligte Gerät ein Ereignis ausgelöst.
            </summary>
            <param name="sender">
            Auslöser des Ereignisses.
            </param>
            <param name="e">
            Angaben zum Ereignis.
            </param>
        </member>
        <member name="T:CoreAudioApi.MMNotificationClient.PropertyValueChangedEvent">
            <summary>
            Wird ausgelöst, wenn sich eine Eigenschaft eines Audiogerätes geändert hat.
            </summary>
            <param name="sender">
            Auslöser des Ereignisses.
            </param>
            <param name="e">
            Angaben zum Ereignis.
            </param>
        </member>
        <member name="T:CoreAudioApi.DeviceAddRemoveEventArgs">
            <summary>
            Enthält Daten über das ausgelöste Ereignis.
            </summary>
        </member>
        <member name="M:CoreAudioApi.DeviceAddRemoveEventArgs.#ctor(System.String)">
            <summary>
            Enthält Daten über das ausgelöste MMNotificationEvent.
            </summary>
            <param name="DeviceID">
            Die ID des Audiogerätes, welches das Ereignis ausgelöst hat.
            </param>
        </member>
        <member name="P:CoreAudioApi.DeviceAddRemoveEventArgs.DeviceID">
            <summary>
            Die ID des Audiogerätes, welches das Ereignis ausgelöst hat.
            </summary>
        </member>
        <member name="T:CoreAudioApi.DeviceStateChangeEventArgs">
            <summary>
            Enthält Daten über das ausgelöste Ereignis.
            </summary>
        </member>
        <member name="M:CoreAudioApi.DeviceStateChangeEventArgs.#ctor(System.String,CoreAudioApi.DeviceState)">
            <summary>
            Enthält Daten über das ausgelöste MMNotificationEvent.
            </summary>
            <param name="DeviceID">
            Die ID des Audiogerätes, welches das Ereignis ausgelöst hat.
            </param>
            <param name="NewDeviceState">
            Der Zustand, in den das Audiogeräte gewechselt ist.
            </param>
        </member>
        <member name="P:CoreAudioApi.DeviceStateChangeEventArgs.DeviceID">
            <summary>
            Die ID des Audiogerätes, welches das Ereignis ausgelöst hat.
            </summary>
        </member>
        <member name="P:CoreAudioApi.DeviceStateChangeEventArgs.NewDeviceState">
            <summary>
            Der Zustand, in den das Audiogeräte gewechselt ist.
            </summary>
        </member>
        <member name="T:CoreAudioApi.DefaultDeviceChangedEventArgs">
            <summary>
            Enthält Daten über das ausgelöste Ereignis.
            </summary>
        </member>
        <member name="M:CoreAudioApi.DefaultDeviceChangedEventArgs.#ctor(System.String,CoreAudioApi.DataFlow,CoreAudioApi.Role)">
            <summary>
            Enthält Daten über das ausgelöste MMNotificationEvent.
            </summary>
            <param name="DeviceID">
            Die ID des Audiogerätes, welches das Ereignis ausgelöst hat.
            </param>
            <param name="DataFlow">
            Die Flußrichtung der Audiodaten nach dem Ereignis.
            </param>
            <param name="Role">
            Die Rolle, die das Audiogerät nach dem Ereignis hat.
            </param>
        </member>
        <member name="P:CoreAudioApi.DefaultDeviceChangedEventArgs.DeviceID">
            <summary>
            Die ID des Audiogerätes, welches das Ereignis ausgelöst hat.
            </summary>
        </member>
        <member name="P:CoreAudioApi.DefaultDeviceChangedEventArgs.DataFlow">
            <summary>
            Die Flußrichtung der Audiodaten nach dem Ereignis.
            </summary>
        </member>
        <member name="P:CoreAudioApi.DefaultDeviceChangedEventArgs.Role">
            <summary>
            Die Rolle, die das Audiogerätes nach dem Ereignis hat.
            </summary>
        </member>
        <member name="T:CoreAudioApi.PropertyChangedEventArgs">
            <summary>
            Enthält Daten über das ausgelöste Ereignis.
            </summary>
        </member>
        <member name="M:CoreAudioApi.PropertyChangedEventArgs.#ctor(System.String,CoreAudioApi.PropertyKey)">
            <summary>
            Enthält Daten über das ausgelöste MMNotificationEvent.
            </summary>
            <param name="DeviceID">
            Die ID des Audiogerätes, welches das Ereignis ausgelöst hat.
            </param>
            <param name="NewPropertyKey">
            Eine PropertyKey-Struktur, die die geänderte Eigenschaft enthält.
            </param>
        </member>
        <member name="P:CoreAudioApi.PropertyChangedEventArgs.DeviceID">
            <summary>
            Die ID des Audiogerätes, welches das Ereignis ausgelöst hat.
            </summary>
        </member>
        <member name="P:CoreAudioApi.PropertyChangedEventArgs.PropertyKey">
            <summary>
            Eine PropertyKey-Struktur, die die geänderte Eigenschaft enthält.
            </summary>
        </member>
        <member name="T:CoreAudioApi.AudioEndpointVolumeCallback">
            <summary>
            AudioEndpointVolumeCallback ermöglicht die Auswertung von Ereignissen, die ausgelöst werden, wenn Anwendungen die Pegeleinstellungen des Audio-Streams zu oder von einem
            Endpoint verändern. Die Pegelwerte liegen zwischen 0.0 und 1.0.
            </summary>
        </member>
        <member name="T:CoreAudioApi.IAudioEndpointVolumeCallback">
            <summary>
            The IAudioEndpointVolumeCallback interface provides notifications of changes in the volume level and muting state of an audio endpoint device. Unlike the other interfaces in
            this section, which are implemented by the WASAPI system component, an EndpointVolumeAPI client implements the IAudioEndpointVolumeCallback interface. To receive event
            notifications, the client passes a pointer to its IAudioEndpointVolumeCallback interface to the IAudioEndpointVolume.RegisterControlChangeNotify method.
            If an audio endpoint device implements hardware volume and mute controls, the IAudioEndpointVolume interface uses the hardware controls to manage the device's volume.
            Otherwise, the IAudioEndpointVolume interface implements volume and mute controls in software, transparently to the client.
            If a device has hardware volume and mute controls, changes made to the volume and mute settings through the methods in the preceding list affect the device's volume in both
            shared mode and exclusive mode. If a device lacks hardware volume and mute controls, changes made to the software volume and mute controls through these methods affect the
            device's volume in shared mode, but not in exclusive mode. In exclusive mode, the client and the device exchange audio data directly, bypassing the software controls.
            The methods in the interface must be nonblocking. The client should never wait on a synchronization object during an event callback. The client should never call the
            IAudioEndpointVolume.UnregisterControlChangeNotify method during an event callback. The client should never release the final reference on an EndpointVolume API object
            during an event callback.
            </summary>
        </member>
        <member name="M:CoreAudioApi.IAudioEndpointVolumeCallback.OnNotify(System.IntPtr)">
            <summary>
            The OnNotify method notifies the client that the volume level or muting state of the audio endpoint device has changed.
            </summary>
            <param name="audioVolumeNotificationDataPointer">
            Pointer to the volume-notification data. This parameter points to a structure of type AudioVolumeNotificationData.
            </param>
        </member>
        <member name="M:CoreAudioApi.AudioEndpointVolumeCallback.OnNotify(System.IntPtr)">
            <summary>
            Teilt einem Client mit, daß eine Anwendung die Pegeleinstellungen des Audio-Streams zu oder von einem Endpoint verändert hat.
            </summary>
            <param name="audioVolumeNotificationDataPointer">
            Pointer zu einer AudioVolumeNotificationData Struktur.
            </param>
        </member>
        <member name="E:CoreAudioApi.AudioEndpointVolumeCallback.AudioVolumeChanged">
            <summary>
            Wird ausgelöst, wenn Anwendungen die Pegeleinstellungen des Audio-Streams zu oder von einem Endpoint verändern.
            </summary>
        </member>
        <member name="T:CoreAudioApi.AudioEndpointVolumeCallback.AudioVolumeChangedEvent">
            <summary>
            Wird ausgelöst, wenn Anwendungen die Pegeleinstellungen des Audio-Streams zu oder von einem Endpoint verändern.
            </summary>
            <param name="sender">
            Auslöser des Ereignisses.
            </param>
            <param name="e">
            Angaben zum Ereignis.
            </param>
        </member>
        <member name="T:CoreAudioApi.AudioEndpointVolumeEventArgs">
            <summary>
            Enthält Daten über das ausgelöste AudioEndpointVolumeEvent.
            </summary>
        </member>
        <member name="M:CoreAudioApi.AudioEndpointVolumeEventArgs.GetChannelVolume(System.Int32)">
            <summary>
            Gibt das Volume eines einzelnen Kanales im Audio-Stream von oder zu einem Audio-Endpoint an.
            Dieser Wert liegt zwischen 0.0 und 1.0.
            </summary>
            <param name="channel">
            Kanal, dessen Volume-Wert gewünscht ist.
            </param>
            <returns>
            Volume-Wert des Kanales.
            </returns>
        </member>
        <member name="M:CoreAudioApi.AudioEndpointVolumeEventArgs.#ctor(System.Guid,System.Boolean,System.Single,System.Int32,System.Single[])">
            <summary>
            Enthält Daten über das ausgelöste AudioEndpointVolumeEvent.
            </summary>
            <param name="GuidEventContext">
            Gibt die Guid zurück, welche der Methode übergeben wurde, die das Ereignis ausgelöst hat.
            </param>
            <param name="Muted">
            Gibt an, ob der Audio-Streame stumm geschaltet (true) ist oder nicht.
            </param>
            <param name="MasterVolume">
            Gibt das geänderte Mastervolume an. Dieser Wert liegt zwischen 0.0 und 1.0.
            </param>
            <param name="Channels">
            Gibt die Anzahl der Kanäle im Audiostream an.
            </param>
            <param name="ChannelVolumes">
            Gibt das Volume der einzelnen Kanäle im Audiostream an. Diese Werte liegen zwischen 0.0 und 1.0.
            </param>
        </member>
        <member name="M:CoreAudioApi.AudioEndpointVolumeEventArgs.#ctor(CoreAudioApi.AudioVolumeNotificationData,System.Single[])">
            <summary>
            Enthält Daten über das ausgelöste AudioEndpointVolumeEvent.
            </summary>
            <param name="audioVolumeNotificationData">
            Struktur, welche Angaben zur Pegeleinstellung des Audio-Streams enthält.
            Die enthaltenen Pegelwerte liegen zwischen 0.0 und 1.0.
            </param>
            <param name="ChannelVolumes">
            Gibt das Volume der einzelnen Kanäle im Audio-Stream an. Diese Werte liegen zwischen 0.0 und 1.0.
            </param>
        </member>
        <member name="P:CoreAudioApi.AudioEndpointVolumeEventArgs.GuidEventContext">
            <summary>
            Gibt die Guid zurück, welche der Methode übergeben wurde, die das Ereignis ausgelöst hat.
            </summary>
        </member>
        <member name="P:CoreAudioApi.AudioEndpointVolumeEventArgs.Muted">
            <summary>
            Gibt an, ob der Audio-Streame stumm geschaltet (true) ist oder nicht.
            </summary>
        </member>
        <member name="P:CoreAudioApi.AudioEndpointVolumeEventArgs.MasterVolume">
            <summary>
            Gibt das geänderte Mastervolume an. Dieser Wert liegt zwischen 0.0 und 1.0.
            </summary>
        </member>
        <member name="P:CoreAudioApi.AudioEndpointVolumeEventArgs.Channels">
            <summary>
            Gibt die Anzahl der Kanäle im Audiostream an.
            </summary>
        </member>
        <member name="T:CoreAudioApi.MMDeviceEnumeratorObject">
            <summary>
            Aktiviert ein IMMDeviceEnumerator-Objekt und damit die CoraAudioApi (ole32.dll).
            </summary>
        </member>
        <member name="T:CoreAudioApi.ToByteConverter">
            <summary>
            Stellt eine Methode bereit, die zweidimensionale, kanalgetrennte Double-Arrays in eindimensionale, kanalweise verschachtelte Byte-Arrays, wie sie für Soundgeräte
            oder -dateien benötigt werden, umwandelt. Der Wertebereich wird bei IEEEFloat-Formaten durch das Zielformat begrenzt. Eine Amplitude von 1.0 entspricht dem Pegel von 0.0 dB.
            Beim Requantisieren nach 16 Bit und nach 8 Bit kann Noiseshaping erster Ordnung genutzt werden. Die Klasse muß nach ihrem Gebrauch mit Dispose() zerstört werden.
            </summary>
        </member>
        <member name="M:CoreAudioApi.ToByteConverter.#ctor(System.Int32,System.Boolean,CoreAudioApi.WaveFormatExtensible)">
            <summary>
            Stellt eine Methode bereit, die zweidimensionale, kanalgetrennte Double-Arrays in eindimensionale, kanalweise verschachtelte Byte-Arrays, wie sie für Soundgeräte
            oder -dateien benötigt werden, umwandelt. Der Wertebereich wird bei IEEEFloat-Formaten durch das Zielformat begrenzt. Eine Amplitude von 1.0 entspricht dem Pegel von 0.0 dB.
            Beim Requantisieren nach 16 Bit und nach 8 Bit kann Noiseshaping erster Ordnung genutzt werden. Die Klasse muß nach ihrem Gebrauch mit Dispose() zerstört werden.
            </summary>
            <param name="AudioFrames">
            Die Anzahl der in einem Zyklus zu verarbeitenden Audioframes.
            </param>
            <param name="NoiseShaping">
            true, wenn zur Verbesserung der Linearität NoiseShaping eingesetzt werden soll.
            </param>
            <param name="waveFormatExtensible">
            Das Zielformt der Audiodaten.
            </param>
        </member>
        <member name="M:CoreAudioApi.ToByteConverter.ConvertToByte(System.Double[0:,0:])">
            <summary>
            Konvertiert ein zweidimensionales, kanalgetrenntes Double-Array mit Audiodaten in ein eindimensionales, kanalverschachteltes Byte-Array.
            Der Wertebereich wird bei IEEEFloat-Formaten durch das Zielformat begrenzt. Eine Amplitude von 1.0 entspricht dem Pegel von 0.0 dB.
            Bei nur einem Kanal muß ein double[n, 1] übergeben werden, bei zweien ein [n, 2]...
            </summary>
            <param name="AudioData">
            Double-Array mit Audiodaten.
            </param>
            <returns>
            Byte-Array mit Audiodaten.
            </returns>
        </member>
        <member name="M:CoreAudioApi.ToByteConverter.ToString">
            <summary>
            Gibt die Haupteigenschaften des ToByteConverter als Zeichenkette zurück.
            </summary>
            <returns>
            Haupteigenschaften des ToByteConverter.
            </returns>
        </member>
        <member name="M:CoreAudioApi.ToByteConverter.Dispose">
            <summary>
            Gibt die Ressourcen des ToByteConverter frei. Schließt den File-Stream.
            </summary>
        </member>
        <member name="M:CoreAudioApi.ToByteConverter.Dispose(System.Boolean)">
            <summary>
            Gibt die Ressourcen des ToByteConverter frei.
            </summary>
            <param name="disposing">
            true, es werden auch verwaltete Objekte frei gegeben.
            false, wenn die Methode aus einem Destructor aufgerufen werden soll.
            </param>
        </member>
        <member name="M:CoreAudioApi.ToByteConverter.Finalize">
            <summary>
            Destructor
            </summary>
        </member>
        <member name="P:CoreAudioApi.ToByteConverter.Disposed">
            <summary>
            Ruft ab, ob das Element frei gegeben wurde.
            </summary>
        </member>
        <member name="P:CoreAudioApi.ToByteConverter.NoiseShaping">
            <summary>
            Ruft ab, ob beim Requantisieren nach 8 oder 16 Bit NoiseShaping eingesetzt wird.
            </summary>
        </member>
        <member name="T:CoreAudioApi.IAudioRenderClient">
            <summary>
            The IAudioRenderClient interface enables a client to write output data to a rendering endpoint buffer. The client obtains a reference to the IAudioRenderClient interface
            of a stream object by calling the IAudioClient.GetService method with parameter riid set to REFIID IID_IAudioRenderClient. 
            The methods in this interface manage the movement of data packets that contain audio-rendering data. The length of a data packet is expressed as the number of audio
            frames in the packet. The size of an audio frame is specified by the nBlockAlign member of the WAVEFORMATEX structure that the client obtains by calling the
            IAudioClient.GetMixFormat method. The size in bytes of an audio frame equals the number of channels in the stream multiplied by the sample size per channel.
            For example, the frame size is four bytes for a stereo (2-channel) stream with 16-bit samples. A packet always contains an integral number of audio frames. 
            When releasing an IAudioRenderClient interface instance, the client must call the interface's Release method from the same thread as the call to
            IAudioClient.GetService that created the object.
            </summary>
        </member>
        <member name="M:CoreAudioApi.IAudioRenderClient.GetBuffer(System.UInt32,System.IntPtr@)">
            <summary>
            The GetBuffer method retrieves a pointer to the next available space in the rendering endpoint buffer into which the caller can write a data packet.
            </summary>
            <param name="numFramesRequested">
            The number of audio frames in the data packet that the caller plans to write to the requested space in the buffer. If the call succeeds,
            the size of the buffer area pointed to by dataBufferPointer matches the size specified in NumFramesRequested.
            </param>
            <param name="dataBufferPointer">
            Pointer to a pointer variable into which the method writes the starting address of the buffer area into which the caller will write the data packet.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IAudioRenderClient.ReleaseBuffer(System.UInt32,CoreAudioApi.AudioClientBufferFlags)">
            <summary>
            The ReleaseBuffer method releases the buffer space acquired in the previous call to the IAudioRenderClient.GetBuffer method.
            </summary>
            <param name="numFramesWritten">
            The number of audio frames written by the client to the data packet. The value of this parameter must be less than or equal to the size of the data packet,
            as specified in the NumFramesRequested parameter passed to the IAudioRenderClient.GetBuffer method.
            </param>
            <param name="bufferFlags">
            The buffer-configuration flags. The caller can set this parameter either to 0 or to the following AudioClientBufferFlags enumeration value Silent.
            If this flag bit is set, the audio engine treats the data packet as though it contains silence regardless of the data values contained in the packet.
            This flag eliminates the need for the client to explicitly write silence data to the rendering buffer.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="T:CoreAudioApi.Propertyes">
            <summary>
            Property Keys
            </summary>
        </member>
        <member name="F:CoreAudioApi.Propertyes.DeviceInterfaceFriendlyName">
            <summary>
            The DeviceInterfaceFriendlyName property contains the friendly name of the audio adapter to which the endpoint device is attached (for example, "XYZ Audio Adapter").
            The vt member of the PROPVARIANT structure is set to VT_LPWSTR. The pwszVal member of the PROPVARIANT structure points to a null-terminated, wide-character string
            that contains the friendly name.
            </summary>
        </member>
        <member name="F:CoreAudioApi.Propertyes.DeviceFriendlyName">
            <summary>
            The DeviceFriendlyName property contains the friendly name of the endpoint device (for example, "Speakers (XYZ Audio Adapter)").
            The vt member of the PROPVARIANT structure is set to VT_LPWSTR. The pwszVal member of the PROPVARIANT structure points to a null-terminated, wide-character string
            that contains the friendly name of the endpoint device.
            </summary>
        </member>
        <member name="F:CoreAudioApi.Propertyes.DeviceDeviceDesc">
            <summary>
            The DeviceDeviceDesc property contains the device description of the endpoint device (for example, "Speakers").
            The vt member of the PROPVARIANT structure is set to VT_LPWSTR. The pwszVal member of the PROPVARIANT structure points to a null-terminated, wide-character string
            that contains the device description.
            </summary>
        </member>
        <member name="F:CoreAudioApi.Propertyes.DeviceContainerId">
            <summary>
            Stores the container identifier of the PnP device that implements the audio endpoint.
            </summary>
        </member>
        <member name="F:CoreAudioApi.Propertyes.AudioEndpointFormFactor">
            <summary>
            The AudioEndpointFormFactor property specifies the form factor of the audio endpoint device. The form factor indicates the physical attributes of
            the audio endpoint device that the user manipulates.
            The vt member of the PROPVARIANT structure is set to VT_UI4. The uintVal member of the PROPVARIANT structure contains an enumeration value that is cast to type UINT.
            It is set to one of the EndpointFormFactor enumeration values.
            </summary>
        </member>
        <member name="F:CoreAudioApi.Propertyes.AudioEndpointControlPanelPageProvider">
            <summary>
            The AudioEndpointControlPanelPageProvider property specifies the CLSID of the registered provider of the device-properties extension for the audio endpoint device.
            The extension supplies the audio endpoint properties that are displayed in the device-properties page of the Windows multimedia control panel, Mmsys.cpl.
            The vt member of the PROPVARIANT structure is set to VT_LPWSTR. The pwszVal member of the PROPVARIANT structure points to a null-terminated, wide-character string
            that contains a GUID that identifies the provider of the control-panel extension.
            </summary>
        </member>
        <member name="F:CoreAudioApi.Propertyes.AudioEndpointAssociation">
            <summary>
            The AudioEndpointAssociation property associates a kernel-streaming (KS) pin category with an audio endpoint device.
            The .inf file that installs an audio adapter assigns a pin category to each KS pin in the adapter. A KS pin on an adapter device represents the point at which an
            audio stream enters or leaves the device. A pin category is a GUID that specifies the type of function performed by a KS pin. For example, header file Ksmedia.h defines
            pin-category GUID KSNODETYPE_MICROPHONE to indicate a KS pin that connects to a microphone, and KSNODETYPE_HEADPHONES to indicate a KS pin that connects to headphones.
            The vt member of the PROPVARIANT structure is set to VT_LPWSTR. The pwszVal member of the PROPVARIANT structure points to a null-terminated, wide-character string
            that contains a KS pin category GUID.
            </summary>
        </member>
        <member name="F:CoreAudioApi.Propertyes.AudioEndpointPhysicalSpeakers">
            <summary>
            The AudioEndpointPhysicalSpeakers property specifies the channel-configuration mask for the audio endpoint device.
            The mask indicates the physical configuration of a set of speakers and specifies the assignment of channels to speakers.
            The vt member of the PROPVARIANT structure is set to VT_UI4. The uintVal member of the PROPVARIANT structure contains a channel-configuration mask that is cast to type UINT.
            </summary>
        </member>
        <member name="F:CoreAudioApi.Propertyes.AudioEndpointGUID">
            <summary>
            The AudioEndpointGUID property supplies the DirectSound device identifier that corresponds to the audio endpoint device.
            The property value is a GUID that the client can supply as the device identifier to the DirectSoundCreate or DirectSoundCaptureCreate function in the DirectSound API.
            This value uniquely identifies the audio endpoint device across all audio endpoint devices in the system.
            The vt member of the PROPVARIANT structure is set to VT_LPWSTR. The pwszVal member of the PROPVARIANT structure points to a null-terminated, wide-character string
            that contains a GUID that identifies the audio endpoint device in DirectSound.
            </summary>
        </member>
        <member name="F:CoreAudioApi.Propertyes.AudioEndpointDisableSysFx">
            <summary>
            The AudioEndpointDisableSysFx property specifies whether system effects are enabled in the shared-mode stream that flows to or from the audio endpoint device.
            System effects are implemented as audio processing objects (APOs) that can be inserted into an audio stream. APOs are software modules that perform audio processing
            functions such as volume control and format conversion. Disabling the system effects for an endpoint device enables the associated stream to pass through the APOs unmodified.
            The vt member of the PROPVARIANT structure is set to VT_BOOL. The boolVal member of the PROPVARIANT structure is set to TRUE if system effects are disabled or to FALSE
            if they are enabled.
            </summary>
        </member>
        <member name="F:CoreAudioApi.Propertyes.AudioEndpointFullRangeSpeakers">
            <summary>
            The AudioEndpointFullRangeSpeakers property specifies the channel-configuration mask for the full-range speakers that are connected to the audio endpoint device.
            The mask indicates the physical configuration of the full-range speakers and specifies the assignment of channels to those speakers.
            The vt member of the PROPVARIANT structure is set to VT_UI4. The uintVal member of the PROPVARIANT structure contains a channel-configuration mask that is cast to type UINT.
            </summary>
        </member>
        <member name="F:CoreAudioApi.Propertyes.AudioEndpointSupportsEventDrivenMode">
            <summary>
            The AudioEndpointSupportsEventDrivenMode property indicates whether the endpoint supports the event-driven mode.
            The values are populated by the OEM in an .inf file. The vt member of the PROPVARIANT structure is set to VT_UI4.
            The uintVal member of the PROPVARIANT structure is a DWORD that indicates if the endpoint supports the event-driven mode.
            </summary>
        </member>
        <member name="F:CoreAudioApi.Propertyes.AudioEndpointJackSubType">
            <summary>
            The AudioEndpointJackSubType property contains an output category GUID for an audio endpoint device. The header file Ksmedia.h defines the GUIDs; each GUID specifies
            the type of connection. These GUIDs also have associated pin categories. For example, header file Ksmedia.h defines the GUID KSNODETYPE_DISPLAYPORT_INTERFACE for a display
            port that connects with the KS pin defined by the GUID PINNAME_DISPLAYPORT_OUT.
            The vt member of the PROPVARIANT structure is set to VT_LPWSTR. The pwszVal member of the PROPVARIANT structure points to a null-terminated, wide-character string
            that contains a category GUID.
            </summary>
        </member>
        <member name="F:CoreAudioApi.Propertyes.AudioEngineDeviceFormat">
            <summary>
            The AudioEngineDeviceFormat property specifies the device format, which is the format that the user has selected for the stream that flows between the audio
            engine and the audio endpoint device when the device operates in shared mode. This format might not be the best default format for an exclusive-mode application to use.
            Typically, an exclusive-mode application finds a suitable device format by making some number of calls to the IAudioClient::IsFormatSupported method.
            The vt member of the PROPVARIANT structure is set to VT_BLOB. The blob member of the PROPVARIANT structure is a structure of type BLOB that contains two members.
            Member blob.cbSize is a DWORD that specifies the number of bytes in the format description. Member blob.pBlobData points to a WAVEFORMATEX structure that contains the
            format description.
            </summary>
        </member>
        <member name="F:CoreAudioApi.Propertyes.AudioEngineOEMFormat">
            <summary>
            The AudioEngineOEMFormat property specifies the default format of the device that is used for rendering or capturing a stream.
            The values are populated by the OEM in an .inf file. The vt member of the PROPVARIANT structure is set to VT_BLOB. The blob member of the PROPVARIANT structure is a
            structure of type BLOB that contains two members. Member blob.cbSize is a DWORD that specifies the number of bytes in the format description. Member blob.pBlobData points
            to a WAVEFORMATEX structure that contains the format description.
            </summary>
        </member>
        <member name="F:CoreAudioApi.Propertyes.DeviceClassIconPath">
            <summary>
            Pfad zum Icon des Audiogerätes gegebenenfalls mit Icon-ID.
            </summary>
        </member>
        <member name="T:CoreAudioApi.IMMEndpoint">
            <summary>
            The IMMEndpoint interface represents an audio endpoint device.
            </summary>
        </member>
        <member name="M:CoreAudioApi.IMMEndpoint.GetDataFlow(CoreAudioApi.DataFlow@)">
            <summary>
            The GetDataFlow method indicates whether the audio endpoint device is a rendering device or a capture device.
            </summary>
            <param name="dataFlow">
            Pointer to a variable into which the method writes the data-flow direction of the endpoint device.
            The data-flow direction for a rendering device is Render. The data-flow direction for a capture device is Capture.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="T:CoreAudioApi.PCMWaveFormateCollection">
            <summary>
            Gibt vorgefertigte PCM-Wave-Formate als WaveFormatExtensible zurück.
            </summary>
        </member>
        <member name="M:CoreAudioApi.PCMWaveFormateCollection.#ctor">
            <summary>
            Gibt vorgefertigte PCM-Wave-Formate als WaveFormatExtensible zurück.
            </summary>
        </member>
        <member name="M:CoreAudioApi.PCMWaveFormateCollection.GetEnumerator">
            <summary>
            Erzeugt einen Waveformatenumerator.
            </summary>
            <returns>
            Waveformatenumerator
            </returns>
        </member>
        <member name="P:CoreAudioApi.PCMWaveFormateCollection.Count">
            <summary>
            Anzahl der gespeicherten PCM-Wave-Formate.
            </summary>
        </member>
        <member name="P:CoreAudioApi.PCMWaveFormateCollection.Item(System.Int32)">
            <summary>
            Gibt vorgefertigte PCM-Wave-Formate als WaveFormatExtensible zurück.
            </summary>
        </member>
        <member name="T:CoreAudioApi.PCMWaveFormateCollection.WaveFormatVorlagen">
            <summary>
            Struktur zur Speicherung von Vorgaben für verschiedene PCM-Wave-Formatvorgaben.
            </summary>
        </member>
        <member name="F:CoreAudioApi.PCMWaveFormateCollection.WaveFormatVorlagen.samplesPerSecond">
            <summary>
            Anzahl der abzuspielenden Audioframes pro Sekunde.
            </summary>
        </member>
        <member name="F:CoreAudioApi.PCMWaveFormateCollection.WaveFormatVorlagen.bitsPerSample">
            <summary>
            Auflösung eines Samples in einem Kanal in Bit.
            </summary>
        </member>
        <member name="F:CoreAudioApi.PCMWaveFormateCollection.WaveFormatVorlagen.channels">
            <summary>
            Anzahl der Kanäle.
            </summary>
        </member>
        <member name="F:CoreAudioApi.PCMWaveFormateCollection.WaveFormatVorlagen.mediaSubFormat">
            <summary>
            Format, in dem die Audiosamples codiert sind.
            </summary>
        </member>
        <member name="M:CoreAudioApi.PCMWaveFormateCollection.WaveFormatVorlagen.#ctor(System.Int32,System.Int32,System.Int32,System.Guid)">
            <summary>
            Struktur zur Speicherung von Vorgaben für verschiedene PCM-Wave-Formatvorgaben.
            </summary>
            <param name="SamplesPerSecond">
            Anzahl der abzuspielenden Audioframes pro Sekunde.
            </param>
            <param name="BitsPerSample">
            Auflösung eines Samples in einem Kanal in Bit.
            </param>
            <param name="Channels">
            Anzahl der Kanäle.
            </param>
            <param name="MediaSubFormat">
            MediaSubFormat.
            </param>
        </member>
        <member name="M:CoreAudioApi.PCMWaveFormateCollection.WaveFormatVorlagen.ToString">
            <summary>
            Gibt die Haupteigenschaften der WaveFormatVorlagen als Zeichenkette zurück.
            </summary>
            <returns>
            Haupteigenschaften des WaveFormatVorlagen.
            </returns>
        </member>
        <member name="T:CoreAudioApi.IAudioClockAdjustment">
            <summary>
            The IAudioClockAdjustment interface is used to adjust the sample rate of a stream. The client obtains a reference to the IAudioClockAdjustment interface of a stream object
            by calling the IAudioClient.GetService method with parameter riid set to REFIID IID_IAudioClockAdjustment. Adjusting the sample rate is not supported for exclusive mode
            streams. The IAudioClockAdjustment interface must be obtained from an audio client that is initialized with both the AudioClientStreamFlags.RateAdjust flag and the share mode
            set to AudioClientShareMode.Shared. If Initialize is called in an AudioClientShareMode.Exclusive mode with the AudioClientStreamFlags.RateAdjust flag,
            Initialize fails with the AUDCLNT_E_UNSUPPORTED_FORMAT error code. 
            </summary>
        </member>
        <member name="M:CoreAudioApi.IAudioClockAdjustment.SetSampleRate(System.Single)">
            <summary>
            The SetSampleRate method sets the sample rate of a stream.
            </summary>
            <param name="SamplesPerSecond">
            The new sample rate in frames per second. This method must not be called from a real-time processing thread. The new sample rate will take effect after the current frame
            is done processing and will remain in effect until SetSampleRate is called again. The audio client must be initialized in shared-mode, otherwise SetSampleRate fails.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="T:CoreAudioApi.PropertyStore">
            <summary>
            Verwaltet Eigenschaften des Soundgerätes (IMMDevice), dem der PropertyStore zugeordnet ist.
            </summary>
        </member>
        <member name="M:CoreAudioApi.PropertyStore.#ctor(CoreAudioApi.IPropertyStore)">
            <summary>
            Verwaltet Eigenschaften des Soundgerätes (IMMDevice), dem der PropertyStore zugeordnet ist.
            </summary>
            <param name="iPropertyStore">
            PropertyStore Interface eines Soundgerätes (IMMDevice).
            </param>
        </member>
        <member name="M:CoreAudioApi.PropertyStore.Contains(CoreAudioApi.PropertyKey)">
            <summary>
            Prüft, ob der angegebene PropertyKey im PropertyStore gespeichert ist.
            </summary>
            <param name="propertyKey">
            Gesuchter PropertyKey.
            </param>
            <returns>
            true, wenn der PropertyKey im PropertyStore gespeichert ist.
            </returns>
        </member>
        <member name="M:CoreAudioApi.PropertyStore.GetKey(System.Int32)">
            <summary>
            Gibt den PropertyKey unter einem anzugebenden Index aus dem PropertxStore zurück.
            </summary>
            <param name="Index">
            Index des gewünschten PropertyKey.
            </param>
            <returns>
            Gewünschter PropertyKey.
            </returns>
        </member>
        <member name="M:CoreAudioApi.PropertyStore.GetVariant(System.Int32)">
            <summary>
            Gibt den PropertyVariant unter einem anzugebenden Index aus dem PropertyStore zurück.
            </summary>
            <param name="Index">
            Index des gewünschten PropertyVariant.
            </param>
            <returns>
            Gewünschter PropertyVariant.
            </returns>
        </member>
        <member name="M:CoreAudioApi.PropertyStore.Dispose">
            <summary>
            Gibt die Ressourcen des AudioClient frei.
            </summary>
        </member>
        <member name="M:CoreAudioApi.PropertyStore.Dispose(System.Boolean)">
            <summary>
            Gibt die Ressourcen des AudioClient frei.
            </summary>
            <param name="disposing">
            true, es werden auch verwaltete Objekte frei gegeben.
            false, wenn die Methode aus einem Destructor aufgerufen werden soll.
            </param>
        </member>
        <member name="M:CoreAudioApi.PropertyStore.Finalize">
            <summary>
            Destructor
            </summary>
        </member>
        <member name="P:CoreAudioApi.PropertyStore.Disposed">
            <summary>
            Ruft ab, ob das Element frei gegeben wurde.
            </summary>
        </member>
        <member name="P:CoreAudioApi.PropertyStore.Item(System.Int32)">
            <summary>
            Gibt die im PropertyStore gespeicherten Einträge nach ihrem Index zurück.
            </summary>
            <param name="Index">
            Index des gewünschten Eintrages.
            </param>
            <returns>
            Gesuchter PropertyStore Eintrag.
            </returns>
        </member>
        <member name="P:CoreAudioApi.PropertyStore.Item(CoreAudioApi.PropertyKey)">
            <summary>
            Gibt die im PropertyStore gespeicherten Einträge nach ihrem PropertyKey zurück.
            </summary>
            <param name="propertyKey">
            PropertyKey des gewünschten Eintrages.
            </param>
            <returns>
            Gesuchter PropertyStore Eintrag.
            </returns>
        </member>
        <member name="P:CoreAudioApi.PropertyStore.Count">
            <summary>
            Gibt die Anzahl der gespeicherten Einträge im PropertyStore zurück.
            </summary>
        </member>
        <member name="T:CoreAudioApi.IMMDeviceEnumerator">
            <summary>
            The IMMDeviceEnumerator interface provides methods for enumerating multimedia device resources.
            In the current implementation of the MMDevice API, the only device resources that this interface can enumerate are audio endpoint devices.
            </summary>
        </member>
        <member name="M:CoreAudioApi.IMMDeviceEnumerator.EnumAudioEndpoints(CoreAudioApi.DataFlow,CoreAudioApi.DeviceState,CoreAudioApi.IMMDeviceCollection@)">
            <summary>
            The EnumAudioEndpoints method generates a collection of audio endpoint devices that meet the specified criteria.
            </summary>
            <param name="dataFlow">
            The data-flow direction for the endpoint devices in the collection. The caller should set this parameter to one of the following DataFlow enumeration.
            If the caller specifies All, the method includes both rendering and capture endpoints in the collection.
            </param>
            <param name="deviceState">
            The state or states of the endpoints that are to be included in the collection.
            The caller should set this parameter to the bitwise OR of one or more of the following DeviceState constants
            For example, if the caller sets the deviceState parameter to Active | Unplugged,
            the method includes endpoints that are either active or unplugged from their jacks,
            but excludes endpoints that are on audio adapters that have been disabled or are not present.
            To include all endpoints, regardless of state, set deviceState = All. 
            </param>
            <param name="immDeviceCollection">
            Pointer to a pointer variable into which the method writes the address of the IMMDeviceCollection interface of the device-collection object.
            Through this method, the caller obtains a counted reference to the interface.
            The caller is responsible for releasing the interface, when it is no longer needed, by calling the interface's Release method.
            If the EnumAudioEndpoints call fails, immDeviceCollection is NULL. 
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IMMDeviceEnumerator.GetDefaultAudioEndpoint(CoreAudioApi.DataFlow,CoreAudioApi.Role,CoreAudioApi.IMMDevice@)">
            <summary>
            The GetDefaultAudioEndpoint method retrieves the default audio endpoint for the specified data-flow direction and role.
            </summary>
            <param name="dataFlow">
            The data-flow direction for the endpoint device. The caller should set this parameter to Render or Capture.
            </param>
            <param name="role">
            The role of the endpoint device.
            </param>
            <param name="immDevice">
            Pointer to a pointer variable into which the method writes the address of the IMMDevice interface of the endpoint object for the default audio endpoint device.
            Through this method, the caller obtains a counted reference to the interface.
            The caller is responsible for releasing the interface, when it is no longer needed, by calling the interface's Release method.
            If the GetDefaultAudioEndpoint call fails, immDevice is NULL.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IMMDeviceEnumerator.GetDevice(System.String,CoreAudioApi.IMMDevice@)">
            <summary>
            The GetDevice method retrieves an audio endpoint device that is identified by an endpoint ID string. 
            </summary>
            <param name="Id">
            Pointer to a string containing the endpoint ID.
            The caller typically obtains this string from the IMMDevice.GetId method or from one of the methods in the IMMNotificationClient interface.
            </param>
            <param name="immDevice">
            Pointer to a pointer variable into which the method writes the address of the IMMDevice interface for the specified device. Through this method,
            the caller obtains a counted reference to the interface.
            The caller is responsible for releasing the interface, when it is no longer needed, by calling the interface's Release method.
            If the GetDevice call fails, immDevice is NULL.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IMMDeviceEnumerator.RegisterEndpointNotificationCallback(CoreAudioApi.IMMNotificationClient)">
            <summary>
            The RegisterEndpointNotificationCallback method registers a client's notification callback interface.
            </summary>
            <param name="immNotificationClient">
            Pointer to the IMMNotificationClient interface that the client is registering for notification callbacks.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IMMDeviceEnumerator.UnregisterEndpointNotificationCallback(CoreAudioApi.IMMNotificationClient)">
            <summary>
            The UnregisterEndpointNotificationCallback method deletes the registration of a notification interface that the client registered in a previous call
            to the IMMDeviceEnumerator.RegisterEndpointNotificationCallback method.
            </summary>
            <param name="immNotificationClient">
            Pointer to the client's IMMNotificationClient interface. The client passed this same interface pointer to the device enumerator in a previous call to the
            IMMDeviceEnumerator.RegisterEndpointNotificationCallback method.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="T:CoreAudioApi.IAudioMeterInformation">
            <summary>
            The IAudioMeterInformation interface represents a peak meter on an audio stream to or from an audio endpoint device. The client obtains a reference to the
            IAudioMeterInformation interface on an endpoint object by calling the IMMDevice.Activate method with parameter iid set to REFIID IID_IAudioMeterInformation. If the adapter
            device that streams audio data to or from the endpoint device implements a hardware peak meter, the IAudioMeterInformation interface uses that meter to monitor the peak
            levels in the audio stream. If the audio device lacks a hardware peak meter, the audio engine automatically implements the peak meter in software, transparently to the client.
            If a device has a hardware peak meter, a client can use the methods in the IAudioMeterInformation interface to monitor the device's peak levels in both shared mode and
            exclusive mode. If a device lacks a hardware peak meter, a client can use those methods to monitor the device's peak levels in shared mode, but not in exclusive mode.
            In exclusive mode, the client and the device exchange audio data directly, bypassing the software peak meter. In exclusive mode, a software peak meter always reports a peak
            value of 0.0. To determine whether a device has a hardware peak meter, call the IAudioMeterInformation.QueryHardwareSupport method. For a rendering endpoint device,
            the IAudioMeterInformation interface monitors the peak levels in the output stream before the stream is attenuated by the endpoint volume controls. Similarly, for a capture
            endpoint device, the interface monitors the peak levels in the input stream before the stream is attenuated by the endpoint volume controls. The peak values reported by
            the methods in the IAudioMeterInformation interface are normalized to the range from 0.0 to 1.0. For example, if a PCM stream contains 16-bit samples, and the peak sample
            value during a particular metering period is –8914, then the absolute value recorded by the peak meter is 8914, and the normalized peak value reported by the
            IAudioMeterInformation interface is 8914/32768 = 0.272.
            </summary>
        </member>
        <member name="M:CoreAudioApi.IAudioMeterInformation.GetPeakValue(System.Single@)">
            <summary>
            The GetPeakValue method gets the peak sample value for the channels in the audio stream.
            </summary>
            <param name="peak">
            Pointer to a float variable into which the method writes the peak sample value for the audio stream. The peak value is a number in the normalized range from 0.0 to 1.0.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IAudioMeterInformation.GetMeteringChannelCount(System.UInt32@)">
            <summary>
            The GetMeteringChannelCount method gets the number of channels in the audio stream that are monitored by peak meters. This method retrieves the peak sample value recorded
            across all of the channels in the stream. The peak value for each channel is recorded over one device period and made available during the subsequent device period.
            Thus, this method always retrieves the peak value recorded during the previous device period. To obtain the device period, call the IAudioClient.GetDevicePeriod method. 
            </summary>
            <param name="channels">
            Pointer to a uint variable into which the method writes the number of channels.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IAudioMeterInformation.GetChannelsPeakValues(System.UInt32,System.IntPtr)">
            <summary>
            The GetChannelsPeakValues method gets the peak sample values for all the channels in the audio stream. This method retrieves the peak sample values for the
            channels in the stream.
            </summary>
            <param name="channels">
            The channel count. This parameter also specifies the number of elements in the afPeakValues array.
            </param>
            <param name="peakValues">
            Pointer to an array of peak sample values. The method writes the peak values for the channels into the array. The array contains one element for each channel in the stream.
            The peak values are numbers in the normalized range from 0.0 to 1.0. The peak value for each channel is recorded over one device period and made available during the
            subsequent device period. Thus, this method always retrieves the peak values recorded during the previous device period. To obtain the device period, call the
            IAudioClient.GetDevicePeriod method. Parameter peakValues points to a caller-allocated float array. If the stream contains n channels, the channels are numbered 0 to n–1.
            The method stores the peak value for each channel in the array element whose array index matches the channel number. To get the number of channels in the audio stream that
            are monitored by peak meters, call the IAudioMeterInformation.GetMeteringChannelCount method. 
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IAudioMeterInformation.QueryHardwareSupport(CoreAudioApi.EndpointHardwareSupport@)">
            <summary>
            The QueryHardwareSupport method queries the audio endpoint device for its hardware-supported functions.
            </summary>
            <param name="hardwareSupportMask">
            Pointer to a DWORD variable into which the method writes a hardware support mask that indicates the hardware capabilities of the audio endpoint device.
            The method can set the mask to 0 or to the bitwise-OR combination of one or more EndpointHardwareSupport enumerator.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="T:CoreAudioApi.IAudioClient">
            <summary>
            The IAudioClient interface enables a client to create and initialize an audio stream between an audio application and the audio engine
            (for a shared-mode stream) or the hardware buffer of an audio endpoint device (for an exclusive-mode stream).
            A client obtains a reference to an IAudioClient interface for an audio endpoint device by following these steps: 
            By using one of the techniques described in IMMDevice Interface, obtain a reference to the IMMDevice interface for an audio endpoint device. 
            Call the IMMDevice.Activate method with parameter interfaceID set to IID_IAudioClient.
            To release the IAudioClient object and free all its associated resources, the client must release all references to any service objects that were created by calling
            GetService, in addition to calling Release on the IAudioClient interface itself. The client must release a service from the same thread that releases the IAudioClient object.
            </summary>
        </member>
        <member name="M:CoreAudioApi.IAudioClient.Initialize(CoreAudioApi.AudioClientShareMode,CoreAudioApi.AudioClientStreamFlags,System.Int64,System.Int64,CoreAudioApi.WaveFormatExtensible,System.Guid@)">
            <summary>
            The Initialize method initializes the audio stream.
            </summary>
            <param name="shareMode">
            The sharing mode for the connection. Through this parameter, the client tells the audio engine whether it wants to share the audio endpoint device with other clients.
            The client should set this parameter to one of the following AudioClientShareMode enumeration values: Exclusive; Shared.
            </param>
            <param name="streamFlags">
            Flags to control creation of the stream. The client should set this parameter to 0 or to the bitwise OR of one or more of the AudioClientStreamFlags. 
            </param>
            <param name="bufferDuration">
            The buffer capacity as a time value. This parameter is expressed in 100-nanosecond units.
            This parameter contains the buffer size that the caller requests for the buffer that the audio application will share with the audio engine (in shared mode)
            or with the endpoint device (in exclusive mode). If the call succeeds, the method allocates a buffer that is a least this large.
            For a shared-mode stream that uses event-driven buffering, the caller must set both hnsPeriodicity and bufferDuration to 0.
            The Initialize method determines how large a buffer to allocate based on the scheduling period of the audio engine.
            </param>
            <param name="periodicity">
            The device period parameter can be nonzero only in exclusive mode. In shared mode, always set this parameter to 0.
            In exclusive mode, this parameter specifies the requested scheduling period for successive buffer accesses by the audio endpoint device.
            If the requested device period lies outside the range that is set by the device's minimum period and the system's maximum period, then the method clamps the
            period to that range. If this parameter is 0, the method sets the device period to its default value. To obtain the default device period,
            call the IAudioClient.GetDevicePeriod method. For a exclusive-mode stream that uses event-driven buffering, the periodicity must be nonzero and equal to bufferDuration.
            </param>
            <param name="waveFormatExtensible">
            Pointer to a format descriptor. This parameter must point to a valid format descriptor of type WaveFormatEx (or WaveFormatExtensible).
            </param>
            <param name="audioSessionGuid">
            Pointer to a session GUID. This parameter points to a GUID value that identifies the audio session that the stream belongs to.
            If the GUID identifies a session that has been previously opened, the method adds the stream to that session. If the GUID does not identify an existing session,
            the method opens a new session and adds the stream to that session. The stream remains a member of the same session for its lifetime.
            Setting this parameter to NULL is equivalent to passing a pointer to a GUID_NULL value.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IAudioClient.GetBufferSize(System.UInt32@)">
            <summary>
            This method retrieves the length of the endpoint buffer shared between the client application and the audio engine. The length is expressed as the number of audio frames
            the buffer can hold. The size in bytes of an audio frame is calculated as the number of channels in the stream multiplied by the sample size per channel.
            For example, the frame size is four bytes for a stereo (2-channel) stream with 16-bit samples. This method requires prior initialization of the IAudioClient interface.
            All calls to this method will fail until the client initializes the audio stream by successfully calling the IAudioClient.Initialize
            method. 
            </summary>
            <param name="bufferSize">
            Pointer to a UINT32 variable into which the method writes the number of audio frames that the buffer can hold.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IAudioClient.GetStreamLatency">
            <summary>
            The GetStreamLatency method retrieves the maximum latency for the current stream and can be called any time after the stream has been initialized.
            This method retrieves the maximum latency for the current stream. The value will not change for the lifetime of the IAudioClient object.
            Rendering clients can use this latency value to compute the minimum amount of data that they can write during any single processing pass.
            To write less than this minimum is to risk introducing glitches into the audio stream.
            </summary>
            <returns>
            StreamLatency
            </returns>
        </member>
        <member name="M:CoreAudioApi.IAudioClient.GetCurrentPadding(System.UInt32@)">
            <summary>
            This method retrieves a padding value that indicates the amount of valid, unread data that the endpoint buffer currently contains.
            A rendering application can use the padding value to determine how much new data it can safely write to the endpoint buffer without overwriting previously written data
            that the audio engine has not yet read from the buffer. A capture application can use the padding value to determine how much new data it can safely read from the endpoint
            buffer without reading invalid data from a region of the buffer to which the audio engine has not yet written valid data. This method requires prior initialization of the
            IAudioClient interface.
            </summary>
            <param name="currentPadding">
            Pointer to a UINT32 variable into which the method writes the frame count (the number of audio frames of padding in the buffer). 
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IAudioClient.IsFormatSupported(CoreAudioApi.AudioClientShareMode,CoreAudioApi.WaveFormatExtensible,CoreAudioApi.WaveFormatExtensible@)">
            <summary>
            The IsFormatSupported method indicates whether the audio endpoint device supports a particular stream format. For exclusive mode, IsFormatSupported returns S_OK if the audio
            endpoint device supports the caller-specified format, or it returns AUDCLNT_E_UNSUPPORTED_FORMAT if the device does not support the format.
            The ppClosestMatch parameter can be NULL. If it is not NULL, the method writes NULL to *ppClosestMatch. For shared mode, if the audio engine supports the caller-specified
            format, IsFormatSupported sets *ppClosestMatch to NULL and returns S_OK. If the audio engine does not support the caller-specified format but does support a similar format,
            the method retrieves the similar format through the ppClosestMatch parameter and returns S_FALSE. If the audio engine does not support the caller-specified format or any
            similar format, the method sets *ppClosestMatch to NULL and returns AUDCLNT_E_UNSUPPORTED_FORMAT. In shared mode, the audio engine always supports the mix format,
            which the client can obtain by calling the IAudioClient.GetMixFormat method. In addition, the audio engine might support similar formats that have the same sample rate
            and number of channels as the mix format but differ in the representation of audio sample values. The audio engine represents sample values internally as floating-point
            numbers, but if the caller-specified format represents sample values as integers, the audio engine typically can convert between the integer sample values and its internal
            floating-point representation.
            </summary>
            <param name="shareMode">
            The sharing mode for the stream format. Through this parameter, the client indicates whether it wants to use the specified format in exclusive mode or shared mode.
            The client should set this parameter to one of the following AudioClientShareMode enumeration values: Exclusive; Shared.
            </param>
            <param name="waveFormatExtensibleIn">
            Pointer to the specified stream format. This parameter points to a caller-allocated format descriptor  of type WaveFormatEx or WaveFormatExtensible.
            The client writes a format description to this structure before calling this method.
            </param>
            <param name="waveFormatExtensibleOut">
            Pointer to a pointer variable into which the method writes the address of a WaveFormatEx or WaveFormatExtensible structure.
            This structure specifies the supported format that is closest to the format that the client specified through the pFormat parameter.
            For shared mode (that is, if the ShareMode parameter is shared), set waveFormatExtensibleOut to point to a valid, non-NULL pointer variable.
            For exclusive mode, set waveFormatExtensibleOut to NULL. The method allocates the storage for the structure.
            If the IsFormatSupported call fails and waveFormatExtensibleOut is non-NULL, the method sets waveFormatExtensibleOut to NULL.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IAudioClient.GetMixFormat(System.IntPtr@)">
            <summary>
            The GetMixFormat method retrieves the stream format that the audio engine uses for its internal processing of shared-mode streams. 
            </summary>
            <param name="deviceFormatPointer">
            Pointer to a pointer variable into which the method writes the address of the mix format. This parameter must be a valid, non-NULL pointer to a pointer variable.
            The method writes the address of a WaveFormatEx or WaveFormatExtensible structure to this variable. The method allocates the storage for the structure.
            If the GetMixFormat call fails, deviceFormatPointer is NULL.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IAudioClient.GetDevicePeriod(System.Int64@,System.Int64@)">
            <summary>
            The GetDevicePeriod method retrieves the length of the periodic interval separating successive processing passes by the audio engine on the data in the endpoint buffer.
            For a shared-mode stream, the audio engine periodically processes the data in the endpoint buffer, which the engine shares with the client application.
            The engine schedules itself to perform these processing passes at regular intervals. The period between processing passes by the audio engine is fixed for a particular
            audio endpoint device and represents the smallest processing quantum for the audio engine. This period plus the stream latency between the buffer and endpoint device
            represents the minimum possible latency that an audio application can achieve. The client has the option of scheduling its periodic processing thread to run at the same
            time interval as the audio engine. In this way, the client can achieve the smallest possible latency for a shared-mode stream. However, in an application for which latency
            is less important, the client can reduce the process-switching overhead on the CPU by scheduling its processing passes to occur less frequently. In this case, the endpoint
            buffer must be proportionally larger to compensate for the longer period between processing passes.
            </summary>
            <param name="defaultDevicePeriod">
            Pointer to a variable into which the method writes a time value specifying the default interval between periodic processing passes by the audio engine.
            The defaultDevicePeriod parameter specifies the default scheduling period for a shared-mode stream. The time is expressed in 100-nanosecond units.
            </param>
            <param name="minimumDevicePeriod">
            Pointer to a variable into which the method writes a time value specifying the minimum interval between periodic processing passes by the audio endpoint device.
            The minimumDevicePeriod parameter specifies the minimum scheduling period for an exclusive-mode stream. The time is expressed in 100-nanosecond units.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IAudioClient.Start">
            <summary>
            The Start method is a control method that the client calls to start the audio stream. Starting the stream causes the IAudioClient object to begin streaming data between
            the endpoint buffer and the audio engine. It also causes the stream's audio clock to resume counting from its current position.
            The first time this method is called following initialization of the stream, the IAudioClient object's stream position counter begins at 0.
            Otherwise, the clock resumes from its position at the time that the stream was last stopped. Resetting the stream forces the stream position back to 0.
            To avoid start-up glitches with rendering streams, clients should not call Start until the audio engine has been initially loaded with data by calling the
            IAudioRenderClient.GetBuffer and IAudioRenderClient.ReleaseBuffer methods on the rendering interface.
            </summary>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IAudioClient.Stop">
            <summary>
            The Stop method is a control method that stops a running audio stream. This method stops data from streaming through the client's connection with the audio engine.
            Stopping the stream freezes the stream's audio clock at its current stream position. A subsequent call to IAudioClient.Start causes the stream to resume running from
            that position. If necessary, the client can call the IAudioClient.Reset method to reset the position while the stream is stopped.
            </summary>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IAudioClient.Reset">
            <summary>
            The Reset method is a control method that the client calls to reset a stopped audio stream. Resetting the stream flushes all pending data and resets the audio
            clock stream position to 0. This method fails if it is called on a stream that is not stopped.
            </summary>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IAudioClient.SetEventHandle(System.IntPtr)">
            <summary>
            The SetEventHandle method sets the event handle that the system signals when an audio buffer is ready to be processed by the client. During stream initialization,
            the client can, as an option, enable event-driven buffering. To do so, the client calls the IAudioClient.Initialize method with the AUDCLNT_STREAMFLAGS_EVENTCALLBACK flag set.
            After enabling event-driven buffering, and before calling the IAudioClient.Start method to start the stream, the client must call SetEventHandle to register the event
            handle that the system will signal each time a buffer becomes ready to be processed by the client. The event handle should be in the nonsignaled state at the time that
            the client calls the Start method. If the client has enabled event-driven buffering of a stream, but the client calls the Start method for that stream without first
            calling SetEventHandle, the Start call will fail and return an error code. If the client does not enable event-driven buffering of a stream but attempts to set an event
            handle for the stream by calling SetEventHandle, the call will fail and return an error code.
            </summary>
            <param name="eventHandle">
            The event handle.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IAudioClient.GetService(System.Guid@,System.Object@)">
            <summary>
            The GetService method accesses additional services from the audio client object. The IAudioSessionControl, IAudioStreamVolume, IChannelAudioVolume, and ISimpleAudioVolume
            interfaces control and monitor aspects of audio sessions and shared-mode streams. These interfaces do not work with exclusive-mode streams.
            </summary>
            <param name="interfaceId">
            The interface ID for the requested service. The client should set this parameter to one of the following REFIID values: IID_IAudioCaptureClient;
            IID_IAudioClock; IID_IAudioRenderClient; IID_IAudioSessionControl; IID_IAudioStreamVolume; IID_IChannelAudioVolume; IID_IMFTrustedOutput; IID_ISimpleAudioVolume;
            </param>
            <param name="interfacePointer">
            Pointer to a pointer variable into which the method writes the address of an instance of the requested interface.
            Through this method, the caller obtains a counted reference to the interface. The caller is responsible for releasing the interface,
            when it is no longer needed, by calling the interface's Release method. If the GetService call fails, interfacePointer is NULL. 
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="T:CoreAudioApi.AudioClientStreamFlags">
            <summary>
            Die Flags des AudioClientStreamFlags Enumerators bestimmen, wie ein Audioclient einen Audiostream verarbeitet.
            </summary>
        </member>
        <member name="F:CoreAudioApi.AudioClientStreamFlags.None">
            <summary>
            None
            </summary>
        </member>
        <member name="F:CoreAudioApi.AudioClientStreamFlags.CrossProcess">
            <summary>
            The audio stream will be a member of a cross-process audio session.
            </summary>
        </member>
        <member name="F:CoreAudioApi.AudioClientStreamFlags.LoopBack">
            <summary>
            The audio stream will operate in loopback mode.
            </summary>
        </member>
        <member name="F:CoreAudioApi.AudioClientStreamFlags.EventCallback">
             <summary>
            Processing of the audio buffer by the client will be event driven.
             </summary>
        </member>
        <member name="F:CoreAudioApi.AudioClientStreamFlags.NoPersist">
            <summary>
            The volume and mute settings for an audio session will not persist across system restarts.
            HKEY_CURRENT_USER\Software\Microsoft\Internet Explorer\LowRegistry\Audio\PolicyConfig\PropertyStore
            </summary>
        </member>
        <member name="F:CoreAudioApi.AudioClientStreamFlags.RateAdjust">
            <summary>
            This constant is new in Windows 7. The sample rate of the stream is adjusted to a rate specified by an application.    
            </summary>
        </member>
        <member name="F:CoreAudioApi.AudioClientStreamFlags.ExpireWhenUnowned">
             <summary>
            The session expires when there are no associated streams and owning session control objects holding references.
             </summary>
        </member>
        <member name="F:CoreAudioApi.AudioClientStreamFlags.DisplayHide">
            <summary>
            The volume control is hidden in the volume mixer user interface when the audio session is created.
            If the session associated with the stream already exists before IAudioClient.Initialize opens the stream, the volume control is displayed in the volume mixer.     
            </summary>
        </member>
        <member name="F:CoreAudioApi.AudioClientStreamFlags.DisplayHideWhenExpired">
            <summary>
            The volume control is hidden in the volume mixer user interface after the session expires.    
            </summary>
        </member>
        <member name="T:CoreAudioApi.AudioClientBufferFlags">
            <summary>
            Die Flags im AudioClientBufferFlags Enumerator bestimmen, wie Audiodaten zu interpretieren sind.
            </summary>
        </member>
        <member name="F:CoreAudioApi.AudioClientBufferFlags.None">
            <summary>
            None
            </summary>
        </member>
        <member name="F:CoreAudioApi.AudioClientBufferFlags.DataDiscontinuity">
            <summary>
            DataDiscontinuity
            </summary>
        </member>
        <member name="F:CoreAudioApi.AudioClientBufferFlags.Silent">
            <summary>
            Silent
            </summary>
        </member>
        <member name="F:CoreAudioApi.AudioClientBufferFlags.TimestampError">
            <summary>
            TimestampError
            </summary>
        </member>
        <member name="T:CoreAudioApi.AudioMeterInformation">
            <summary>
            Stellt Methoden zur Messung der Aussteuerung der Kanäle eines Audio-Streams von oder zu einem Audio-Endpoint bereit. Ein AudioMeterInformation-Objekt kann aus der
            AudioMeterInformation-Eigenschaft einer IMMDevice-Klasse gewonnen werden.
            Wenn das Audiogerät (Soundkarte) den Pegel hardwaregestützt misst, werden diese Daten zurückgegeben. Ist das nicht der Fall, geschieht die Messung per Software. Es ist dann
            nicht möglich, Pegeldaten aus Exclusive-Mode-Streams zu gewinnen. Mit der Methode AudioEndpointVolume.QueryHardwareSupport kann bestimmt werden, ob das Audiogerät
            Hardwarepegelmesser besitzt. Die gemessenen Pegel werden im Bereich zwischen 0.0 und 1.0 zurückgegeben.
            Das AudioMeterInformation muß nach seiner Verwendung mit Dispose vernichtet werden.
            </summary>
        </member>
        <member name="M:CoreAudioApi.AudioMeterInformation.#ctor(CoreAudioApi.IAudioMeterInformation)">
            <summary>
            Stellt Methoden zur Messung der Aussteuerung der Kanäle eines Audio-Streams von oder zu einem Audio-Endpoint bereit. Ein AudioMeterInformation-Objekt kann aus der
            AudioMeterInformation-Eigenschaft einer IMMDevice-Klasse gewonnen werden.
            Wenn das Audiogerät (Soundkarte) den Pegel hardwaregestützt misst, werden diese Daten zurückgegeben. Ist das nicht der Fall, geschieht die Messung per Software. Es ist dann
            nicht möglich, Pegeldaten aus Exclusive-Mode-Streams zu gewinnen. Mit der Methode AudioEndpointVolume.QueryHardwareSupport kann bestimmt werden, ob das Audiogerät
            Hardwarepegelmesser besitzt. Die gemessenen Pegel werden im Bereich zwischen 0.0 und 1.0 zurückgegeben.
            Das AudioMeterInformation muß nach seiner Verwendung mit Dispose vernichtet werden.
            </summary>
            <param name="iAudioMeterInformation">
            IAudioMeterInformation aus einem MMDevice.
            </param>
        </member>
        <member name="M:CoreAudioApi.AudioMeterInformation.GetChannelsPeakValue">
            <summary>
            Gibt die Pegel-Spitzenwerte aller einzelnen Kanäle des Audio-Streams von oder zu einem Audio-Endpoint im Bereich zwischen 0.0 und 1.0 an.
            </summary>
            <returns>
            Pegel-Spitzenwerte aller Kanäle des Audio-Streams im Bereich zwischen 0.0 und 1.0.
            </returns>
        </member>
        <member name="M:CoreAudioApi.AudioMeterInformation.Dispose">
            <summary>
            Gibt die Ressourcen des AudioMeterInformation frei.
            </summary>
        </member>
        <member name="M:CoreAudioApi.AudioMeterInformation.Dispose(System.Boolean)">
            <summary>
            Gibt die Ressourcen des AudioMeterInformation frei.
            </summary>
            <param name="disposing">
            true, es werden auch verwaltete Objekte frei gegeben.
            false, wenn die Methode aus einem Destructor aufgerufen werden soll.
            </param>
        </member>
        <member name="M:CoreAudioApi.AudioMeterInformation.Finalize">
            <summary>
            Destructor
            </summary>
        </member>
        <member name="P:CoreAudioApi.AudioMeterInformation.Disposed">
            <summary>
            Ruft ab, ob das Element frei gegeben wurde.
            </summary>
        </member>
        <member name="P:CoreAudioApi.AudioMeterInformation.Channels">
            <summary>
            Gibt die Anzahl der Kanäle in dem Audio-Stream zurück, der den Audio-Endpoint passiert.
            Der Wert bleibt über die Lebenszeit der Klasse konstant.
            </summary>
        </member>
        <member name="P:CoreAudioApi.AudioMeterInformation.HardwareSupport">
            <summary>
            Gibt an, ob das Audiogerät die Lautstärke per Hardware messen kann.
            </summary>
        </member>
        <member name="P:CoreAudioApi.AudioMeterInformation.MasterPeakValue">
            <summary>
            Gibt den Master-Pegel des Audio-Streams von oder zu einem Audio-Endpoint im Bereich zwischen 0.0 und 1.0 an.
            </summary>
        </member>
        <member name="T:CoreAudioApi.DeviceState">
            <summary>
            The DeviceState enumeration indicate the current state of an audio endpoint device. The Windows multimedia control panel, Mmsys.cpl, displays the audio endpoint devices
            in the system. Disabling a device in Mmsys.cpl hides the device from the device-discovery mechanisms in higher-level audio APIs, but it does not invalidate any stream
            objects that a client might have instantiated before the device was disabled. For example, if a stream is playing on the device when the user disables it in Mmsys.cpl,
            the stream continues to play uninterrupted.
            </summary>
        </member>
        <member name="F:CoreAudioApi.DeviceState.Active">
            <summary>
            The audio endpoint device is active. That is, the audio adapter that connects to the endpoint device is present and enabled.
            In addition, if the endpoint device plugs into a jack on the adapter, then the endpoint device is plugged in.
            </summary>
        </member>
        <member name="F:CoreAudioApi.DeviceState.Disable">
            <summary>
            The audio endpoint device is disabled. The user has disabled the device in the Windows multimedia control panel, Mmsys.cpl.
            </summary>
        </member>
        <member name="F:CoreAudioApi.DeviceState.Notpresent">
            <summary>
            The audio endpoint device is not present because the audio adapter that connects to the endpoint device has been removed from the system,
            or the user has disabled the adapter device in Device Manager.
            </summary>
        </member>
        <member name="F:CoreAudioApi.DeviceState.Unplugged">
            <summary>
            The audio endpoint device is unplugged. The audio adapter that contains the jack for the endpoint device is present and enabled, but the endpoint device is not plugged
            into the jack. Only a device with jack-presence detection can be in this state. For more information about jack-presence detection, see Audio Endpoint Devices.
            </summary>
        </member>
        <member name="F:CoreAudioApi.DeviceState.All">
            <summary>
            Includes audio endpoint devices in all states—active, disabled, not present, and unplugged.
            </summary>
        </member>
        <member name="T:CoreAudioApi.DataFlow">
            <summary>
            Der DataFlow Enumerator definiert Konstanten, welche die Flussrichtung der Sounddaten zwischen einem Audioendpoint und der Anwendung bestimmmen.
            </summary>
        </member>
        <member name="F:CoreAudioApi.DataFlow.Render">
            <summary>
            Audio Wiedergabe Stream. Audiodaten fließen von einer Anwendung zu einem Audioendpoint, der den Stream wiedergibt.
            </summary>
        </member>
        <member name="F:CoreAudioApi.DataFlow.Capture">
            <summary>
            Audio Aufnahme Stream. Audiodaten fließen von einem Audioendpoint, der die Daten aufnimmt, zu einer Anwendung.
            </summary>
        </member>
        <member name="F:CoreAudioApi.DataFlow.All">
            <summary>
            Audio Aufnahme oder Wiedergabe Stream. Audiodaten können in beide Richtungen zwischen Audioendpoint und Anwendung fließen.
            </summary>
        </member>
        <member name="F:CoreAudioApi.DataFlow.DataFlowEnumCount">
            <summary>
            Die Anzahl der Elemente in diesem Enumerator ohne das DataFlowEnumCount-Mitglied.
            </summary>
        </member>
        <member name="T:CoreAudioApi.MMDeviceEnumerator">
            <summary>
            Stellt Methoden zur Verfügung, um Audiogeräte aufzulisten und darauf zugreifen zu können.
            </summary>
        </member>
        <member name="M:CoreAudioApi.MMDeviceEnumerator.#cctor">
            <summary>
            Stellt Methoden zur Verfügung, um Audiogeräte aufzulisten und darauf zugreifen zu können.
            </summary>
        </member>
        <member name="M:CoreAudioApi.MMDeviceEnumerator.EnumAudioEndPoints(CoreAudioApi.DataFlow,CoreAudioApi.DeviceState)">
            <summary>
            Stellt eine Collection der im System verfügbaren Audiogeräte bereit.
            </summary>
            <param name="dataFlow">
            Bestimmt die Flussrichtung der Audiodaten (soll aufgenommen oder wiedergegeben werden).
            </param>
            <param name="deviceState">
            Zustand der aufgelisteten Audiogeräte (aktiv?).
            </param>
            <returns>
            Collection von Audiogeräten.
            </returns>
        </member>
        <member name="M:CoreAudioApi.MMDeviceEnumerator.GetDefaultAudioEndpoint(CoreAudioApi.DataFlow,CoreAudioApi.Role)">
            <summary>
            Ruft das Standardaudiogerät ab.
            </summary>
            <param name="dataFlow">
            Bestimmt die Flussrichtung der Audiodaten (soll aufgenommen oder wiedergegeben werden).
            Nur Render und Capture sind erlaubt.
            </param>
            <param name="role">
            Gibt an, in welcher Rolle das Audiogerät das Standardgerät ist (Multimedia, Kommunikation ...).
            </param>
            <returns>
            Standardaudiogerät
            </returns>
        </member>
        <member name="M:CoreAudioApi.MMDeviceEnumerator.GetDevice(System.String)">
            <summary>
            Ruft ein Audiogerät nach seiner ID ab.
            </summary>
            <param name="ID">
            ID des Audiogerätes.
            </param>
            <returns>
            Audiogerät
            </returns>
        </member>
        <member name="M:CoreAudioApi.MMDeviceEnumerator.AddEndpointNotifications(CoreAudioApi.MMNotificationClient)">
            <summary>
            Registriert einen IMMNotificationClient, um Veränderungen an den Audiogeräten feststellen zu können.
            </summary>
            <param name="mmNotificationClient">
            Der zu registrierende MMNotificationClient.
            </param>
        </member>
        <member name="M:CoreAudioApi.MMDeviceEnumerator.RemoveEndpointNotifications(CoreAudioApi.MMNotificationClient)">
            <summary>
            Entfernt einen IMMNotificationClient.
            </summary>
            <param name="mmNotificationClient">
            Der zu freizugebende MMNotificationClient.
            </param>
        </member>
        <member name="T:CoreAudioApi.IPropertyStore">
            <summary>
            Exposes methods for enumerating, getting, and setting property values.
            </summary>
        </member>
        <member name="M:CoreAudioApi.IPropertyStore.GetCount(System.UInt32@)">
            <summary>
            Gets the number of properties attached to the file.
            </summary>
            <param name="propertyCount">
            When this method returns, contains the property count.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IPropertyStore.GetAt(System.UInt32,CoreAudioApi.PropertyKey@)">
            <summary>
            Gets a property key from an item's array of properties.
            </summary>
            <param name="propertyIndex">
            The index of the property key in the array of PROPERTYKEY structures. This is a zero-based index.
            </param>
            <param name="propertyKey">
            When this method returns, contains a PROPERTYKEY structure that receives the unique identifier for a property. 
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IPropertyStore.GetValue(CoreAudioApi.PropertyKey@,CoreAudioApi.PropertyVariant@)">
            <summary>
            Gets data for a specific property.
            </summary>
            <param name="propertyKey">
            A reference to the PROPERTYKEY structure retrieved through IPropertyStore.GetAt. This structure contains a unique identifier for the property in question.
            </param>
            <param name="propVariant">
            When this method returns, contains a PROPVARIANT structure that contains the property data.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IPropertyStore.SetValue(CoreAudioApi.PropertyKey@,CoreAudioApi.PropertyVariant@)">
            <summary>
            Sets a new property value, or replaces or removes an existing value. In CoraAudioApi this write changes without call Commit() !!!
            </summary>
            <param name="propertyKey">
            A reference to the PROPERTYKEY structure retrieved through IPropertyStore.GetAt. This structure contains a unique identifier for the property in question.
            </param>
            <param name="propVariant">
            A reference to a PROPVARIANT structure that contains the new property data. 
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IPropertyStore.Commit">
            <summary>
            Saves a property change.
            </summary>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="T:CoreAudioApi.AudioClientShareMode">
            <summary>
            Die Werte des AudioClientShareMode Enumerators bestimmen, ob ein Audiogerät exclusiv oder zusammen mit anderen Anwendungen genutzt werden soll.
            </summary>
        </member>
        <member name="F:CoreAudioApi.AudioClientShareMode.Shared">
            <summary>
            Der Audiostream teilt sich ein Gerät mit anderen Anwendungen.
            </summary>
        </member>
        <member name="F:CoreAudioApi.AudioClientShareMode.Exclusive">
            <summary>
            Der Audiostream benutzt ein Gerät für sich allein. Dieses Verhalten muß im Audiotreiber (Systemsteuerung) ermöglicht werden (ist standardmäßig an).
            </summary>
        </member>
        <member name="T:CoreAudioApi.AudioVolumeNotificationData">
            <summary>
            Hilfsstruktur zum Auslesen der AudioVolumeNotificationData ohne das unbestimmt lange Array am Ende der Struktur.
            </summary>
        </member>
        <member name="P:CoreAudioApi.AudioVolumeNotificationData.GuidEventContext">
            <summary>
            Gibt die Guid zurück, welche der Methode übergeben wurde, die das Ereignis ausgelöst hat.
            </summary>
        </member>
        <member name="P:CoreAudioApi.AudioVolumeNotificationData.Muted">
            <summary>
            Gibt an, ob der Audio-Stream stumm geschaltet (true) ist oder nicht.
            </summary>
        </member>
        <member name="P:CoreAudioApi.AudioVolumeNotificationData.MasterVolume">
            <summary>
            Gibt das geänderte Mastervolume an. Dieser Wert liegt zwischen 0 und 1.0.
            </summary>
        </member>
        <member name="P:CoreAudioApi.AudioVolumeNotificationData.Channels">
            <summary>
            Gibt die Anzahl der Kanäle im Audiostream an.
            </summary>
        </member>
        <member name="P:CoreAudioApi.AudioVolumeNotificationData.FirstVolumesValue">
            <summary>
            Erster ChannelVolume-Wert.
            </summary>
        </member>
        <member name="T:CoreAudioApi.PropertyStoreProperty">
            <summary>
            Stellt einen Eintrag im PropertyStore (Variant), bestehend aus seinem Schlüssel und dem zugehörigen Inhalt, dar.
            </summary>
        </member>
        <member name="M:CoreAudioApi.PropertyStoreProperty.#ctor(CoreAudioApi.PropertyKey,CoreAudioApi.PropertyVariant)">
            <summary>
            Stellt einen Eintrag im PropertyStore (Variant), bestehend aus seinem Schlüssel und dem zugehörigen Inhalt, dar.
            </summary>
            <param name="propertyKey">
            Schlüssel zum Eintrag im PropertyStore.
            </param>
            <param name="propertyVariant">
            Inhalt des PropertyStoreeintrages.
            </param>
        </member>
        <member name="M:CoreAudioApi.PropertyStoreProperty.ToString">
            <summary>
            Wandelt den Inhalt des PropertyStore Eintrages in ein String um.
            </summary>
            <returns>
            PropertyStore Eintrag
            </returns>
        </member>
        <member name="P:CoreAudioApi.PropertyStoreProperty.Key">
            <summary>
            Schlüssel zum Eintrag im PropertyStore.
            </summary>
        </member>
        <member name="P:CoreAudioApi.PropertyStoreProperty.Value">
            <summary>
            Inhalt des PropertyStore Eintrages.
            </summary>
        </member>
        <member name="T:CoreAudioApi.IAudioEndpointVolumeEx">
            <summary>
            The IAudioEndpointVolumeEx interface provides volume controls on the audio stream to or from a device endpoint. A client obtains a reference to the IAudioEndpointVolumeEx
            interface of an endpoint device by calling the IMMDevice.Activate method with parameter iid set to REFIID IID_IAudioEndpointVolumeEx.
            If the adapter device that streams audio data to or from the endpoint device has hardware volume and mute controls, the IAudioEndpointVolume interface uses those controls
            to manage the volume and mute settings of the audio stream. If the audio device lacks a hardware volume control for the stream, the audio engine automatically implements
            volume and mute controls in software. For applications that manage shared-mode streams to and from endpoint devices, the behavior of the IAudioEndpointVolume is different
            for rendering streams and capture streams. For a shared-mode rendering stream, the endpoint volume control that the client accesses through the IAudioEndpointVolume
            interface operates independently of the per-session volume controls that the ISimpleAudioVolume and IChannelAudioVolume interfaces implement. Thus, the volume level of
            the rendering stream results from the combined effects of the endpoint volume control and per-session controls. For a shared-mode capture stream, the per-session
            volume controls that the ISimpleAudioVolume and IChannelAudioVolume interfaces implement are tied directly to the endpoint volume control implemented by the
            IAudioEndpointVolume interface. Changing the per-session volume control through the methods in the ISimpleAudioVolume and IChannelAudioVolume interfaces changes the
            setting of the IAudioEndpointVolume interface's volume control, and the reverse is also true. However, clients of the EndpointVolume API should not rely on this behavior
            because it might change in future releases. If a device has hardware volume and mute controls, changes made to the device's volume and mute settings through the
            IAudioEndpointVolume interface affect the volume level in both shared mode and exclusive mode. If a device lacks hardware volume and mute controls, changes made to
            the software volume and mute controls through the IAudioEndpointVolume interface affect the volume level in shared mode, but not in exclusive mode. In exclusive mode,
            the client and the device exchange audio data directly, bypassing the software controls. However, the software controls are persistent, and volume changes made while
            the device operates in exclusive mode take effect when the device switches to shared-mode operation. To determine whether a device has hardware volume and mute controls,
            call the IAudioEndpointVolume.QueryHardwareSupport method. 
            </summary>
        </member>
        <member name="M:CoreAudioApi.IAudioEndpointVolumeEx.RegisterControlChangeNotify(CoreAudioApi.IAudioEndpointVolumeCallback)">
            <summary>
            The RegisterControlChangeNotify method registers a client's notification callback interface.
            </summary>
            <param name="iAudioEndpointVolumeCallback">
            Pointer to the IAudioEndpointVolumeCallback interface that the client is registering for notification callbacks.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IAudioEndpointVolumeEx.UnregisterControlChangeNotify(CoreAudioApi.IAudioEndpointVolumeCallback)">
            <summary>
            The UnregisterControlChangeNotify method deletes the registration of a client's notification callback interface that the client registered in a previous call to the
            IAudioEndpointVolume.RegisterControlChangeNotify method. 
            </summary>
            <param name="iAudioEndpointVolumeCallback">
            Pointer to the client's IAudioEndpointVolumeCallback interface. The client passed this same interface pointer to the endpoint volume object in a previous call to the
            IAudioEndpointVolume.RegisterControlChangeNotify method. 
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IAudioEndpointVolumeEx.GetChannelCount(System.UInt32@)">
            <summary>
            The GetChannelCount method gets a count of the channels in the audio stream that enters or leaves the audio endpoint device.
            </summary>
            <param name="channelCount">
            Pointer to a UINT variable into which the method writes the channel count.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IAudioEndpointVolumeEx.SetMasterVolumeLevel(System.Single,System.Guid@)">
            <summary>
            The SetMasterVolumeLevel method sets the master volume level, in decibels, of the audio stream that enters or leaves the audio endpoint device.
            </summary>
            <param name="levelDB">
            The new master volume level in decibels. To obtain the range and granularity of the volume levels that can be set by this method, call the
            IAudioEndpointVolume.GetVolumeRange method.
            </param>
            <param name="eventContext">
            Context value for the IAudioEndpointVolumeCallback.OnNotify method. This parameter points to an event-context GUID. If the SetMasterVolumeLevel call changes the volume
            level of the endpoint, all clients that have registered IAudioEndpointVolumeCallback interfaces with that endpoint will receive notifications. In its implementation of
            the OnNotify method, a client can inspect the event-context GUID to discover whether it or another client is the source of the volume-change event.
            If the caller supplies a NULL pointer for this parameter, the notification routine receives the context GUID value GUID_NULL.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IAudioEndpointVolumeEx.SetMasterVolumeLevelScalar(System.Single,System.Guid@)">
            <summary>
            The SetMasterVolumeLevelScalar method sets the master volume level of the audio stream that enters or leaves the audio endpoint device. The volume level is expressed
            as a normalized, audio-tapered value in the range from 0.0 to 1.0.
            </summary>
            <param name="level">
            The new master volume level. The level is expressed as a normalized value in the range from 0.0 to 1.0.
            </param>
            <param name="eventContext">
            Context value for the IAudioEndpointVolumeCallback.OnNotify method. This parameter points to an event-context GUID. If the SetMasterVolumeLevelScalar call changes the
            volume level of the endpoint, all clients that have registered IAudioEndpointVolumeCallback interfaces with that endpoint will receive notifications.
            In its implementation of the OnNotify method, a client can inspect the event-context GUID to discover whether it or another client is the source of the volume-change event.
            If the caller supplies a NULL pointer for this parameter, the notification routine receives the context GUID value GUID_NULL.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IAudioEndpointVolumeEx.GetMasterVolumeLevel(System.Single@)">
            <summary>
            The GetMasterVolumeLevel method gets the master volume level, in decibels, of the audio stream that enters or leaves the audio endpoint device.
            </summary>
            <param name="levelDB">
            Pointer to the master volume level. This parameter points to a float variable into which the method writes the volume level in decibels. To get the range of volume levels
            obtained from this method, call the IAudioEndpointVolume.GetVolumeRange method.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IAudioEndpointVolumeEx.GetMasterVolumeLevelScalar(System.Single@)">
            <summary>
            The GetMasterVolumeLevelScalar method gets the master volume level of the audio stream that enters or leaves the audio endpoint device. The volume level is expressed as a
            normalized, audio-tapered value in the range from 0.0 to 1.0.
            </summary>
            <param name="level">
            Pointer to the master volume level. This parameter points to a float variable into which the method writes the volume level. The level is expressed as a normalized value
            in the range from 0.0 to 1.0.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IAudioEndpointVolumeEx.SetChannelVolumeLevel(System.UInt32,System.Single,System.Guid@)">
            <summary>
            The SetChannelVolumeLevel method sets the volume level, in decibels, of the specified channel of the audio stream that enters or leaves the audio endpoint device.
            </summary>
            <param name="channel">
            The channel number. If the audio stream contains n channels, the channels are numbered from 0 to n – 1. To obtain the number of channels, call the
            IAudioEndpointVolume.GetChannelCount method.
            </param>
            <param name="levelDB">
            The new volume level in decibels. To obtain the range and granularity of the volume levels that can be set by this method,
            call the IAudioEndpointVolume.GetVolumeRange method.
            </param>
            <param name="eventContext">
            Context value for the IAudioEndpointVolumeCallback.OnNotify method. This parameter points to an event-context GUID. If the SetChannelVolumeLevel call changes the volume
            level of the endpoint, all clients that have registered IAudioEndpointVolumeCallback interfaces with that endpoint will receive notifications.
            In its implementation of the OnNotify method, a client can inspect the event-context GUID to discover whether it or another client is the source of the volume-change event.
            If the caller supplies a NULL pointer for this parameter, the notification routine receives the context GUID value GUID_NULL.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IAudioEndpointVolumeEx.SetChannelVolumeLevelScalar(System.UInt32,System.Single,System.Guid@)">
            <summary>
            The SetChannelVolumeLevelScalar method sets the normalized, audio-tapered volume level of the specified channel in the audio stream that enters or leaves the audio
            endpoint device.
            </summary>
            <param name="channel">
            The channel number. If the audio stream contains n channels, the channels are numbered from 0 to n – 1. To obtain the number of channels,
            call the IAudioEndpointVolume.GetChannelCount method.
            </param>
            <param name="level">
            The volume level. The volume level is expressed as a normalized value in the range from 0.0 to 1.0.
            </param>
            <param name="eventContext">
            Context value for the IAudioEndpointVolumeCallback.OnNotify method. This parameter points to an event-context GUID. If the SetChannelVolumeLevelScalar call changes the
            volume level of the endpoint, all clients that have registered IAudioEndpointVolumeCallback interfaces with that endpoint will receive notifications.
            In its implementation of the OnNotify method, a client can inspect the event-context GUID to discover whether it or another client is the source of the volume-change event.
            If the caller supplies a NULL pointer for this parameter, the notification routine receives the context GUID value GUID_NULL.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IAudioEndpointVolumeEx.GetChannelVolumeLevel(System.UInt32,System.Single@)">
            <summary>
            The GetChannelVolumeLevel method gets the volume level, in decibels, of the specified channel in the audio stream that enters or leaves the audio endpoint device.
            </summary>
            <param name="channel">
            The channel number. If the audio stream has n channels, the channels are numbered from 0 to n – 1. To obtain the number of channels in the stream,
            call the IAudioEndpointVolume.GetChannelCount method.
            </param>
            <param name="levelDB">
            Pointer to a float variable into which the method writes the volume level in decibels. To get the range of volume levels obtained from this method,
            call the IAudioEndpointVolume.GetVolumeRange method. 
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IAudioEndpointVolumeEx.GetChannelVolumeLevelScalar(System.UInt32,System.Single@)">
            <summary>
            The GetChannelVolumeLevelScalar method gets the normalized, audio-tapered volume level of the specified channel of the audio stream that enters or leaves
            the audio endpoint device.
            </summary>
            <param name="cannel">
            The channel number. If the audio stream contains n channels, the channels are numbered from 0 to n – 1. To obtain the number of channels,
            call the IAudioEndpointVolume.GetChannelCount method.
            </param>
            <param name="level">
            Pointer to a float variable into which the method writes the volume level. The level is expressed as a normalized value in the range from 0.0 to 1.0.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IAudioEndpointVolumeEx.SetMute(System.Boolean,System.Guid@)">
            <summary>
            The SetMute method sets the muting state of the audio stream that enters or leaves the audio endpoint device.
            </summary>
            <param name="mute">
            The new muting state. If Mute is TRUE, the method mutes the stream. If FALSE, the method turns off muting.
            </param>
            <param name="eventContext">
            Context value for the IAudioEndpointVolumeCallback.OnNotify method. This parameter points to an event-context GUID. If the SetMute call changes the muting state of the
            endpoint, all clients that have registered IAudioEndpointVolumeCallback interfaces with that endpoint will receive notifications.
            In its implementation of the OnNotify method, a client can inspect the event-context GUID to discover whether it or another client is the source of the control-change event.
            If the caller supplies a NULL pointer for this parameter, the notification routine receives the context GUID value GUID_NULL.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IAudioEndpointVolumeEx.GetMute(System.Boolean@)">
            <summary>
            The GetMute method gets the muting state of the audio stream that enters or leaves the audio endpoint device.
            </summary>
            <param name="mute">
            Pointer to a BOOL variable into which the method writes the muting state. If mute is TRUE, the stream is muted. If FALSE, the stream is not muted.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IAudioEndpointVolumeEx.GetVolumeStepInfo(System.UInt32@,System.UInt32@)">
            <summary>
            The GetVolumeStepInfo method gets information about the current step in the volume range.
            </summary>
            <param name="step">
            Pointer to a UINT variable into which the method writes the current step index. This index is a value in the range from 0 to stepCount – 1, where 0 represents the minimum
            volume level and stepCount – 1 represents the maximum level.
            </param>
            <param name="stepCount">
            Pointer to a UINT variable into which the method writes the number of steps in the volume range. This number remains constant for the lifetime of the IAudioEndpointVolume
            interface instance.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IAudioEndpointVolumeEx.VolumeStepUp(System.Guid@)">
            <summary>
            The VolumeStepUp method increments, by one step, the volume level of the audio stream that enters or leaves the audio endpoint device.
            </summary>
            <param name="eventContext">
            Context value for the IAudioEndpointVolumeCallback.OnNotify method. This parameter points to an event-context GUID. If the VolumeStepUp call changes the volume level
            of the endpoint, all clients that have registered IAudioEndpointVolumeCallback interfaces with that endpoint will receive notifications. In its implementation of the
            OnNotify method, a client can inspect the event-context GUID to discover whether it or another client is the source of the volume-change event.
            If the caller supplies a NULL pointer for this parameter, the client's notification method receives a NULL context pointer.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IAudioEndpointVolumeEx.VolumeStepDown(System.Guid@)">
            <summary>
            The VolumeStepDown method decrements, by one step, the volume level of the audio stream that enters or leaves the audio endpoint device.
            </summary>
            <param name="eventContext">
            Context value for the IAudioEndpointVolumeCallback.OnNotify method. This parameter points to an event-context GUID. If the VolumeStepDown call changes the volume level
            of the endpoint, all clients that have registered IAudioEndpointVolumeCallback interfaces with that endpoint will receive notifications.
            In its implementation of the OnNotify method, a client can inspect the event-context GUID to discover whether it or another client is the source of the volume-change event.
            If the caller supplies a NULL pointer for this parameter, the client's notification method receives a NULL context pointer.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IAudioEndpointVolumeEx.QueryHardwareSupport(CoreAudioApi.EndpointHardwareSupport@)">
            <summary>
            The QueryHardwareSupport method queries the audio endpoint device for its hardware-supported functions.
            </summary>
            <param name="hardwareSupportMask">
            Pointer to a DWORD variable into which the method writes a hardware support mask that indicates the hardware capabilities of the audio endpoint device.
            The method can set the mask to 0 or to the bitwise-OR combination of one or more EndpointHardwareSupport enumerator.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IAudioEndpointVolumeEx.GetVolumeRange(System.Single@,System.Single@,System.Single@)">
            <summary>
            The GetVolumeRange method gets the volume range, in decibels, of the audio stream that enters or leaves the audio endpoint device.
            </summary>
            <param name="volumeMindB">
            Pointer to the minimum volume level. This parameter points to a float variable into which the method writes the minimum volume level in decibels.
            This value remains constant for the lifetime of the IAudioEndpointVolume interface instance.
            </param>
            <param name="volumeMaxdB">
            Pointer to the maximum volume level. This parameter points to a float variable into which the method writes the maximum volume level in decibels.
            This value remains constant for the lifetime of the IAudioEndpointVolume interface instance.
            </param>
            <param name="volumeIncrementdB">
            Pointer to the volume increment. This parameter points to a float variable into which the method writes the volume increment in decibels.
            This increment remains constant for the lifetime of the IAudioEndpointVolume interface instance.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IAudioEndpointVolumeEx.GetVolumeRangeChannel(System.UInt32,System.Single@,System.Single@,System.Single@)">
            <summary>
            The GetVolumeRangeChannel method gets the volume range for a specified channel.
            </summary>
            <param name="channel">
            The channel number for which to get the volume range. If the audio stream has n channels, the channels are numbered from 0 to n – 1.
            To obtain the number of channels in the stream, call the IAudioEndpointVolume.GetChannelCount method.
            </param>
            <param name="volumeMinDB">
            Receives the minimum volume level for the channel, in decibels.
            </param>
            <param name="volumeMaxDB">
            Receives the maximum volume level for the channel, in decibels.
            </param>
            <param name="volumeIncrementDB">
            Receives the volume increment for the channel, in decibels.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="T:CoreAudioApi.WaveFileReader">
            <summary>
            Öffnet eine Wave-Datei und ermöglicht es, blockweise Audiodaten daraus zu lesen. Die Blöcke werden als kanalweise verschachtelte Byte-Arrays oder als
            mehrkanalige Double-Arrays, deren Wertebereich sich zwischen -1.0 und 1.0 bewegt, zurückgegeben.
            </summary>
        </member>
        <member name="M:CoreAudioApi.WaveFileReader.#ctor(System.String,System.Int32)">
            <summary>
            Öffnet eine Wave-Datei und ermöglicht es, blockweise Audiodaten daraus zu lesen. Die Blöcke werden als kanalweise verschachtelte Byte-Arrays oder als
            mehrkanalige Double-Arrays, deren Wertebereich sich zwischen -1.0 und 1.0 bewegt, zurückgegeben.
            </summary>
            <param name="FileName">
            Filename der Wave-Datei.
            </param>
            <param name="AudioFrames">
            Gibt an, wie viele Audioframes während eines Lesezyklus (Methodenaufruf) gelesen werden sollen.
            Für den Betrieb von FFT oder Filtern sind Vielfache von 2 (1024 bis 4096 ...) ein Richtwert.
            Sehr kleine Werte ( &gt; 1024 ) erfordern mehr Rechenleistung.
            </param>
        </member>
        <member name="M:CoreAudioApi.WaveFileReader.#ctor(System.String,System.Int32,System.Int32)">
            <summary>
            Öffnet eine Wave-Datei und ermöglicht es, blockweise Audiodaten daraus zu lesen. Die Blöcke werden als kanalweise verschachtelte Byte-Arrays oder als
            mehrkanalige Double-Arrays, deren Wertebereich sich zwischen -1.0 und 1.0 bewegt, zurückgegeben.
            </summary>
            <param name="FileName">
            Filename der Wave-Datei.
            </param>
            <param name="AudioFrames">
            Gibt an, wie viele Audioframes während eines Lesezyklus (Methodenaufruf) gelesen werden sollen.
            Für den Betrieb von FFT oder Filtern sind Vielfache von 2 (1024 bis 4096 ...) ein Richtwert.
            Sehr kleine Werte ( &gt; 1024 ) erfordern mehr Rechenleistung.
            </param>
            <param name="BufferSize">
            Legt die Größe des zugrunde liegenden Filestreams in Bytes fest. Größere Puffer führen zu selteneren Festplattenzugriffen.
            Bytes für etwa 4 s Audio bei der erwarteten Samplerate, Auflösung und Kanalzahl sind ein guter Wert.
            </param>
        </member>
        <member name="M:CoreAudioApi.WaveFileReader.ReadNextBlockAsDouble">
            <summary>
            Liest einen Block Audiodaten aus der Datei in ein mehrkanaliges Double-Array. Die gelesenen Werte bewegen sich im Bereich von -1.0 bis 1.0.
            Dabei schließen sich die Daten im Array an die des letzten Aufrufes von ReadNextBlockAsDouble an. Ist das Ende der Datei erreicht, werden entweder "stille" Arrays zurückgegeben oder,
            wenn Loop = true ist, der Lesevorgang an ihrem Anfang fortgesetzt.
            </summary>
            <returns>
            Mehrkanaliges Double-Array mit gelesenen Audiodaten.
            </returns>
        </member>
        <member name="M:CoreAudioApi.WaveFileReader.ReadNextBlock">
            <summary>
            Liest in ein Byte-Array einen Block Audiodaten aus der Datei. Dabei schließen sich die Daten im Array an die des letzten Aufrufes von ReadNextBlock an.
            Ist das Ende der Datei erreicht, werden entweder "stille" Arrays zurückgegeben oder, wenn Loop = true ist, wird beim Erreichen des Dateiendes der
            Lesevorgang am Anfang fortgesetzt.
            </summary>
            <returns>
            Byte-Array mit gelesenen Audiodaten.
            </returns>
        </member>
        <member name="M:CoreAudioApi.WaveFileReader.ToString">
            <summary>
            Gibt die Haupteigenschaften des WaveFileReader als Zeichenkette zurück.
            </summary>
            <returns>
            Haupteigenschaften des WaveFileReader.
            </returns>
        </member>
        <member name="M:CoreAudioApi.WaveFileReader.Dispose">
            <summary>
            Gibt die Ressourcen des WaveFileReader frei. Schließt den File-Stream.
            </summary>
        </member>
        <member name="M:CoreAudioApi.WaveFileReader.Dispose(System.Boolean)">
            <summary>
            Gibt die Ressourcen des WaveFileReader frei. Schließt den File-Stream.
            </summary>
            <param name="disposing">
            true, es werden auch verwaltete Objekte frei gegeben.
            false, wenn die Methode aus einem Destructor aufgerufen werden soll.
            </param>
        </member>
        <member name="M:CoreAudioApi.WaveFileReader.Finalize">
            <summary>
            Destructor
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFileReader.Disposed">
            <summary>
            Ruft ab, ob das Element frei gegeben wurde.
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFileReader.WaveFormatTag">
            <summary>
            Gibt das Format an, in dem die Audiodaten in der Datei gespeichert sind.
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFileReader.Channels">
            <summary>
            Gibt an, wie viele Kanäle in der Datei gespeichert sind.
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFileReader.SamplesPerSecond">
            <summary>
            Gibt an, wie viele Audioframes pro Sekunde Audiodaten in der Datei gespeichert sind.
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFileReader.BytesPerSecond">
            <summary>
            Gibt an, wie viele Bytes pro Sekunde Audiodaten in der Datei gespeichert sind.
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFileReader.BlockAlign">
            <summary>
            Gibt an, durch wie viele Bytes ein Audioframe dargestellt wird.
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFileReader.BitsPerSample">
            <summary>
            Gibt an, wie viele Datenbytes zu einem Audioframe gehören (BlockAlign = Channels * BitsPerSample / 8).
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFileReader.ExtraSize">
            <summary>
            Gibt die Größe der erweiterten Formatangaben zurück.
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFileReader.BitsPerSamplesPerBlock">
            <summary>
            Gibt die Anzahl der validen Bits zurück.
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFileReader.ChannelMask">
            <summary>
            Gibt die Zuordnung der Lautsprecher zu den gespeicherten Audiodatenspuren zurück.
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFileReader.MediaSubFormat">
            <summary>
            Gibt den Datenformat-Code zurück.
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFileReader.PadPosition">
            <summary>
            Gibt die Position des ersten Datenbytes des PAD-Chunks zurück.
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFileReader.PadSize">
            <summary>
            Gibt die Länge des PAD-Chunks in Byte zurück.
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFileReader.FileName">
            <summary>
            Gibt den Filename der Wave-Datei zurück.
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFileReader.CanConvertToDouble">
            <summary>
            Gibt an, ob das vorliegende Format es erlaubt, die Audiodaten mit der Methode ReadNextBlockAsDouble() gelese werden können.
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFileReader.AudioFrames">
            <summary>
            Gibt die Anzahl der in der Datei gespeicherten Audioframes zurück.
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFileReader.PlayTimeFile">
            <summary>
            Gibt die gesamte Spielzeit der geöffneten Datei an.
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFileReader.PlayPosition">
            <summary>
            Gibt an oder legt fest, welcher Audioframe als nächstes gelesen wird.
            Der Wert bezieht sich auf den Beginn der Audiodaten in der Datei und ist 0-basiert.
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFileReader.PlayTimeNow">
            <summary>
            Gibt an, bei welcher Zeit die Datei gerade abgespielt wird.
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFileReader.Loop">
            <summary>
            Gibt an oder legt fest, ob der Lesevorgang beim Erreichen des Dateiendes an Anfang der Datei fortgesetzt werden soll.
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFileReader.WaveFormatExtensible">
            <summary>
            Liefert die Angaben zum Format der in der Datei gespeicherten Audiodaten in einer WaveFormatExtensible-Struktur.
            </summary>
        </member>
        <member name="T:CoreAudioApi.WaveFileReader.Chunk">
            <summary>
            Beinhaltet Namen und Positionsdaten eines Chunks einer Wave-Datei.
            </summary>
        </member>
        <member name="M:CoreAudioApi.WaveFileReader.Chunk.#ctor(System.String,System.Int64,System.Int64)">
            <summary>
            Beinhaltet Namen und Positionsdaten eines Chunks einer Wave-Datei.
            </summary>
            <param name="Name">
            Name des Chunks.
            </param>
            <param name="Position">
            Position des ersten Datenbytes eines Chunks.
            </param>
            <param name="Länge">
            Anzahl der Datenbytes in einem Chunk.
            </param>
        </member>
        <member name="M:CoreAudioApi.WaveFileReader.Chunk.ToString">
            <summary>
            Gibt den Namen des Chunks als Zeichenkette zurück.
            </summary>
            <returns>
            Namen des Chunks.
            </returns>
        </member>
        <member name="P:CoreAudioApi.WaveFileReader.Chunk.Name">
            <summary>
            Name des Chunks.
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFileReader.Chunk.Position">
            <summary>
            Position des ersten Datenbytes eines Chunks.
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFileReader.Chunk.Länge">
            <summary>
            Anzahl der Datenbytes in einem Chunk.
            </summary>
        </member>
        <member name="T:CoreAudioApi.WaveFileWriter">
            <summary>
            Erstellt eine Wave-Datei und ermöglicht es, blockweise hinein zu schreiben. Die Blöcke können als kanalweise verschachtelte Byte-Arrays oder als mehrkanalige
            Double-Arrays übergeben werden. Bei einem eingetretenen Fehler wird versucht die Datei zu schließen, aber nicht zu löschen.
            Es werden die Formate PCM, in den Auflösungen 8, 16, 24 und 32 Bit, und IEEEFloat mit 32 und 64 Bit pro Sample unterstützt. Zum Requantisieren auf 8 oder 16 Bit
            sollte nicht die Methode WriteNextBlockFromDouble() sondern WriteNextBlock() in Verbindung mit der Klasse ToByteConverter genutzt werden, um Quantisierungsfehler
            zu minimieren.
            </summary>
        </member>
        <member name="M:CoreAudioApi.WaveFileWriter.#ctor(System.String,CoreAudioApi.WaveFormatExtensible)">
            <summary>
            Erstellt eine Wave-Datei und ermöglicht es, blockweise hinein zu schreiben. Die Blöcke können als kanalweise verschachtelte Byte-Arrays oder als mehrkanalige
            Double-Arrays übergeben werden. Bei einem eingetretenen Fehler wird versucht die Datei zu schließen, aber nicht zu löschen.
            Es werden die Formate PCM, in den Auflösungen 8, 16, 24 und 32 Bit, und IEEEFloat mit 32 und 64 Bit pro Sample unterstützt. Zum Requantisieren auf 8 oder 16 Bit
            sollte nicht die Methode WriteNextBlockFromDouble() sondern WriteNextBlock() in Verbindung mit der Klasse ToByteConverter genutzt werden, um Quantisierungsfehler
            zu minimieren.
            </summary>
            <param name="FileName">
            Der komplette Pfad der zu schreibenden Datei.
            </param>
            <param name="waveFormatExtensible">
            WaveFormatExtensible mit den Formatvorgaben der zu schreibenden Datei.
            </param>
        </member>
        <member name="M:CoreAudioApi.WaveFileWriter.#ctor(System.String,CoreAudioApi.WaveFormatExtensible,System.Int32)">
            <summary>
            Erstellt eine Wave-Datei und ermöglicht es, blockweise hinein zu schreiben. Die Blöcke können als kanalweise verschachtelte Byte-Arrays oder als mehrkanalige
            Double-Arrays übergeben werden. Bei einem eingetretenen Fehler wird versucht die Datei zu schließen, aber nicht zu löschen.
            Es werden die Formate PCM, in den Auflösungen 8, 16, 24 und 32 Bit, und IEEEFloat mit 32 und 64 Bit pro Sample unterstützt. Zum Requantisieren auf 8 oder 16 Bit
            sollte nicht die Methode WriteNextBlockFromDouble() sondern WriteNextBlock() in Verbindung mit der Klasse ToByteConverter genutzt werden, um Quantisierungsfehler
            zu minimieren.
            </summary>
            <param name="FileName">
            Der komplette Pfad der zu schreibenden Datei.
            </param>
            <param name="waveFormatExtensible">
            WaveFormatExtensible mit den Formatvorgaben der zu schreibenden Datei.
            </param>
            <param name="PadSize">
            Legt fest, wie viele Bytes der PAD-Chunk beinhalten soll, der dazu dient, einen freien Raum vor den Audiodaten zu schaffen, damit diese zusätzliche Daten in die Datei
            schreiben können. Die minimale Größe wird 4 Byte und die maximale 65536 Byte sein, auch wenn andere Werte für PadSize angegeben werden. Die endgültige Größe wird der
            nächst kleinere geradzahlige Wert von PadSize werden.
            </param>
        </member>
        <member name="M:CoreAudioApi.WaveFileWriter.#ctor(System.String,System.Int32,CoreAudioApi.WaveFormatExtensible)">
            <summary>
            Erstellt eine Wave-Datei und ermöglicht es, blockweise hinein zu schreiben. Die Blöcke können als kanalweise verschachtelte Byte-Arrays oder als mehrkanalige
            Double-Arrays übergeben werden. Bei einem eingetretenen Fehler wird versucht die Datei zu schließen, aber nicht zu löschen.
            Es werden die Formate PCM, in den Auflösungen 8, 16, 24 und 32 Bit, und IEEEFloat mit 32 und 64 Bit pro Sample unterstützt. Zum Requantisieren auf 8 oder 16 Bit
            sollte nicht die Methode WriteNextBlockFromDouble() sondern WriteNextBlock() in Verbindung mit der Klasse ToByteConverter genutzt werden, um Quantisierungsfehler
            zu minimieren.
            </summary>
            <param name="FileName">
            Der komplette Pfad der zu schreibenden Datei.
            </param>
            <param name="BufferSize">
            Legt die Größe des Streampuffers in Audio-Frames fest. Größere Puffer führen zu selteneren Festplattenzugriffen.
            Audio-Frames für 4 s sind ein guter Wert. Bei Werten kleiner als 1 wird automatisch ein Puffer für 4 s Audio erzeugt.
            </param>
            <param name="waveFormatExtensible">
            WaveFormatExtensible mit den Formatvorgaben der zu schreibenden Datei.
            </param>
        </member>
        <member name="M:CoreAudioApi.WaveFileWriter.#ctor(System.String,System.Int32,CoreAudioApi.WaveFormatExtensible,System.Int32)">
            <summary>
            Erstellt eine Wave-Datei und ermöglicht es, blockweise hinein zu schreiben. Die Blöcke können als kanalweise verschachtelte Byte-Arrays oder als mehrkanalige
            Double-Arrays übergeben werden. Bei einem eingetretenen Fehler wird versucht die Datei zu schließen, aber nicht zu löschen.
            Es werden die Formate PCM, in den Auflösungen 8, 16, 24 und 32 Bit, und IEEEFloat mit 32 und 64 Bit pro Sample unterstützt. Zum Requantisieren auf 8 oder 16 Bit
            sollte nicht die Methode WriteNextBlockFromDouble() sondern WriteNextBlock() in Verbindung mit der Klasse ToByteConverter genutzt werden, um Quantisierungsfehler
            zu minimieren.
            </summary>
            <param name="FileName">
            Der komplette Pfad der zu schreibenden Datei.
            </param>
            <param name="BufferSize">
            Legt die Größe des Streampuffers in Audio-Frames fest. Größere Puffer führen zu selteneren Festplattenzugriffen.
            Audio-Frames für 4 s sind ein guter Wert. Bei Werten kleiner als 1 wird automatisch ein Puffer für 4 s Audio erzeugt.
            </param>
            <param name="waveFormatExtensible">
            WaveFormatExtensible mit den Formatvorgaben der zu schreibenden Datei.
            </param>
            <param name="PadSize">
            Legt fest, wie viele Bytes der PAD-Chunk beinhalten soll, der dazu dient, einen freien Raum vor den Audiodaten zu schaffen, damit diese zusätzliche Daten in die Datei
            schreiben können. Die minimale Größe wird 4 Byte und die maximale 65536 Byte sein, auch wenn andere Werte für PadSize angegeben werden. Die endgültige Größe wird der
            nächst kleinere geradzahlige Wert von PadSize werden.
            </param>
        </member>
        <member name="M:CoreAudioApi.WaveFileWriter.WriteNextBlockFromDouble(System.Double[0:,0:])">
            <summary>
            Schreibt die Audiodaten aus einem zweidimensionalen Double-Array, dessen Wertebereich dem Zielformat entsprechen muß, in eine Wave-Datei.
            Dabei schließen sich die aktuellen Audiodaten an jene des vorherigen Schreibvorganges an.
            Nach dem Speichern des letzten Blockes muß die Methode Close() dieser Klasse aufgerufen werden, um die Datei abzuschließen.
            Es ist dafür zu sorgen, daß das Format der übergebenen Audiodaten tatsächlich dem des im Konstruktor übergebenen WaveFormatExtensible entspricht.
            </summary>
            <param name="AudioData">
            Array mit Audiodaten.
            </param>
        </member>
        <member name="M:CoreAudioApi.WaveFileWriter.WriteNextBlock(System.Byte[])">
            <summary>
            Schreibt ein kanalverschachteltes Byte-Array in die Wave-Datei. Dabei schließen sich die aktuellen Audiodaten an jene des vorherigen Schreibvorganges an.
            Nach dem Speichern des letzten Blockes muß die Methode Close() dieser Klasse aufgerufen werden, um die Datei abzuschließen.
            Es ist dafür zu sorgen, daß das Format der übergebenen Audiodaten tatsächlich dem des im Konstruktor übergebenen WaveFormatExtensible entspricht.
            </summary>
            <param name="AudioData">
            Kanalverschachteltes Byte-Array mit Audiodaten.
            </param>
        </member>
        <member name="M:CoreAudioApi.WaveFileWriter.WriteNextBlock(System.Int16[])">
            <summary>
            Schreibt ein kanalverschachteltes Short-Array in die Wave-Datei. Dabei schließen sich die aktuellen Audiodaten an jene des vorherigen Schreibvorganges an.
            Nach dem Speichern des letzten Blockes muß die Methode Close() dieser Klasse aufgerufen werden, um die Datei abzuschließen.
            Es ist dafür zu sorgen, daß das Format der übergebenen Audiodaten tatsächlich dem des im Konstruktor übergebenen WaveFormatExtensible entspricht.
            </summary>
            <param name="AudioData">
            Kanalverschachteltes Short-Array mit Audiodaten.
            </param>
        </member>
        <member name="M:CoreAudioApi.WaveFileWriter.Close">
            <summary>
            Schließt die Wavedatei und schreibt die Dateilänge und die Anzahl der Audiodaten in den Kopf. Wurden noch keine Audiodaten geschrieben, wird ein Audioframe mit
            dem Wert 0 in die Datei geschrieben. Close muß zum Beenden des Speicherns in die Datei immer aufgerufen werden!
            </summary>
        </member>
        <member name="M:CoreAudioApi.WaveFileWriter.ToString">
            <summary>
            Gibt die Haupteigenschaften des WaveFileWriter als Zeichenkette zurück.
            </summary>
            <returns>
            Haupteigenschaften des WaveFileWriter.
            </returns>
        </member>
        <member name="M:CoreAudioApi.WaveFileWriter.Dispose">
            <summary>
            Gibt die Ressourcen des WaveFileWriter frei. Schließt den File-Stream.
            </summary>
        </member>
        <member name="M:CoreAudioApi.WaveFileWriter.Dispose(System.Boolean)">
            <summary>
            Gibt die Ressourcen des WaveFileWriter frei. Schließt den File-Stream.
            </summary>
            <param name="disposing">
            true, es werden auch verwaltete Objekte frei gegeben.
            false, wenn die Methode aus einem Destructor aufgerufen werden soll.
            </param>
        </member>
        <member name="M:CoreAudioApi.WaveFileWriter.Finalize">
            <summary>
            Destructor
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFileWriter.Disposed">
            <summary>
            Ruft ab, ob das Element frei gegeben wurde.
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFileWriter.WaveFormatTag">
            <summary>
            Gibt das Format an, in dem die Audiodaten in der Datei gespeichert werden.
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFileWriter.Channels">
            <summary>
            Gibt an, wie viele Kanäle in die Datei gespeichert werden.
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFileWriter.SamplesPerSecond">
            <summary>
            Gibt an, wie viele Audioframes pro Sekunde Audiodaten in die Datei gespeichert werden.
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFileWriter.BytesPerSecond">
            <summary>
            Gibt an, wie viele Bytes pro Sekunde Audiodaten in die Datei gespeichert werden.
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFileWriter.BlockAlign">
            <summary>
            Gibt an, wie viele Datenbytes zu einem Audioframe gehören (BlockAlign = Channels * BitsPerSample / 8).
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFileWriter.BitsPerSample">
            <summary>
            Gibt an, durch wie viele Bits ein Sample in einem Kanal dargestellt wird.
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFileWriter.ExtraSize">
            <summary>
            Gibt die Größe der erweiterten Formatangaben zurück.
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFileWriter.BitsPerSamplesPerBlock">
            <summary>
            Gibt die Anzahl der validen Bits zurück.
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFileWriter.ChannelMask">
            <summary>
            Gibt die Zuordnung der Lautsprecher zu den gespeicherten Audiodatenspuren zurück.
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFileWriter.MediaSubFormat">
            <summary>
            Gibt den Datenformat-Code zurück.
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFileWriter.FileName">
            <summary>
            Gibt den Filename der zu schreibenden Wave-Datei zurück.
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFileWriter.PadSize">
            <summary>
            Gibt an, wie viele Bytes der PAD-Chunk beinhaltet, der dazu dient, einen freien Raum vor den Audiodaten zu schaffen, damit diese zusätzliche Daten in die Datei schreiben
            können. Die minimale Größe ist 4 Byte und die maximale 65536 Byte.
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFileWriter.WritePosition">
            <summary>
            Gibt an, wie viele Audioframes momentan in die Datei geschrieben wurden.
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFileWriter.MaxAudioFrames">
            <summary>
            Gibt an, wie viele Audioframes in die Wav-Datei, abhängig vom Dateisystem auf dem sie angelegt werden soll, maximal geschrieben werden können.
            Dabei ist nicht berücksichtigt, wie viel Speicherplatz frei ist.
            </summary>
        </member>
        <member name="P:CoreAudioApi.WaveFileWriter.WriteTime">
            <summary>
            Gibt an, wie lange Audioframes bis zum Abruf in die Datei geschrieben wurden.
            </summary>
        </member>
        <member name="T:CoreAudioApi.PropertyKey">
            <summary>
            Specifies the FMTID/PID identifier that programmatically identifies a property.
            </summary>
        </member>
        <member name="M:CoreAudioApi.PropertyKey.#ctor(System.Guid,System.Int32)">
            <summary>
            Specifies the FMTID/PID identifier that programmatically identifies a property.
            </summary>
            <param name="PropertyGuid">
            A unique GUID for the property
            </param>
            <param name="PropertyIndex">
            A property identifier (PID). It is recommended that you set this value to PID_FIRST_USABLE. Any value greater than or equal to 2 is acceptable.
            Values of 0 and 1 are reserved and should not be used.
            </param>
        </member>
        <member name="M:CoreAudioApi.PropertyKey.ToString">
            <summary>
            Returns the PropertyKey as String.
            </summary>
            <returns>
            PropertyKey as String
            </returns>
        </member>
        <member name="P:CoreAudioApi.PropertyKey.PropertyGuid">
            <summary>
            A unique GUID for the property
            </summary>
        </member>
        <member name="P:CoreAudioApi.PropertyKey.PropertyIndex">
            <summary>
            A property identifier (PID). It is recommended that you set this value to PID_FIRST_USABLE. Any value greater than or equal to 2 is acceptable.
            Values of 0 and 1 are reserved and should not be used.
            </summary>
        </member>
        <member name="T:CoreAudioApi.CoreAudioException">
            <summary>
            Stellt Fehler dar, die bei der Ausführung der CoreAudioApi entstehen können.
            </summary>
        </member>
        <member name="M:CoreAudioApi.CoreAudioException.#ctor">
            <summary>
            Stellt Fehler dar, die bei der Ausführung der CoreAudioApi entstehen können.
            </summary>
        </member>
        <member name="M:CoreAudioApi.CoreAudioException.#ctor(System.String)">
            <summary>
            Stellt Fehler dar, die bei der Ausführung der CoreAudioApi entstehen können.
            </summary>
            <param name="message">
            Ruft eine Meldung ab, die die aktuelle Ausnahme beschreibt.
            </param>
        </member>
        <member name="M:CoreAudioApi.CoreAudioException.#ctor(System.String,System.Exception)">
            <summary>
            Stellt Fehler dar, die bei der Ausführung der CoreAudioApi entstehen können.
            </summary>
            <param name="message">
            Ruft eine Meldung ab, die die aktuelle Ausnahme beschreibt.
            </param>
            <param name="innerException">
            Ruft die Exception-Instanz ab, die die Ausnahme ausgelöst hat.
            </param>
        </member>
        <member name="T:CoreAudioApi.CoreAudioErrorCodes">
            <summary>
            Listet Fehler auf, die bei der Ausführung der CoreAudioApi entstehen können.
            </summary>
        </member>
        <member name="T:CoreAudioApi.AudioEndpointVolumeEx">
            <summary>
            Stellt Methoden zur Beeinflussung der Lautstätke eines Audio-Streams von oder zu einem Audio-Endpoint bereit. Ein AudioEndpointVolumeEx-Objekt kann aus der
            AudioEndpointVolumeEx-Eigenschaft einer IMMDevice-Klasse gewonnen werden.
            Besitzt ein Audiogerät (Soundkarte) hardwarebasierte Einstellmöglichkeiten für Volume und Mute, werden diese zur Einstellung des Pegels genutzt. Ist das nicht der Fall, wird
            der Pegel automatisch softwareseitig beeinflusst. Im Falle des Vorhandenseins von Hardware-Reglern werden damit sowohl Audio-Streams im Share-Mode wie im Exclusive-Mode
            beeinflusst. Im anderen Fall bleiben Exclusive-Mode-Streams unbeeinflusst. Mit der Methode AudioEndpointVolume.QueryHardwareSupport kann bestimmt werden, ob das Audiogerät
            Hardwareregler besitzt.
            Bei Share-Mode-Rendering-Streams wirken die Methoden der AudioEndpointVolumeEx unabhängig von jenen Einstellungen, die sessionsbezogen mit Hilfe der ISimpleAudioVolume- und
            IChannelAudioVolume-Schnittstellen getätigt werden (Dämpfungen multiplizieren sich). Dagegen wirken die Einstellungen der beiden Schnittstellen bei Share-Mode-Capture-Streams
            direkt auf jene der AudioEndpointVolumeEx-Klasse und umgekehrt(harte Verkopplung). Das kann sich in künftigen Windows-Versionen ändern. AudioEndpointVolumeEx muß nach seiner
            Verwendung mit Dispose vernichtet werden.
            </summary>
        </member>
        <member name="M:CoreAudioApi.AudioEndpointVolumeEx.#ctor(CoreAudioApi.IAudioEndpointVolumeEx)">
            <summary>
            Stellt Methoden zur Beeinflussung der Lautstätke eines Audio-Streams von oder zu einem Audio-Endpoint bereit. Ein AudioEndpointVolumeEx-Objekt kann aus der
            AudioEndpointVolumeEx-Eigenschaft einer IMMDevice-Klasse gewonnen werden.
            Besitzt ein Audiogerät (Soundkarte) hardwarebasierte Einstellmöglichkeiten für Volume und Mute, werden diese zur Einstellung des Pegels genutzt. Ist das nicht der Fall, wird
            der Pegel automatisch softwareseitig beeinflusst. Im Falle des Vorhandenseins von Hardware-Reglern werden damit sowohl Audio-Streams im Share-Mode wie im Exclusive-Mode
            beeinflusst. Im anderen Fall bleiben Exclusive-Mode-Streams unbeeinflusst. Mit der Methode AudioEndpointVolume.QueryHardwareSupport kann bestimmt werden, ob das Audiogerät
            Hardwareregler besitzt.
            Bei Share-Mode-Rendering-Streams wirken die Methoden der AudioEndpointVolumeEx unabhängig von jenen Einstellungen, die sessionsbezogen mit Hilfe der ISimpleAudioVolume- und
            IChannelAudioVolume-Schnittstellen getätigt werden (Dämpfungen multiplizieren sich). Dagegen wirken die Einstellungen der beiden Schnittstellen bei Share-Mode-Capture-Streams
            direkt auf jene der AudioEndpointVolumeEx-Klasse und umgekehrt(harte Verkopplung). Das kann sich in künftigen Windows-Versionen ändern. AudioEndpointVolumeEx muß nach seiner
            Verwendung mit Dispose vernichtet werden.
            </summary>
            <param name="iAudioEndpointVolumeEx">
            AudioEndpointVolume aus einem MMDevice.
            </param>
        </member>
        <member name="M:CoreAudioApi.AudioEndpointVolumeEx.GetChannelLevelMin(System.Int32)">
            <summary>
            Gibt den minimalen Pegel (größte Dämpfung) in dB an, der mit dem Volume-Regler des abgerufenen Kanales eingestellt werden kann.
            Der Wert bleibt über die Lebenszeit der Klasse konstant.
            </summary>
            <param name="channel">
            Kanal, dessen Wert gewünscht ist.
            </param>
            <returns>
            Minimaler Pegel in dB.
            </returns>
        </member>
        <member name="M:CoreAudioApi.AudioEndpointVolumeEx.GetChannelLevelMax(System.Int32)">
            <summary>
            Gibt den maximalen Pegel (kleinste Dämpfung) in dB an, der mit dem Volume-Regler des abgerufenen Kanales eingestellt werden kann.
            Der Wert bleibt über die Lebenszeit der Klasse konstant.
            </summary>
            <param name="channel">
            Kanal, dessen Wert gewünscht ist.
            </param>
            <returns>
            Maximaler Pegel in dB.
            </returns>
        </member>
        <member name="M:CoreAudioApi.AudioEndpointVolumeEx.GetChannelVolumeIncrement(System.Int32)">
            <summary>
            Gibt die Schrittweite in dB an, in der der Volume-Regler den Pegel des abgerufenen Kanales beeinflussen kann.
            Der Wert bleibt über die Lebenszeit der Klasse konstant.
            </summary>
            <param name="channel">
            Kanal, dessen Wert gewünscht ist.
            </param>
            <returns>
            Schrittweite in dB.
            </returns>
        </member>
        <member name="M:CoreAudioApi.AudioEndpointVolumeEx.GetMasterVolumeLevel">
            <summary>
            Gibt den MasterVolumeLevel des Audio-Streams in dB an.
            </summary>
            <returns>
            MasterVolumeLevel des Audio-Streams in dB.
            </returns>
        </member>
        <member name="M:CoreAudioApi.AudioEndpointVolumeEx.SetMasterVolumeLevel(System.Single)">
            <summary>
            Legt den MasterVolumeLevel des Audio-Streams in dB fest.
            </summary>
            <param name="level">
            MasterVolumeLevel in dB.
            </param>
        </member>
        <member name="M:CoreAudioApi.AudioEndpointVolumeEx.SetMasterVolumeLevel(System.Single,System.Guid)">
            <summary>
            Legt den MasterVolumeLevel des Audio-Streams in dB fest.
            </summary>
            <param name="level">
            MasterVolumeLevel in dB.
            </param>
            <param name="eventContext">
            Wird mitgegeben, um einem Ereignisempfänger (AudioVolumeChanged) die Identifikation des Auslösers zu ermöglichen.
            </param>
        </member>
        <member name="M:CoreAudioApi.AudioEndpointVolumeEx.GetMasterVolumeLevelScalar">
            <summary>
            Gibt den MasterVolumeLevel des Audio-Streams in einem Bereich zwischen 0.0 und 1.0 an.
            </summary>
            <returns>
            MasterVolumeLevel des Audio-Streams in einem Bereich zwischen 0.0 und 1.0.
            </returns>
        </member>
        <member name="M:CoreAudioApi.AudioEndpointVolumeEx.SetMasterVolumeLevelScalar(System.Single)">
            <summary>
            Legt den MasterVolumeLevel des Audio-Streams in einem Bereich zwischen 0.0 und 1.0 fest.
            </summary>
            <param name="level">
            MasterVolumeLevel zwischen 0.0 und 1.0.
            </param>
        </member>
        <member name="M:CoreAudioApi.AudioEndpointVolumeEx.SetMasterVolumeLevelScalar(System.Single,System.Guid)">
            <summary>
            Legt den MasterVolumeLevel des Audio-Streams in einem Bereich zwischen 0.0 und 1.0 fest.
            </summary>
            <param name="level">
            MasterVolumeLevel zwischen 0.0 und 1.0.
            </param>
            <param name="eventContext">
            Wird mitgegeben, um einem Ereignisempfänger (AudioVolumeChanged) die Identifikation des Auslösers zu ermöglichen.
            </param>
        </member>
        <member name="M:CoreAudioApi.AudioEndpointVolumeEx.GetChannelVolumeLevel(System.Int32)">
            <summary>
            Gibt den VolumeLevel des bestimmten Kanales des Audio-Streams in dB an.
            </summary>
            <param name="channel">
            Kanal, dessen Pegel abgefragt werden soll.
            </param>
            <returns>
            Pegel des gewünschten Kanales in dB.
            </returns>
        </member>
        <member name="M:CoreAudioApi.AudioEndpointVolumeEx.SetChannelVolumeLevel(System.Int32,System.Single)">
            <summary>
            Legt den VolumeLevel des bestimmten Kanales des Audio-Streams in dB fest.
            </summary>
            <param name="channel">
            Kanal, dessen Pegel beeinflusst werden soll.
            </param>
            <param name="level">
            Gewünschter Pegel in dB.
            </param>
        </member>
        <member name="M:CoreAudioApi.AudioEndpointVolumeEx.SetChannelVolumeLevel(System.Int32,System.Single,System.Guid)">
            <summary>
            Legt den VolumeLevel des bestimmten Kanales des Audio-Streams in dB fest.
            </summary>
            <param name="channel">
            Kanal, dessen Pegel beeinflusst werden soll.
            </param>
            <param name="level">
            Gewünschter Pegel in dB.
            </param>
            <param name="eventContext">
            Wird mitgegeben, um einem Ereignisempfänger (AudioVolumeChanged) die Identifikation des Auslösers zu ermöglichen.
            </param>
        </member>
        <member name="M:CoreAudioApi.AudioEndpointVolumeEx.GetChannelVolumeLevelScalar(System.Int32)">
            <summary>
            Gibt den VolumeLevel des bestimmten Kanales des Audio-Streams in einem Bereich zwischen 0.0 und 1.0 an.
            </summary>
            <param name="channel">
            Kanal, dessen Pegel abgefragt werden soll.
            </param>
            <returns>
            Pegel des gewünschten Kanales in dB.
            </returns>
        </member>
        <member name="M:CoreAudioApi.AudioEndpointVolumeEx.SetChannelVolumeLevelScalar(System.Int32,System.Single)">
            <summary>
            Legt den VolumeLevel des bestimmten Kanales des Audio-Streams in einem Bereich zwischen 0.0 und 1.0 fest.
            </summary>
            <param name="channel">
            Kanal, dessen Pegel beeinflusst werden soll.
            </param>
            <param name="level">
            Gewünschter Pegel in dB.
            </param>
        </member>
        <member name="M:CoreAudioApi.AudioEndpointVolumeEx.SetChannelVolumeLevelScalar(System.Int32,System.Single,System.Guid)">
            <summary>
            Legt den VolumeLevel des bestimmten Kanales des Audio-Streams in einem Bereich zwischen 0.0 und 1.0 fest.
            </summary>
            <param name="channel">
            Kanal, dessen Pegel beeinflusst werden soll.
            </param>
            <param name="level">
            Gewünschter Pegel in dB.
            </param>
            <param name="eventContext">
            Wird mitgegeben, um einem Ereignisempfänger (AudioVolumeChanged) die Identifikation des Auslösers zu ermöglichen.
            </param>
        </member>
        <member name="M:CoreAudioApi.AudioEndpointVolumeEx.GetMute">
            <summary>
            Gibt an, ob der Audiostream stumm geschaltet (true) ist.
            </summary>
            <returns>
            Gibt an, ob der Audiostream stumm geschaltet (true) ist.
            </returns>
        </member>
        <member name="M:CoreAudioApi.AudioEndpointVolumeEx.SetMute(System.Boolean)">
            <summary>
            Legt fest, ob der Audiostream stumm geschaltet (true) ist.
            </summary>
            <param name="mute">
            Legt fest, ob der Audiostream stumm geschaltet (true) ist.
            </param>
        </member>
        <member name="M:CoreAudioApi.AudioEndpointVolumeEx.SetMute(System.Boolean,System.Guid)">
            <summary>
            Legt fest, ob der Audiostream stumm geschaltet (true) ist.
            </summary>
            <param name="mute">
            Legt fest, ob der Audiostream stumm geschaltet (true) ist.
            </param>
            <param name="eventContext">
            Wird mitgegeben, um einem Ereignisempfänger (AudioVolumeChanged) die Identifikation des Auslösers zu ermöglichen.
            </param>
        </member>
        <member name="M:CoreAudioApi.AudioEndpointVolumeEx.VolumeStepUp">
            <summary>
            Erhöht die Lautstärke um einen Schritt.
            </summary>
        </member>
        <member name="M:CoreAudioApi.AudioEndpointVolumeEx.VolumeStepUp(System.Guid)">
            <summary>
            Erhöht die Lautstärke um einen Schritt.
            </summary>
            <param name="eventContext">
            Wird mitgegeben, um einem Ereignisempfänger (AudioVolumeChanged) die Identifikation des Auslösers zu ermöglichen.
            </param>
        </member>
        <member name="M:CoreAudioApi.AudioEndpointVolumeEx.VolumeStepDown">
            <summary>
            Senkt die Lautstärke um einen Schritt.
            </summary>
        </member>
        <member name="M:CoreAudioApi.AudioEndpointVolumeEx.VolumeStepDown(System.Guid)">
            <summary>
            Senkt die Lautstärke um einen Schritt.
            </summary>
            <param name="eventContext">
            Wird mitgegeben, um einem Ereignisempfänger (AudioVolumeChanged) die Identifikation des Auslösers zu ermöglichen.
            </param>
        </member>
        <member name="M:CoreAudioApi.AudioEndpointVolumeEx.RegisterControlChangeNotify(CoreAudioApi.AudioEndpointVolumeCallback)">
            <summary>
            Registriert ein AudioEndpointVolumeCallback-Objekt, welches es ermöglicht, bei Änderungen an den Volume-Einstellungen Ereignisse zu empfangen.
            </summary>
            <param name="audioEndpointVolumeCallback">
            Zu registrierendes AudioEndpointVolumeCallback-Objekt.
            </param>
        </member>
        <member name="M:CoreAudioApi.AudioEndpointVolumeEx.UnregisterControlChangeNotify(CoreAudioApi.AudioEndpointVolumeCallback)">
            <summary>
            Gibt ein registriertes AudioEndpointVolumeCallback-Objekt wieder frei.
            </summary>
            <param name="audioEndpointVolumeCallback">
            Freizugebendes AudioEndpointVolumeCallback-Objekt.
            </param>
        </member>
        <member name="M:CoreAudioApi.AudioEndpointVolumeEx.Dispose">
            <summary>
            Gibt die Ressourcen des AudioEndpointVolumeEx frei.
            </summary>
        </member>
        <member name="M:CoreAudioApi.AudioEndpointVolumeEx.Dispose(System.Boolean)">
            <summary>
            Gibt die Ressourcen des AudioEndpointVolumeEx frei.
            </summary>
            <param name="disposing">
            true, es werden auch verwaltete Objekte frei gegeben.
            false, wenn die Methode aus einem Destructor aufgerufen werden soll.
            </param>
        </member>
        <member name="M:CoreAudioApi.AudioEndpointVolumeEx.Finalize">
            <summary>
            Destructor
            </summary>
        </member>
        <member name="P:CoreAudioApi.AudioEndpointVolumeEx.Disposed">
            <summary>
            Ruft ab, ob das Element frei gegeben wurde.
            </summary>
        </member>
        <member name="P:CoreAudioApi.AudioEndpointVolumeEx.EventContext">
            <summary>
            Ruft ab oder legt fest, welche Guid all jenen Set-Methoden mitgegeben wird, in deren Überladung keine Guid explizit übergeben werden kann. Diese Guid wird mitgegeben,
            um einem Ereignisempfänger (AudioVolumeChanged) die Identifikation des Auslösers zu ermöglichen. Wird EventContext nicht festgelegt, ist der Wert Guid.Empty. 
            </summary>
        </member>
        <member name="P:CoreAudioApi.AudioEndpointVolumeEx.Channels">
            <summary>
            Gibt die Anzahl der Kanäle in dem Audio-Stream zurück, der den Audio-Endpoint passiert.
            Der Wert bleibt über die Lebenszeit der Klasse konstant.
            </summary>
        </member>
        <member name="P:CoreAudioApi.AudioEndpointVolumeEx.HardwareSupport">
            <summary>
            Gibt an, ob das Audiogerät die Lautstärke per Hardware einstellen kann.
            </summary>
        </member>
        <member name="P:CoreAudioApi.AudioEndpointVolumeEx.MasterLevelMin">
            <summary>
            Gibt den minimalen Pegel (größte Dämpfung) in dB an, der mit den Volume-Reglern eingestellt werden kann.
            Der Wert bleibt über die Lebenszeit der Klasse konstant.
            </summary>
        </member>
        <member name="P:CoreAudioApi.AudioEndpointVolumeEx.MasterLevelMax">
            <summary>
            Gibt den maximalen Pegel (kleinste Dämpfung) in dB an, der mit den Volume-Reglern eingestellt werden kann.
            Der Wert bleibt über die Lebenszeit der Klasse konstant.
            </summary>
        </member>
        <member name="P:CoreAudioApi.AudioEndpointVolumeEx.MasterVolumeIncrement">
            <summary>
            Gibt die Schrittweite in dB an, in der die Volume-Regler den Pegel beeinflussen können.
            Der Wert bleibt über die Lebenszeit der Klasse konstant.
            </summary>
        </member>
        <member name="P:CoreAudioApi.AudioEndpointVolumeEx.StepCount">
            <summary>
            Gibt die Anzahl der Schritte an, in denen die Lautstärke mit Hilfe der Methoden VolumeStepUp und VolumeStepDown geregelt werden kann.
            Der Wert bleibt über die Lebenszeit der Klasse konstant.
            </summary>
        </member>
        <member name="P:CoreAudioApi.AudioEndpointVolumeEx.Step">
            <summary>
            Gibt den Schritt an, auf dem sich der Volume-Regler gerade befindet.
            </summary>
        </member>
        <member name="T:CoreAudioApi.ToDoubleConverter">
            <summary>
            Stellt eine Methode bereit, die eindimensionale, kanalweise verschachtelte Byte-Arrays mit Audiodaten, wie sie für Soundgeräte oder -dateien benötigt werden, in kanalgetrennte
            Double-Arrays mit einem Wertebereich von -1.0 bis 1.0 umwandelt.
            </summary>
        </member>
        <member name="M:CoreAudioApi.ToDoubleConverter.#ctor(CoreAudioApi.WaveFormatExtensible)">
            <summary>
            Stellt eine Methode bereit, die eindimensionale, kanalweise verschachtelte Byte-Arrays mit Audiodaten, wie sie für Soundgeräte oder -dateien benötigt werden, in kanalgetrennte
            Double-Arrays mit einem Wertebereich von -1.0 bis 1.0 umwandelt.
            </summary>
            <param name="waveFormatExtensible">
            Das Quellformat der Audiodaten.
            </param>
        </member>
        <member name="M:CoreAudioApi.ToDoubleConverter.ConvertToDouble(System.Byte[])">
            <summary>
            Konvertiert ein eindimensionales, kanalverschachteltes Byte-Array mit Audiodaten in ein zweidimensionales, kanalgetrenntes Double-Array,
            dessen Wertebereich sich zwischen -1.0 und 1.0 bewegt. Bei nur einem Kanal wird ein double[n,1] zurückgegeben, bei zweien [n,2]...
            </summary>
            <param name="AudioData">
            Das zu konvertierende eindimensionale, kanalverschachtelte Array mit Audiodaten.
            </param>
            <returns>
            Zweidimensionales, kanalgetrenntes Double-Array mit Audiodaten.
            </returns>
        </member>
        <member name="M:CoreAudioApi.ToDoubleConverter.ToString">
            <summary>
            Gibt die Haupteigenschaften des ToDoubleConverter als Zeichenkette zurück.
            </summary>
            <returns>
            Haupteigenschaften des ToDoubleConverter.
            </returns>
        </member>
        <member name="T:CoreAudioApi.StorageAccessMode">
            <summary>
            StorageAccessMode
            </summary>
        </member>
        <member name="F:CoreAudioApi.StorageAccessMode.Read">
            <summary>
            Read
            </summary>
        </member>
        <member name="F:CoreAudioApi.StorageAccessMode.Write">
            <summary>
            Write
            </summary>
        </member>
        <member name="F:CoreAudioApi.StorageAccessMode.ReadWrite">
            <summary>
            Read and (or) Write
            </summary>
        </member>
        <member name="T:CoreAudioApi.EndpointFormFactors">
            <summary>
            The EndpointFormFactor enumeration defines constants that indicate the general physical attributes of an audio endpoint device.
            </summary>
        </member>
        <member name="F:CoreAudioApi.EndpointFormFactors.RemoteNetworkDevice">
            <summary>
            An audio endpoint device that the user accesses remotely through a network.
            </summary>
        </member>
        <member name="F:CoreAudioApi.EndpointFormFactors.Speakers">
            <summary>
            A set of speakers.
            </summary>
        </member>
        <member name="F:CoreAudioApi.EndpointFormFactors.LineLevel">
            <summary>
            An audio endpoint device that sends a line-level analog signal to a line-input jack on an audio adapter or that receives
            a line-level analog signal from a line-output jack on the adapter.
            </summary>
        </member>
        <member name="F:CoreAudioApi.EndpointFormFactors.Headphones">
            <summary>
            A set of headphones.
            </summary>
        </member>
        <member name="F:CoreAudioApi.EndpointFormFactors.Microphone">
            <summary>
            A microphone.
            </summary>
        </member>
        <member name="F:CoreAudioApi.EndpointFormFactors.Headset">
            <summary>
            An earphone or a pair of earphones with an attached mouthpiece for two-way communication.
            </summary>
        </member>
        <member name="F:CoreAudioApi.EndpointFormFactors.Handset">
            <summary>
            The part of a telephone that is held in the hand and that contains a speaker and a microphone for two-way communication.
            </summary>
        </member>
        <member name="F:CoreAudioApi.EndpointFormFactors.UnknownDigitalPassthrough">
            <summary>
            An audio endpoint device that connects to an audio adapter through a connector for a digital interface of unknown type that transmits non-PCM data
            in digital pass-through mode.
            </summary>
        </member>
        <member name="F:CoreAudioApi.EndpointFormFactors.SPDIF">
            <summary>
            An audio endpoint device that connects to an audio adapter through a Sony/Philips Digital Interface (S/PDIF) connector.
            </summary>
        </member>
        <member name="F:CoreAudioApi.EndpointFormFactors.DigitalAudioDisplayDevice">
            <summary>
            An audio endpoint device that connects to an audio adapter through a High-Definition Multimedia Interface (HDMI) connector or a display port.
            </summary>
        </member>
        <member name="F:CoreAudioApi.EndpointFormFactors.UnknownFormFactor">
            <summary>
            An audio endpoint device with unknown physical attributes.
            </summary>
        </member>
        <member name="F:CoreAudioApi.EndpointFormFactors.EndpointFormFactorEnumCount">
            <summary>
            Maximum number of endpoint form factors.
            </summary>
        </member>
        <member name="T:CoreAudioApi.IAudioCaptureClient">
            <summary>
            The IAudioCaptureClient interface enables a client to read input data from a capture endpoint buffer. The client obtains a reference to the IAudioCaptureClient interface on 
            a stream object by calling the IAudioClient.GetService method with parameter riid set to REFIID IID_IAudioCaptureClient. When releasing an IAudioCaptureClient interface
            instance, the client must call the Release method of the instance from the same thread as the call to IAudioClient.GetService that created the object.
            </summary>
        </member>
        <member name="M:CoreAudioApi.IAudioCaptureClient.GetBuffer(System.IntPtr@,System.Int32@,CoreAudioApi.AudioClientBufferFlags@,System.Int64@,System.Int64@)">
            <summary>
            The GetBuffer method retrieves a pointer to the next available packet of data in the capture endpoint buffer. 
            </summary>
            <param name="bufferPointer">
            Pointer to a pointer variable into which the method writes the starting address of the next data packet that is available for the client to read.
            </param>
            <param name="framesToRead">
            Pointer to a UINT32 variable into which the method writes the frame count (the number of audio frames available in the data packet). The client should either read the
            entire data packet or none of it. 
            </param>
            <param name="audioClientBufferFlags">
            Pointer to a DWORD variable into which the method writes the buffer-status flags. The method writes either 0 or the bitwise-OR combination of one or more of the
            AudioClientBufferFlags. 
            </param>
            <param name="devicePosition">
            Pointer to a UINT64 variable into which the method writes the device position of the first audio frame in the data packet. The device position is expressed as the number of
            audio frames from the start of the stream. This parameter can be NULL if the client does not require the device position.
            </param>
            <param name="qPCPosition">
            Pointer to a UINT64 variable into which the method writes the value of the performance counter at the time that the audio endpoint device recorded the device position of
            the first audio frame in the data packet. The method converts the counter value to 100-nanosecond units before writing it to qPCPosition. This parameter can be
            NULL if the client does not require the performance counter value.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IAudioCaptureClient.ReleaseBuffer(System.UInt32)">
            <summary>
            The ReleaseBuffer method releases the buffer. The client should call this method when it finishes reading a data packet that it obtained previously by calling the
            IAudioCaptureClient.GetBuffer method. The data in the packet that the client obtained from a GetBuffer call is guaranteed to remain valid until the client calls
            ReleaseBuffer to release the packet. Between each GetBuffer call and its corresponding ReleaseBuffer call, the client must either read the entire data packet or none of it.
            If the client reads the entire packet following the GetBuffer call, then it should call ReleaseBuffer with NumFramesRead set to the total number of frames in the data packet.
            In this case, the next call to GetBuffer will produce a new data packet. If the client reads none of the data from the packet following the call to GetBuffer,
            then it should call ReleaseBuffer with NumFramesRead set to 0. In this case, the next GetBuffer call will produce the same data packet as in the previous GetBuffer call.
            </summary>
            <param name="framesReaded">
            The number of audio frames that the client read from the capture buffer. This parameter must be either equal to the number of frames in the previously
            acquired data packet or 0.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IAudioCaptureClient.GetNextPacketSize(System.UInt32@)">
            <summary>
            The GetNextPacketSize method retrieves the number of frames in the next data packet in the capture endpoint buffer. Use this method only with shared-mode streams.
            It does not work with exclusive-mode streams. Before calling the IAudioCaptureClient.GetBuffer method to retrieve the next data packet, the client can call
            GetNextPacketSize to retrieve the number of audio frames in the next packet. The count reported by GetNextPacketSize matches the count retrieved in the GetBuffer call
            (through the pNumFramesToRead output parameter) that follows the GetNextPacketSize call. A packet always consists of an integral number of audio frames.
            </summary>
            <param name="framesInNextPacket">
            Pointer to a UINT32 variable into which the method writes the frame count (the number of audio frames in the next capture packet).
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="T:CoreAudioApi.PropertyVariant">
            <summary>
            Löst die Union eines Eintrages im PropertyStore (Variant) nach Typ auf und gibt seinen Inhalt typisiert zurück.
            </summary>
        </member>
        <member name="P:CoreAudioApi.PropertyVariant.Value">
            <summary>
            Property Value
            </summary>
        </member>
        <member name="T:CoreAudioApi.SampleRateConverter">
            <summary>
            Stellt einen Samplerate-Konverter bereit, der im Bereich von 8000 bis 192000 Audioframes pro Sekunde in beliebigen Verhältnissen vermitteln kann. Er ist für Fälle gedacht,
            in denen die Samplerate von Audiodaten aus einer Datei für die Wiedergabe oder zur Speicherung in eine andere Datei konvertiert werden soll.
            Die Ein- und Ausgangsarrays haben die gleiche Größe, welche bei der Ableitung der Klasse festgelegt werden muß. Die zeitliche Synchronisation besorgt ein Delegat,
            welcher ebenfalls bei der Ableitung übergeben wird und an den eine Clientmethode gebunden wird, die neue Daten besorgt.
            </summary>
        </member>
        <member name="M:CoreAudioApi.SampleRateConverter.#ctor(System.Int32,System.Int32,System.Int32,System.Int32,System.Boolean,System.Delegate)">
            <summary>
            Stellt einen Samplerate-Konverter bereit, der im Bereich von 8000 bis 192000 Audioframes pro Sekunde in beliebigen Verhältnissen vermitteln kann. Er ist für Fälle gedacht,
            in denen die Samplerate von Audiodaten aus einer Datei für die Wiedergabe oder zur Speicherung in eine andere Datei konvertiert werden soll.
            Die Ein- und Ausgangsarrays haben die gleiche Größe, welche bei der Ableitung der Klasse festgelegt werden muß. Die zeitliche Synchronisation besorgt ein Delegat,
            welcher ebenfalls bei der Ableitung übergeben wird und an den eine Clientmethode gebunden wird, die neue Daten besorgt. 
            </summary>
            <param name="SamplesPerSecondIn">
            Samplerate der Eingangsdaten.
            </param>
            <param name="SamplesPerSecondOut">
            Samplerate der Ausgangsdaten.
            </param>
            <param name="AudioFrames">
            Anzahl der in den Ein- und Ausgangsarrays gehaltenen Audioframes.
            </param>
            <param name="Channels">
            Anzahl der Kanäle.
            </param>
            <param name="HighQuality">
            Legt die Verarbeitungsgenauigkeit fest.
            true: die konvertierten Audiodaten erreichen 24 Bit Qualität, aber es wird mehr Rechenleistung benötigt.
            false: die konvertierten Audiodaten erreichen 16 Bit Qualität und es wird weniger Rechenleistung benötigt.
            </param>
            <param name="SetAudioDataDelegate">
            Delegat, welcher ausgelöst wird, wenn neue Audiodaten benötigt werden. An ihn muß eine Clientmethode gebunden sein, die diese Aufgabe erfülllt.
            </param>
        </member>
        <member name="M:CoreAudioApi.SampleRateConverter.SetAudioData(System.Double[0:,0:])">
            <summary>
            Dient der Übergabe neuer Audiodaten, deren Abtastrate umgerechnet werden soll. Diese Methode muß aus einer Clientmethode aufgerufen werden, welche an den
            SetAudioDataDelegate zu binden ist.
            </summary>
            <param name="Eingang">
            Array mit den unzuwandelnden Audiodaten.
            </param>
        </member>
        <member name="M:CoreAudioApi.SampleRateConverter.GetAudioData">
            <summary>
            Gibt die Audiodaten mit umgerechneter Samplerate zurück. Dabei wird der SetAudioDataDelegate aufgerufen, an den im Client des SampleRateConverter eine Methode
            gebunden sein muß, die SampleRateConverter.SetAudioData(double[,] Eingang) aufruft und so neue Audiodaten herbeischafft.
            </summary>
            <returns>
            Umgerechnete Audiodaten.
            </returns>
        </member>
        <member name="M:CoreAudioApi.SampleRateConverter.ToString">
            <summary>
            Gibt die Haupteigenschaften des SampleRateConverter als Zeichenkette zurück.
            </summary>
            <returns>
            Haupteigenschaften des SampleRateConverter.
            </returns>
        </member>
        <member name="P:CoreAudioApi.SampleRateConverter.Interpolieren">
            <summary>
            Gibt an, ob zwischen gespeicherten Tiefpasswerten interpoliert wird.
            </summary>
        </member>
        <member name="P:CoreAudioApi.SampleRateConverter.LatenzSamples">
            <summary>
            Gibt an, um wie viele Audioframes das Signal bei der Konvertierung im Bezug auf das Ausgangssignal verzögert wird.
            </summary>
        </member>
        <member name="P:CoreAudioApi.SampleRateConverter.LatenzTime">
            <summary>
            Gibt an, um wie viele 100 ns Einheiten das Signal bei der Konvertierung im Bezug auf die Samplerate am Ausgang verzögert wird.
            </summary>
        </member>
        <member name="T:CoreAudioApi.AudioRenderClient">
            <summary>
            AudioRenderClient verwaltet einen Audiostream, um Audiodaten in einen Rendering-Endpoint zu schreiben. Er wird aus der AudioRenderClient-Eigenschaft eines AudioClient
            gewonnen. Der AudioRenderClient muß nach seiner Verwendung mit Dispose vernichtet werden.
            </summary>
        </member>
        <member name="M:CoreAudioApi.AudioRenderClient.#ctor(CoreAudioApi.IAudioRenderClient)">
            <summary>
            AudioRenderClient verwaltet einen Audiostream, um Audiodaten in einen Rendering-Endpoint zu schreiben. Er wird aus der AudioRenderClient-Eigenschaft eines AudioClient
            gewonnen. Der AudioRenderClient muß nach seiner Verwendung mit Dispose vernichtet werden.
            </summary>
            <param name="iAudioRenderClient">
            Ein IAudioRenderClient aus einem AudioClient.
            </param>
        </member>
        <member name="M:CoreAudioApi.AudioRenderClient.GetBuffer(System.Int32)">
            <summary>
            Gibt den Pointer zu der Stelle im Stream zurück, an welche die nächsten Audioframes geschrieben werden können.
            </summary>
            <param name="framesToWrite">
            Anzahl der Audioframes, die in den Stream geschrieben werden sollen.
            </param>
            <returns>
            Pointer zu der Stelle im Stream, an welche die nächsten Audioframes geschrieben werden können.
            </returns>
        </member>
        <member name="M:CoreAudioApi.AudioRenderClient.ReleaseBuffer(System.Int32,CoreAudioApi.AudioClientBufferFlags)">
            <summary>
            Gibt den, von GetBuffer gefüllten Audiostream, wieder frei.
            </summary>
            <param name="framesWritten">
            Gibt die Anzahl der in den Stream geschriebenen Audioframes an. Der Wert muß kleiner oder gleich des zuletzt übergebenen framesToWrite aus GetBuffer sein.
            </param>
            <param name="bufferFlags">
            Wenn dieses Flag auf "Silent" gesetzt wird, werden alle enthaltenen Daten als Stille behandelt.
            </param>
        </member>
        <member name="M:CoreAudioApi.AudioRenderClient.Dispose">
            <summary>
            Gibt die Ressourcen des AudioRenderClient frei.
            </summary>
        </member>
        <member name="M:CoreAudioApi.AudioRenderClient.Dispose(System.Boolean)">
            <summary>
            Gibt die Ressourcen des AudioRenderClient frei.
            </summary>
            <param name="disposing">
            true, es werden auch verwaltete Objekte frei gegeben.
            false, wenn die Methode aus einem Destructor aufgerufen werden soll.
            </param>
        </member>
        <member name="M:CoreAudioApi.AudioRenderClient.Finalize">
            <summary>
            Destructor
            </summary>
        </member>
        <member name="P:CoreAudioApi.AudioRenderClient.Disposed">
            <summary>
            Ruft ab, ob das Element frei gegeben wurde.
            </summary>
        </member>
        <member name="T:CoreAudioApi.AudioCaptureClient">
            <summary>
            AudioCaptureClient verwaltet einen Audiostream, um Audiodaten aus einem Capture-Endpoint zu lesen. Er wird aus der AudioCaptureClient-Eigenschaft eines AudioClient gewonnen.
            Der AudioCaptureClient muß nach seiner Verwendung mit Dispose vernichtet werden.
            </summary>
        </member>
        <member name="M:CoreAudioApi.AudioCaptureClient.#ctor(CoreAudioApi.IAudioCaptureClient)">
            <summary>
            AudioCaptureClient verwaltet einen Audiostream, um Audiodaten aus einem Capture-Endpoint zu lesen. Er wird aus der AudioCaptureClient-Eigenschaft eines AudioClient gewonnen.
            Der AudioCaptureClient muß nach seiner Verwendung mit Dispose vernichtet werden.
            </summary>
            <param name="iAudioCaptureClient">
            Ein IAudioCaptureClient aus einem AudioClient.
            </param>
        </member>
        <member name="M:CoreAudioApi.AudioCaptureClient.GetBuffer(System.Int32@,CoreAudioApi.AudioClientBufferFlags@,System.Int64@,System.Int64@)">
            <summary>
            Gibt den Pointer zu der Stelle im Stream zurück, an der die nächsten Audioframes gelesen werden können.
            </summary>
            <param name="framesToRead">
            Anzahl der Audioframes, die aus dem Audiostream gelesen wurden.
            </param>
            <param name="audioClientBufferFlags">
            Gibt zurück, wie die gelesenen Pufferdaten zu interpretieren sind (Ton, Stille...).
            </param>
            <param name="devicePosition">
            Gibt die Position des ersten Audioframes im gelesenen Datenpaket im Stream zurück. Die Anzahl der Audioframes bezieht sich auf den Beginn des Streams.
            </param>
            <param name="qPCPosition">
            Gibt einen Performance Counter zu dem Zeitpunkt zurück, zu dem der Audioendpoint den ersten Frame in das Datenpaket geschrieben hat. Das Counter Ergebnis wird in
            100 ns Einheiten ausgegeben. Dieser Wert kann null sein, wenn der Client den Counter nicht unterstützt.
            </param>
            <returns>
            Pointer zu der Stelle im Stream, an die die nächsten Audioframes gelesen werden können.
            </returns>
        </member>
        <member name="M:CoreAudioApi.AudioCaptureClient.ReleaseBuffer(System.Int32)">
            <summary>
            Gibt den, von GetBuffer gelesenen Audiostream, wieder frei.
            </summary>
            <param name="framesReaded">
            Gibt die Anzahl der vom Stream gelesenen Audioframes an. Der Wert muß kleiner oder gleich des zuletzt übergebenen framesToRead aus GetBuffer sein.
            </param>
        </member>
        <member name="M:CoreAudioApi.AudioCaptureClient.GetNextPacketSize">
            <summary>
            Gibt die Anzahl der zur Zeit des Aufrufes lesbaren Audioframes zurück. Der Wert steht nur im Shared-Mode zur Verfügung.
            </summary>
            <returns>
            Die Anzahl der zur Zeit des Aufrufes lesbaren Audioframes.
            </returns>
        </member>
        <member name="M:CoreAudioApi.AudioCaptureClient.Dispose">
            <summary>
            Gibt die Ressourcen des AudioCaptureClient frei.
            </summary>
        </member>
        <member name="M:CoreAudioApi.AudioCaptureClient.Dispose(System.Boolean)">
            <summary>
            Gibt die Ressourcen des AudioCaptureClient frei.
            </summary>
            <param name="disposing">
            true, es werden auch verwaltete Objekte frei gegeben.
            false, wenn die Methode aus einem Destructor aufgerufen werden soll.
            </param>
        </member>
        <member name="M:CoreAudioApi.AudioCaptureClient.Finalize">
            <summary>
            Destructor
            </summary>
        </member>
        <member name="P:CoreAudioApi.AudioCaptureClient.Disposed">
            <summary>
            Ruft ab, ob das Element frei gegeben wurde.
            </summary>
        </member>
        <member name="T:CoreAudioApi.IMMDeviceCollection">
            <summary>
            The IMMDeviceCollection interface represents a collection of multimedia device resources.
            In the current implementation, the only device resources that the MMDevice API can create collections of are audio endpoint devices.
            </summary>
        </member>
        <member name="M:CoreAudioApi.IMMDeviceCollection.GetCount(System.UInt32@)">
            <summary>
            Retrieves a count of the devices in the device collection.
            </summary>
            <param name="devices">
            Pointer to a UINT variable into which the method writes the number of devices in the device collection. 
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IMMDeviceCollection.Item(System.UInt32,CoreAudioApi.IMMDevice@)">
            <summary>
            Retrieves a pointer to the specified item in the device collection.
            </summary>
            <param name="deviceNumber">
            The device number. If the collection contains n devices, the devices are numbered 0 to n – 1.
            </param>
            <param name="immDevice">
            Pointer to a pointer variable into which the method writes the address of the IMMDevice interface of the specified item in the device collection.
            Through this method, the caller obtains a counted reference to the interface.
            The caller is responsible for releasing the interface, when it is no longer needed, by calling the interface's Release method.
            If the Item call fails, immDevice is NULL. 
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="T:CoreAudioApi.IMMDevice">
            <summary>
            The IMMDevice interface encapsulates the generic features of a multimedia device resource.
            In the current implementation of the MMDevice API, the only type of device resource that an IMMDevice interface can represent is an audio endpoint device.
            </summary>
        </member>
        <member name="M:CoreAudioApi.IMMDevice.Activate(System.Guid@,CoreAudioApi.TagCLSCTX,System.IntPtr,System.Object@)">
            <summary>
            The Activate method creates a IMMDevice object with the specified interface.
            </summary>
            <param name="interfaceID">
            The interface identifier. This parameter is a reference to a GUID that identifies the interface that the caller requests be activated.
            The caller will use this interface to communicate with the COM object.
            </param>
            <param name="tagCLSCTX">
            The execution context in which the code that manages the newly created object will run.
            The caller can restrict the context by setting this parameter to the bitwise OR of one or more CLSCTX enumeration values. Alternatively,
            the client can avoid imposing any context restrictions by specifying CLSCTX_ALL.
            </param>
            <param name="activationParams">
            Set to NULL to activate an IAudioClient, IAudioEndpointVolume, IAudioMeterInformation, IAudioSessionManager, or IDeviceTopology interface on an audio endpoint device.
            When activating an IBaseFilter, IDirectSound, IDirectSound8, IDirectSoundCapture, or IDirectSoundCapture8 interface on the device,
            the caller can specify a pointer to a PROPVARIANT structure that contains stream-initialization information.
            </param>
            <param name="client">
            Pointer to a pointer variable into which the method writes the address of the interface specified by parameter iid.
            Through this method, the caller obtains a counted reference to the interface. The caller is responsible for releasing the interface,
            when it is no longer needed, by calling the interface's Release method. If the Activate call fails, client is NULL.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IMMDevice.OpenPropertyStore(CoreAudioApi.StorageAccessMode,CoreAudioApi.IPropertyStore@)">
            <summary>
            The OpenPropertyStore method retrieves an interface to the device's property store.
            </summary>
            <param name="storageAccessMode">
            The storage-access mode. This parameter specifies whether to open the property store in read mode, write mode, or read/write mode.
            Set this parameter to one of the following STGM constants:
            </param>
            <param name="iPropertyStore">
            Pointer to a pointer variable into which the method writes the address of the IPropertyStore interface of the device's property store.
            Through this method, the caller obtains a counted reference to the interface. The caller is responsible for releasing the interface,
            when it is no longer needed, by calling the interface's Release method. If the OpenPropertyStore call fails, iPropertyStore is NULL.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IMMDevice.GetID(System.String@)">
            <summary>
            The GetID method retrieves an endpoint ID string that identifies the audio endpoint device.
            </summary>
            <param name="id">
            Pointer to a pointer variable into which the method writes the address of a null-terminated, wide-character string containing the endpoint device ID.
            The method allocates the storage for the string. The caller is responsible for freeing the storage, when it is no longer needed, by calling the CoTaskMemFree function.
            If the GetId call fails, id is NULL.
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="M:CoreAudioApi.IMMDevice.GetState(CoreAudioApi.DeviceState@)">
            <summary>
            The GetState method retrieves the current device state.
            </summary>
            <param name="deviceState">
            Pointer to a DWORD variable into which the method writes the current state of the device. The device-state value is one of the following DeviceState constants:
            </param>
            <returns>
            Error Code
            </returns>
        </member>
        <member name="T:CoreAudioApi.EndpointHardwareSupport">
            <summary>
            Die Werte im EndpointHardwareSupport Enumerator geben an, ob Stellglieder zur Beeinflussung, Stummschaltung oder Messung des Pegels als Hardware in einem Audiogerät
            implementiert sind.
            </summary>
        </member>
        <member name="F:CoreAudioApi.EndpointHardwareSupport.Nothing">
            <summary>
            Keine Funktion wird von Hardware unterstützt.
            </summary>
        </member>
        <member name="F:CoreAudioApi.EndpointHardwareSupport.Volume">
            <summary>
            Die Beeinflussung des Pegels eines Audio-Streams von oder zu einem Audio-Endpoint wird durch Hardware unterstützt.
            </summary>
        </member>
        <member name="F:CoreAudioApi.EndpointHardwareSupport.Mute">
            <summary>
            Die Stummschaltung eines Audio-Streams von oder zu einem Audio-Endpoint wird durch Hardware unterstützt.
            </summary>
        </member>
        <member name="F:CoreAudioApi.EndpointHardwareSupport.Meter">
            <summary>
            Die Messung des Pegels eines Audio-Streams von oder zu einem Audio-Endpoint wird durch das Audiogerät per Hardware unterstützt.
            </summary>
        </member>
    </members>
</doc>
